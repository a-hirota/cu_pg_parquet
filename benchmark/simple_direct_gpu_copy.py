"""
PostgreSQL â†’ GPUç›´æ¥ã‚³ãƒ”ãƒ¼ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰

ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ä¾‹ã‚’åŸºã«ã—ãŸã€æœ€å°é™ã®å®Ÿè£…:
```python
import psycopg, rmm, kvikio
from kvikio import CuFile

rows_est   = 50_000_000
row_bytes  = 17*8 + 17*4   # æ¦‚ç®—
dbuf       = rmm.DeviceBuffer(size=19 + rows_est*row_bytes + 2)

with psycopg.connect("dbname=bench") as conn:
    with conn.cursor() as cur:
        with cur.copy("COPY lineorder TO STDOUT (FORMAT BINARY)") as copy:
            offset = 0
            for chunk in copy:
                dbuf.copy_from_host(buffer=chunk, dst_offset=offset)
                offset += len(chunk)
```

ç’°å¢ƒå¤‰æ•°:
GPUPASER_PG_DSN  : PostgreSQLæ¥ç¶šæ–‡å­—åˆ— (ä¾‹: "dbname=postgres user=postgres host=localhost port=5432")
"""

import os
import time
import psycopg
import rmm
import numpy as np
from numba import cuda
import argparse

def simple_direct_gpu_copy(table_name="lineorder", limit_rows=50_000_000):
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãªGPUç›´æ¥ã‚³ãƒ”ãƒ¼å®Ÿè£…
    
    Args:
        table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å
        limit_rows: å‡¦ç†è¡Œæ•°åˆ¶é™
    """
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰æ¥ç¶šæ–‡å­—åˆ—ã‚’å–å¾—
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("ä¾‹: export GPUPASER_PG_DSN='dbname=postgres user=postgres host=localhost port=5432'")
        return None

    print(f"=== ã‚·ãƒ³ãƒ—ãƒ«GPUç›´æ¥ã‚³ãƒ”ãƒ¼å®Ÿè£… ===")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {table_name}")
    print(f"è¡Œæ•°åˆ¶é™: {limit_rows:,}")
    print(f"æ¥ç¶šå…ˆ: {dsn}")

    # RMM åˆæœŸåŒ–
    try:
        if not rmm.is_initialized():
            rmm.reinitialize(pool_allocator=True, initial_pool_size=8*1024**3)  # 8GB
            print("âœ… RMM ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        print(f"âŒ RMMåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None

    # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºæ¨å®šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ä¾‹ã¨åŒã˜è¨ˆç®—æ–¹æ³•ï¼‰
    rows_est = limit_rows
    row_bytes = 17*8 + 17*4  # 17åˆ—æƒ³å®š: 8ãƒã‚¤ãƒˆÃ—8åˆ— + 4ãƒã‚¤ãƒˆÃ—9åˆ—
    header_bytes = 19        # PostgreSQL COPY BINARYãƒ˜ãƒƒãƒ€ãƒ¼
    buffer_size = header_bytes + rows_est * row_bytes + 1024  # å°‘ã—ä½™è£•

    print(f"æ¨å®šãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {buffer_size / (1024*1024):.2f} MB")

    # æ³¨ï¼šGPU ãƒãƒƒãƒ•ã‚¡ã¯ COPY å®Œäº†å¾Œã«å®Ÿãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§ç¢ºä¿
    print(f"æ¨å®šãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {buffer_size / (1024*1024):.2f} MB")

    # PostgreSQLæ¥ç¶š & COPYå®Ÿè¡Œ
    print("PostgreSQLæ¥ç¶š & GPUç›´æ¥ã‚³ãƒ”ãƒ¼é–‹å§‹...")
    start_time = time.time()
    
    try:
        with psycopg.connect(dsn) as conn:
            with conn.cursor() as cur:
                # COPY ã‚¯ã‚¨ãƒªï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ä¾‹ã¨åŒæ§˜ï¼‰
                copy_sql = f"COPY (SELECT * FROM {table_name} LIMIT {limit_rows}) TO STDOUT (FORMAT BINARY)"
                print(f"å®Ÿè¡ŒSQL: {copy_sql}")
                
                with cur.copy(copy_sql) as copy:
                    offset = 0
                    chunk_count = 0
                    total_bytes = 0
                    
                    # ãƒãƒ£ãƒ³ã‚¯ã‚’é€æ¬¡å—ã‘å–ã‚Šã€GPU ã«ç›´æ¥æ›¸ãè¾¼ã¿
                    for chunk in copy:
                        if chunk:
                            chunk_size = len(chunk)
                            
                            # ãƒãƒƒãƒ•ã‚¡ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ ãƒã‚§ãƒƒã‚¯
                            if offset + chunk_size > dbuf.size:
                                print(f"âš ï¸  è­¦å‘Š: ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºä¸è¶³")
                                print(f"   ç¾åœ¨ã‚ªãƒ•ã‚»ãƒƒãƒˆ: {offset:,}")
                                print(f"   ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size:,}")
                                print(f"   ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {dbuf.size:,}")
                                break
                            
                            # ã€é‡è¦ã€‘GPU ãƒãƒƒãƒ•ã‚¡ã«ç›´æ¥ã‚³ãƒ”ãƒ¼ï¼ˆRMM 25.xå¯¾å¿œï¼‰
                            # Numba CUDA Driver ã§ host â†’ GPU + offset
                            cuda.cudadrv.driver.memcpy_htod(
                                int(dbuf.ptr) + offset,  # dst GPU ptr + ã‚ªãƒ•ã‚»ãƒƒãƒˆ
                                chunk,                   # src host bytes
                                chunk_size               # ã‚µã‚¤ã‚º
                            )
                            offset += chunk_size
                            chunk_count += 1
                            total_bytes += chunk_size
                            
                            # é€²æ—è¡¨ç¤ºã‚’ç„¡åŠ¹åŒ–
                            # if chunk_count % 500 == 0:
                            #     print(f"  ğŸ“Š ãƒãƒ£ãƒ³ã‚¯ {chunk_count:,} | {total_bytes / (1024*1024):.2f} MB")
    
    except Exception as e:
        print(f"âŒ PostgreSQLå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None

    copy_time = time.time() - start_time
    
    # GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ & 1å›ã‚³ãƒ”ãƒ¼
    print("GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ & 1å›ã‚³ãƒ”ãƒ¼å®Ÿè¡Œä¸­...")
    start_gpu_time = time.time()
    
    # å®Ÿãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«åˆã‚ã›ã¦ãƒãƒƒãƒ•ã‚¡ç¢ºä¿
    dbuf = rmm.DeviceBuffer(size=total_bytes)
    
    # RMM 25.x æ­£ã—ã„API - ä½ç½®å¼•æ•°1å€‹ã®ã¿
    dbuf.copy_from_host(host_bytes)
    
    # ãƒ›ã‚¹ãƒˆãƒ¡ãƒ¢ãƒªè§£æ”¾
    del host_bytes
    
    gpu_time = time.time() - start_gpu_time
    
    print(f"âœ… GPU 1å›ã‚³ãƒ”ãƒ¼å®Œäº†!")
    print(f"--- çµæœ ---")
    print(f"  COPYå®Ÿè¡Œæ™‚é–“: {copy_time:.4f} ç§’")
    print(f"  GPUè»¢é€æ™‚é–“ : {gpu_time:.4f} ç§’")
    print(f"  å‡¦ç†ãƒãƒ£ãƒ³ã‚¯: {chunk_count:,} å€‹")
    print(f"  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_bytes / (1024*1024):.2f} MB")
    print(f"  ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦: {total_bytes / (1024*1024) / copy_time:.2f} MB/sec")
    print(f"  GPUè»¢é€é€Ÿåº¦   : {total_bytes / (1024*1024) / gpu_time:.2f} MB/sec")

    # GPU ãƒãƒƒãƒ•ã‚¡ã®å†…å®¹ç¢ºèªï¼ˆæœ€åˆã®æ•°ãƒã‚¤ãƒˆï¼‰
    print(f"\n--- GPUãƒãƒƒãƒ•ã‚¡å†…å®¹ç¢ºèª ---")
    try:
        # æœ€åˆã®32ãƒã‚¤ãƒˆã‚’ãƒ›ã‚¹ãƒˆã«ã‚³ãƒ”ãƒ¼ã—ã¦ç¢ºèª
        sample_size = min(32, offset)
        if sample_size > 0:
            sample_buf = rmm.DeviceBuffer(size=sample_size)
            sample_buf.copy_from_device(dbuf, size=sample_size)
            
            # numba GPU ã‚¢ãƒ¬ã‚¤ã¨ã—ã¦å–å¾—
            gpu_array = cuda.as_cuda_array(sample_buf).view(dtype=np.uint8)
            sample_bytes = gpu_array.copy_to_host()
            
            print(f"å…ˆé ­ {sample_size} ãƒã‚¤ãƒˆ:")
            hex_str = ' '.join(f'{b:02x}' for b in sample_bytes)
            print(f"  Hex: {hex_str}")
            print(f"  Dec: {list(sample_bytes)}")
            
    except Exception as e:
        print(f"ãƒãƒƒãƒ•ã‚¡å†…å®¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

    return {
        'dbuf': dbuf,
        'size': offset,
        'chunks': chunk_count,
        'time': copy_time,
        'throughput_mbps': total_bytes / (1024*1024) / copy_time
    }

def save_gpu_buffer_to_file(dbuf, size, output_path):
    """
    GPU ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ä¾‹
    ï¼ˆkvikio CuFile ã¾ãŸã¯é€šå¸¸ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼‰
    """
    print(f"\n--- GPUãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ ---")
    print(f"å‡ºåŠ›ãƒ‘ã‚¹: {output_path}")
    
    try:
        # kvikio CuFile ã‚’è©¦è¡Œ
        from kvikio import CuFile
        
        start_time = time.time()
        with CuFile(output_path, 'w') as f:
            # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®ã¿æ›¸ãè¾¼ã¿
            trimmed_buf = rmm.DeviceBuffer(size=size)
            trimmed_buf.copy_from_device(dbuf, size=size)
            f.pwrite(trimmed_buf)
        
        save_time = time.time() - start_time
        print(f"âœ… CuFileä¿å­˜å®Œäº† ({save_time:.4f}ç§’)")
        print(f"   ã‚µã‚¤ã‚º: {size / (1024*1024):.2f} MB")
        print(f"   é€Ÿåº¦: {size / (1024*1024) / save_time:.2f} MB/sec")
        
    except ImportError:
        print("âš ï¸  kvikio (CuFile) ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚é€šå¸¸ã®æ–¹æ³•ã§ä¿å­˜ã—ã¾ã™...")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: GPUâ†’ãƒ›ã‚¹ãƒˆâ†’ãƒ•ã‚¡ã‚¤ãƒ«
        start_time = time.time()
        gpu_array = cuda.as_cuda_array(dbuf).view(dtype=np.uint8)
        host_data = gpu_array[:size].copy_to_host()
        
        with open(output_path, 'wb') as f:
            f.write(host_data.tobytes())
        
        save_time = time.time() - start_time
        print(f"âœ… é€šå¸¸ä¿å­˜å®Œäº† ({save_time:.4f}ç§’)")
        print(f"   ã‚µã‚¤ã‚º: {size / (1024*1024):.2f} MB")
        print(f"   é€Ÿåº¦: {size / (1024*1024) / save_time:.2f} MB/sec")
        
    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='PostgreSQL â†’ GPUç›´æ¥ã‚³ãƒ”ãƒ¼ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰')
    parser.add_argument('--table', type=str, default='lineorder', help='ãƒ†ãƒ¼ãƒ–ãƒ«å')
    parser.add_argument('--rows', type=int, default=1000000, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    parser.add_argument('--save', type=str, help='GPUç”Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ‘ã‚¹ (optional)')
    
    args = parser.parse_args()
    
    # CUDAåˆæœŸåŒ–ç¢ºèª
    try:
        cuda.current_context()
        print("âœ… CUDA context OK")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        exit(1)
    
    # ã‚·ãƒ³ãƒ—ãƒ« GPU ç›´æ¥ã‚³ãƒ”ãƒ¼å®Ÿè¡Œ
    result = simple_direct_gpu_copy(
        table_name=args.table,
        limit_rows=args.rows
    )
    
    if result and args.save:
        save_gpu_buffer_to_file(
            result['dbuf'], 
            result['size'], 
            args.save
        )
    
    print(f"\nğŸ‰ ã‚·ãƒ³ãƒ—ãƒ«GPUç›´æ¥ã‚³ãƒ”ãƒ¼å®Œäº†!")

if __name__ == "__main__":
    main()