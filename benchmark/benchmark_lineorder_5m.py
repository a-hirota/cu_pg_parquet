"""
Benchmark: PostgreSQL → COPY BINARY → GPU 2‑pass → Arrow RecordBatch → Parquet

環境変数
--------
GPUPASER_PG_DSN  : psycopg2.connect 互換 DSN 文字列
PG_TABLE_PREFIX  : lineorder テーブルがスキーマ名付きの場合に指定 (optional)

処理内容
----------
lineorder テーブル (約500万行を想定) を
1. COPY BINARY で取得
2. GPU パイプライン decode_chunk で Arrow RecordBatch に変換
3. 処理時間を計測
4. 結果を Parquet ファイルに出力
5. 出力された Parquet ファイルを cuDF で読み込み、基本情報を表示して検証
"""

import os
import time
import numpy as np
import psycopg
import pyarrow as pa
import pyarrow.parquet as pq
import cudf
from numba import cuda

# Import necessary functions from the correct modules using absolute paths from root
from src.meta_fetch import fetch_column_meta, ColumnMeta # Import ColumnMeta as well
from src.gpu_parse_wrapper import parse_binary_chunk_gpu, detect_pg_header_size
from src.gpu_decoder_v2 import decode_chunk
from src.gpu_decoder_v2_decimal_optimized import decode_chunk_decimal_optimized
from src.gpu_decoder_v2_decimal_column_wise import decode_chunk_decimal_column_wise
# Remove CPU row start calculator import
# from test.test_single_row_pg_parser import calculate_row_starts_cpu


TABLE_NAME = "lineorder"
OUTPUT_PARQUET_PATH = "benchmark/lineorder_5m.output.parquet" # 出力ファイルパス

def run_benchmark():
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("エラー: 環境変数 GPUPASER_PG_DSN が設定されていません。")
        return

    prefix = os.environ.get("PG_TABLE_PREFIX", "")
    tbl = f"{prefix}{TABLE_NAME}" if prefix else TABLE_NAME

    # 環境変数でDecimal最適化を制御
    optimization_mode = os.environ.get("DECIMAL_OPTIMIZATION_MODE", "column_wise")
    
    mode_names = {
        "column_wise": "Column-wise最適化版",
        "integrated": "Integrated最適化版", 
        "traditional": "従来版"
    }
    mode_name = mode_names.get(optimization_mode, "Column-wise最適化版")
    
    print(f"ベンチマーク開始 ({mode_name}): テーブル={tbl}")
    print(f"* Decimal最適化モード: {optimization_mode}")
    
    if optimization_mode == "column_wise":
        print("* Pass1段階でDecimal処理統合 (列ごと処理)")
    elif optimization_mode == "integrated":
        print("* Pass1段階でDecimal処理統合 (全列統合)")
    else:
        print("* 従来のPass1/Pass2分離処理")
    start_total_time = time.time()
    conn = psycopg.connect(dsn)
    try:
        # -------------------------------
        # ColumnMeta
        # -------------------------------
        print("メタデータを取得中...")
        start_meta_time = time.time()
        columns = fetch_column_meta(conn, f"SELECT * FROM {tbl}")
        meta_time = time.time() - start_meta_time
        print(f"メタデータ取得完了 ({meta_time:.4f}秒)")

        # --- Add debug print for column metadata ---
        print("\n--- Column Metadata ---")
        for col in columns:
            print(f"Name: {col.name}, OID: {col.pg_oid}, Typmod: {col.pg_typmod}, Arrow ID: {col.arrow_id}, Elem Size: {col.elem_size}, Arrow Param: {col.arrow_param}")
        print("-----------------------\n")
        # --- End debug print ---
        
        ncols = len(columns)

        # -------------------------------
        # COPY BINARY chunk
        # -------------------------------
        print("COPY BINARY を実行中 (LIMIT 1,000,000)...") # Add limit info
        start_copy_time = time.time()
        # 注意: 全データをメモリに読み込むため、巨大テーブルではメモリ不足の可能性あり
        limit_rows = 1000000
        copy_sql = f"COPY (SELECT * FROM {tbl} LIMIT {limit_rows}) TO STDOUT (FORMAT binary)" # Add LIMIT clause
        buf = bytearray()
        with conn.cursor().copy(copy_sql) as cpy:
            while True:
                chunk = cpy.read()
                if not chunk:
                    break
                buf.extend(chunk)
            raw_host = np.frombuffer(buf, dtype=np.uint8)
        copy_time = time.time() - start_copy_time
        print(f"COPY BINARY 完了 ({copy_time:.4f}秒), データサイズ: {len(raw_host) / (1024*1024):.2f} MB")

    finally:
        conn.close()

    # -------------------------------
    # GPU 処理
    # -------------------------------
    print("GPUにデータを転送中...")
    start_transfer_time = time.time()
    raw_dev = cuda.to_device(raw_host)
    transfer_time = time.time() - start_transfer_time
    print(f"GPU転送完了 ({transfer_time:.4f}秒)")

    # ヘッダーサイズを検出
    header_sample = raw_dev[:min(128, raw_dev.shape[0])].copy_to_host()
    header_size = detect_pg_header_size(header_sample)
    print(f"検出したヘッダーサイズ: {header_size} バイト")

    # GPU Parse (includes row counting, offset calculation, field parsing)
    print("GPUでパース中 (行数カウント、オフセット計算、フィールド解析)...")
    start_parse_time = time.time()
    # Call the updated wrapper which now handles row counting and offset calculation internally
    field_offsets_dev, field_lengths_dev = parse_binary_chunk_gpu(
        raw_dev,
        ncols=ncols,
        header_size=header_size
        # use_gpu_row_detection parameter is now removed
        # rows and row_start_positions are no longer passed
    )
    parse_time = time.time() - start_parse_time
    # The row count is now determined inside parse_binary_chunk_gpu
    rows = field_offsets_dev.shape[0] # Get actual row count from output array shape
    print(f"GPUパース完了 ({parse_time:.4f}秒), 行数: {rows}")

    # 環境変数でDecimal最適化を制御
    optimization_mode = os.environ.get("DECIMAL_OPTIMIZATION_MODE", "column_wise")
    
    if optimization_mode == "column_wise":
        print("GPUでデコード中 (Pass 1 & 2 - Column-wise Decimal最適化版)...")
        start_decode_time = time.time()
        batch = decode_chunk_decimal_column_wise(raw_dev, field_offsets_dev, field_lengths_dev, columns, use_pass1_integration=True)
        decode_time = time.time() - start_decode_time
        print(f"GPUデコード完了 (Column-wise最適化版) ({decode_time:.4f}秒)")
    elif optimization_mode == "integrated":
        print("GPUでデコード中 (Pass 1 & 2 - Integrated Decimal最適化版)...")
        start_decode_time = time.time()
        batch = decode_chunk_decimal_optimized(raw_dev, field_offsets_dev, field_lengths_dev, columns, use_pass1_integration=True)
        decode_time = time.time() - start_decode_time
        print(f"GPUデコード完了 (Integrated最適化版) ({decode_time:.4f}秒)")
    else:  # traditional
        print("GPUでデコード中 (Pass 1 & 2 - 従来版)...")
        start_decode_time = time.time()
        batch = decode_chunk(raw_dev, field_offsets_dev, field_lengths_dev, columns)
        decode_time = time.time() - start_decode_time
        print(f"GPUデコード完了 (従来版) ({decode_time:.4f}秒)")

    # Arrow Table に変換 (複数バッチの場合は結合が必要だが、ここでは単一バッチと仮定)
    result_table = pa.Table.from_batches([batch])
    print(f"Arrow Table 作成完了: {result_table.num_rows} 行, {result_table.num_columns} 列")

    # -------------------------------
    # Parquet 出力
    # -------------------------------
    print(f"Parquetファイル書き込み中: {OUTPUT_PARQUET_PATH}")
    start_write_time = time.time()
    pq.write_table(result_table, OUTPUT_PARQUET_PATH)
    write_time = time.time() - start_write_time
    print(f"Parquet書き込み完了 ({write_time:.4f}秒)")

    total_time = time.time() - start_total_time
    
    # Decimal列数をカウント
    decimal_cols = sum(1 for col in columns if col.arrow_id == 5)  # DECIMAL128 = 5
    
    print(f"\nベンチマーク完了 ({mode_name}): 総時間 = {total_time:.4f} 秒")
    print("--- 時間内訳 ---")
    print(f"  メタデータ取得: {meta_time:.4f} 秒")
    print(f"  COPY BINARY   : {copy_time:.4f} 秒")
    print(f"  GPU転送       : {transfer_time:.4f} 秒")
    print(f"  GPUパース     : {parse_time:.4f} 秒")
    print(f"  GPUデコード   : {decode_time:.4f} 秒")
    print(f"  Parquet書き込み: {write_time:.4f} 秒")
    print("----------------")
    print(f"--- 統計情報 ---")
    print(f"  処理行数      : {rows:,} 行")
    print(f"  処理列数      : {len(columns)} 列")
    print(f"  Decimal列数   : {decimal_cols} 列")
    print(f"  データサイズ  : {len(raw_host) / (1024*1024):.2f} MB")
    print(f"  最適化モード  : {mode_name}")
    if decimal_cols > 0:
        print(f"  理論効果      : Decimal列 {decimal_cols}個 → メモリアクセス削減期待")
    print("----------------")


    # -------------------------------
    # cuDF での検証
    # -------------------------------
    print(f"\ncuDFでParquetファイルを読み込んで検証中: {OUTPUT_PARQUET_PATH}")
    try:
        start_cudf_read_time = time.time()
        gdf = cudf.read_parquet(OUTPUT_PARQUET_PATH)
        cudf_read_time = time.time() - start_cudf_read_time
        print(f"cuDF読み込み完了 ({cudf_read_time:.4f}秒)")
        print("--- cuDF DataFrame Info ---")
        gdf.info()
        print("\n--- cuDF DataFrame Head ---")
        print(gdf.head())
        print("-------------------------")
        print("cuDFでの読み込み検証: 成功")
    except Exception as e:
        print(f"cuDFでの読み込み検証: 失敗 - {e}")

if __name__ == "__main__":
    # CUDAコンテキストの初期化を確認
    try:
        cuda.current_context()
        print("CUDA context OK")
    except Exception as e:
        print(f"CUDA context initialization failed: {e}")
        exit(1)
    run_benchmark()
