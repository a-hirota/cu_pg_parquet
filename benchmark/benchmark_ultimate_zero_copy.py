"""
ç©¶æ¥µã®cuDF ZeroCopyçµ±åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

PostgreSQL â†’ COPY BINARY â†’ æœ€é©åŒ–GPUä¸¦åˆ—å‡¦ç† â†’ cuDF ZeroCopy â†’ GPUç›´æ¥Parquet

å…¨ã¦ã®æœ€é©åŒ–æŠ€è¡“ã‚’çµ±åˆã—ãŸç©¶æ¥µãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰ˆ:
1. ä¸¦åˆ—åŒ–GPUè¡Œæ¤œå‡ºãƒ»ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æŠ½å‡º  
2. ãƒ¡ãƒ¢ãƒªã‚³ã‚¢ãƒ¬ãƒƒã‚·ãƒ³ã‚°æœ€é©åŒ–
3. cuDFã«ã‚ˆã‚‹ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼Arrowå¤‰æ›
4. GPUç›´æ¥Parquetæ›¸ãå‡ºã—
5. RMMçµ±åˆãƒ¡ãƒ¢ãƒªç®¡ç†

ç’°å¢ƒå¤‰æ•°:
GPUPASER_PG_DSN  : PostgreSQLæ¥ç¶šæ–‡å­—åˆ—
PG_TABLE_PREFIX  : ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ (optional)
"""

import os
import sys
import time
import numpy as np
import psycopg
import cudf
from numba import cuda
import argparse

from src.metadata import fetch_column_meta
from src.types import ColumnMeta
from src.binary_parser import detect_pg_header_size
from src.ultimate_zero_copy_processor import ultimate_postgresql_to_cudf_parquet

TABLE_NAME = "lineorder"

def create_output_filename(method: str, compression: str = "snappy") -> str:
    """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ"""
    timestamp = int(time.time())
    return f"benchmark/lineorder_{method}_{compression}_{timestamp}.parquet"

def run_ultimate_benchmark(
    limit_rows: int = 1000000,
    compression: str = "snappy", 
    use_rmm: bool = True,
    optimize_gpu: bool = True,
    output_path: str = None
):
    """ç©¶æ¥µç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
    
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return None

    prefix = os.environ.get("PG_TABLE_PREFIX", "")
    tbl = f"{prefix}{TABLE_NAME}" if prefix else TABLE_NAME
    
    if output_path is None:
        output_path = create_output_filename("ultimate", compression)

    print("=" * 80)
    print("ğŸš€ ç©¶æ¥µã®cuDF ZeroCopyçµ±åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ğŸš€")
    print("=" * 80)
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«        : {tbl}")
    print(f"åˆ¶é™è¡Œæ•°        : {limit_rows:,}")
    print(f"åœ§ç¸®æ–¹å¼        : {compression}")
    print(f"RMMä½¿ç”¨         : {use_rmm}")
    print(f"GPUæœ€é©åŒ–       : {optimize_gpu}")
    print(f"å‡ºåŠ›ãƒ‘ã‚¹        : {output_path}")
    print("-" * 80)
    
    overall_start_time = time.time()
    benchmark_results = {}
    
    # === PostgreSQLæ¥ç¶šãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾— ===
    conn = psycopg.connect(dsn)
    try:
        print("ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        meta_start = time.time()
        columns = fetch_column_meta(conn, f"SELECT * FROM {tbl}")
        benchmark_results['metadata_time'] = time.time() - meta_start
        print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({benchmark_results['metadata_time']:.4f}ç§’)")
        
        ncols = len(columns)
        decimal_cols = sum(1 for col in columns if col.arrow_id == 5)
        
        print(f"   åˆ—æ•°: {ncols}, Decimalåˆ—æ•°: {decimal_cols}")

        # === COPY BINARYå®Ÿè¡Œ ===
        print("ğŸ“¥ COPY BINARYå®Ÿè¡Œä¸­...")
        copy_start = time.time()
        copy_sql = f"COPY (SELECT * FROM {tbl} LIMIT {limit_rows}) TO STDOUT (FORMAT binary)"
        buf = bytearray()
        
        with conn.cursor().copy(copy_sql) as cpy:
            while True:
                chunk = cpy.read()
                if not chunk:
                    break
                buf.extend(chunk)
            raw_host = np.frombuffer(buf, dtype=np.uint8)
        
        benchmark_results['copy_binary_time'] = time.time() - copy_start
        data_size_mb = len(raw_host) / (1024*1024)
        print(f"âœ… COPY BINARYå®Œäº† ({benchmark_results['copy_binary_time']:.4f}ç§’)")
        print(f"   ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {data_size_mb:.2f} MB")

    finally:
        conn.close()

    # === GPUè»¢é€ ===
    print("ğŸš€ GPUè»¢é€ä¸­...")
    transfer_start = time.time()
    raw_dev = cuda.to_device(raw_host)
    benchmark_results['gpu_transfer_time'] = time.time() - transfer_start
    print(f"âœ… GPUè»¢é€å®Œäº† ({benchmark_results['gpu_transfer_time']:.4f}ç§’)")

    # === ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºæ¤œå‡º ===
    header_sample = raw_dev[:min(128, raw_dev.shape[0])].copy_to_host()
    header_size = detect_pg_header_size(header_sample)
    print(f"ğŸ“ ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º: {header_size} ãƒã‚¤ãƒˆ")

    # === ç©¶æ¥µçµ±åˆå‡¦ç†å®Ÿè¡Œ ===
    print("âš¡ ç©¶æ¥µçµ±åˆå‡¦ç†é–‹å§‹...")
    ultimate_start = time.time()
    
    try:
        cudf_df, detailed_timing = ultimate_postgresql_to_cudf_parquet(
            raw_dev=raw_dev,
            columns=columns,
            ncols=ncols,
            header_size=header_size,
            output_path=output_path,
            compression=compression,
            use_rmm=use_rmm,
            optimize_gpu=optimize_gpu
        )
        
        benchmark_results['ultimate_processing_time'] = time.time() - ultimate_start
        benchmark_results.update(detailed_timing)
        
        rows = len(cudf_df)
        cols = len(cudf_df.columns)
        
        print(f"âœ… ç©¶æ¥µçµ±åˆå‡¦ç†å®Œäº† ({benchmark_results['ultimate_processing_time']:.4f}ç§’)")
        print(f"   çµæœ: {rows:,} è¡Œ Ã— {cols} åˆ—")
        
    except Exception as e:
        print(f"âŒ ç©¶æ¥µçµ±åˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return None

    # === ç·åˆæ™‚é–“è¨ˆç®— ===
    benchmark_results['total_time'] = time.time() - overall_start_time

    # === çµæœæ¤œè¨¼ ===
    print("ğŸ” çµæœæ¤œè¨¼ä¸­...")
    try:
        verify_start = time.time()
        verification_df = cudf.read_parquet(output_path)
        benchmark_results['verification_time'] = time.time() - verify_start
        
        print(f"âœ… æ¤œè¨¼å®Œäº† ({benchmark_results['verification_time']:.4f}ç§’)")
        print(f"   èª­ã¿è¾¼ã¿çµæœ: {len(verification_df):,} è¡Œ Ã— {len(verification_df.columns)} åˆ—")
        
        # ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª
        print("   ãƒ‡ãƒ¼ã‚¿å‹:")
        for col_name, dtype in verification_df.dtypes.items():
            print(f"     {col_name}: {dtype}")
        
        # ãƒ‡ãƒ¼ã‚¿å†…å®¹ã®ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        print("\n   ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€åˆã®5è¡Œï¼‰:")
        try:
            sample_df = verification_df.head()
            for i in range(min(5, len(sample_df))):
                row_data = []
                for col in sample_df.columns:
                    value = sample_df[col].iloc[i]
                    # å€¤ã®å‹ã¨å†…å®¹ã‚’é©åˆ‡ã«è¡¨ç¤º
                    if hasattr(value, 'item'):
                        value = value.item()  # numpy/cudf scalar to python
                    row_data.append(str(value)[:20])  # é•·ã„å€¤ã¯åˆ‡ã‚Šè©°ã‚
                print(f"     è¡Œ{i+1}: {row_data}")
        except Exception as e:
            print(f"     ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
        
        # åŸºæœ¬çµ±è¨ˆæƒ…å ±
        print("\n   åŸºæœ¬çµ±è¨ˆ:")
        try:
            numeric_cols = verification_df.select_dtypes(include=['number']).columns
            if len(numeric_cols) > 0:
                for col in numeric_cols[:5]:  # æœ€åˆã®5ã¤ã®æ•°å€¤åˆ—ã®ã¿
                    col_data = verification_df[col]
                    if len(col_data) > 0:
                        print(f"     {col}: å¹³å‡={float(col_data.mean()):.2f}, æœ€å°={float(col_data.min()):.2f}, æœ€å¤§={float(col_data.max()):.2f}")
        except Exception as e:
            print(f"     çµ±è¨ˆæƒ…å ±ã‚¨ãƒ©ãƒ¼: {e}")
            
    except Exception as e:
        print(f"âš ï¸  æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼: {e}")
        benchmark_results['verification_time'] = 0

    # === æœ€çµ‚çµæœè¡¨ç¤º ===
    print_final_results(benchmark_results, rows, cols, data_size_mb, decimal_cols)
    
    return {
        'dataframe': cudf_df,
        'timing': benchmark_results,
        'output_path': output_path,
        'rows': rows,
        'columns': cols,
        'data_size_mb': data_size_mb
    }

def print_final_results(timing: dict, rows: int, cols: int, data_size_mb: float, decimal_cols: int):
    """æœ€çµ‚çµæœã®è©³ç´°è¡¨ç¤º"""
    
    print("\n" + "=" * 80)
    print("ğŸ† ç©¶æ¥µãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ")
    print("=" * 80)
    
    # åŸºæœ¬çµ±è¨ˆ
    print("ğŸ“Š å‡¦ç†çµ±è¨ˆ:")
    print(f"   å‡¦ç†è¡Œæ•°      : {rows:,} è¡Œ")
    print(f"   å‡¦ç†åˆ—æ•°      : {cols} åˆ—")
    print(f"   Decimalåˆ—æ•°   : {decimal_cols} åˆ—")
    print(f"   ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º  : {data_size_mb:.2f} MB")
    
    # æ™‚é–“å†…è¨³
    print("\nâ±ï¸  è©³ç´°ã‚¿ã‚¤ãƒŸãƒ³ã‚°:")
    timing_keys = [
        ('metadata_time', 'ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—'),
        ('copy_binary_time', 'COPY BINARY'),
        ('gpu_transfer_time', 'GPUè»¢é€'),
        ('gpu_parsing', 'GPUä¸¦åˆ—ãƒ‘ãƒ¼ã‚¹'),
        ('preparation', 'å‰å‡¦ç†ãƒ»ãƒãƒƒãƒ•ã‚¡æº–å‚™'),
        ('kernel_execution', 'GPUçµ±åˆã‚«ãƒ¼ãƒãƒ«'),
        ('cudf_creation', 'cuDFä½œæˆ'),
        ('parquet_export', 'Parquetæ›¸ãå‡ºã—'),
        ('verification_time', 'çµæœæ¤œè¨¼'),
        ('total_time', 'ç·å®Ÿè¡Œæ™‚é–“')
    ]
    
    for key, label in timing_keys:
        if key in timing:
            print(f"   {label:20}: {timing[key]:8.4f} ç§’")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
    total_time = timing.get('total_time', 1.0)
    processing_time = timing.get('ultimate_processing_time', timing.get('overall_total', 1.0))
    
    if total_time > 0 and processing_time > 0:
        print("\nğŸš€ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™:")
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
        total_cells = rows * cols
        cell_throughput = total_cells / processing_time
        data_throughput = data_size_mb / processing_time
        
        print(f"   ã‚»ãƒ«å‡¦ç†é€Ÿåº¦  : {cell_throughput:,.0f} cells/sec")
        print(f"   ãƒ‡ãƒ¼ã‚¿å‡¦ç†é€Ÿåº¦: {data_throughput:.2f} MB/sec") 
        
        # åŠ¹ç‡æŒ‡æ¨™
        gpu_time = timing.get('kernel_execution', 0)
        if gpu_time > 0:
            gpu_efficiency = (gpu_time / processing_time) * 100
            print(f"   GPUä½¿ç”¨åŠ¹ç‡   : {gpu_efficiency:.1f}%")
        
        # å…¨ä½“åŠ¹ç‡
        processing_ratio = (processing_time / total_time) * 100
        print(f"   å‡¦ç†æ™‚é–“æ¯”ç‡  : {processing_ratio:.1f}%")
    
    print("=" * 80)

def run_comparison_with_traditional():
    """å¾“æ¥ç‰ˆã¨ã®è©³ç´°æ¯”è¼ƒ"""
    
    print("\n" + "ğŸ”¥" * 20 + " ç©¶æ¥µ vs å¾“æ¥ æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ " + "ğŸ”¥" * 20)
    
    # 1. å¾“æ¥ç‰ˆå®Ÿè¡Œ
    print("\n[1/2] ğŸ“Š å¾“æ¥ç‰ˆå®Ÿè¡Œä¸­...")
    traditional_start = time.time()
    
    try:
        from benchmark.benchmark_lineorder_5m import run_benchmark as run_traditional
        run_traditional()
        traditional_time = time.time() - traditional_start
        print(f"âœ… å¾“æ¥ç‰ˆå®Œäº†: {traditional_time:.4f}ç§’")
    except Exception as e:
        print(f"âŒ å¾“æ¥ç‰ˆã§ã‚¨ãƒ©ãƒ¼: {e}")
        traditional_time = None
    
    # 2. ç©¶æ¥µç‰ˆå®Ÿè¡Œ
    print("\n[2/2] ğŸš€ ç©¶æ¥µç‰ˆå®Ÿè¡Œä¸­...")
    ultimate_start = time.time()
    ultimate_result = run_ultimate_benchmark()
    ultimate_time = time.time() - ultimate_start
    
    if ultimate_result:
        print(f"âœ… ç©¶æ¥µç‰ˆå®Œäº†: {ultimate_time:.4f}ç§’")
    
    # 3. æ¯”è¼ƒçµæœ
    if traditional_time and ultimate_result:
        print("\n" + "ğŸ" * 30)
        print("ğŸ† æœ€çµ‚æ¯”è¼ƒçµæœ")
        print("ğŸ" * 30)
        print(f"å¾“æ¥ç‰ˆæ™‚é–“     : {traditional_time:8.4f} ç§’")
        print(f"ç©¶æ¥µç‰ˆæ™‚é–“     : {ultimate_time:8.4f} ç§’")
        
        if traditional_time > 0:
            speedup = traditional_time / ultimate_time
            improvement = ((traditional_time - ultimate_time) / traditional_time) * 100
            print(f"é«˜é€ŸåŒ–å€ç‡     : {speedup:8.2f}x")
            print(f"æ€§èƒ½å‘ä¸Š       : {improvement:8.1f}%")
            
            if speedup > 1:
                print("ğŸ‰ ç©¶æ¥µç‰ˆã®å‹åˆ©ï¼")
            else:
                print("ğŸ¤” è¦èª¿æŸ»...")
        
        print("ğŸ" * 30)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    parser = argparse.ArgumentParser(description='ç©¶æ¥µã®cuDF ZeroCopyãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯')
    parser.add_argument('--rows', type=int, default=1000000, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    parser.add_argument('--compression', choices=['snappy', 'gzip', 'lz4', 'none'], 
                       default='snappy', help='åœ§ç¸®æ–¹å¼')
    parser.add_argument('--no-rmm', action='store_true', help='RMMã‚’ç„¡åŠ¹åŒ–')
    parser.add_argument('--no-gpu-opt', action='store_true', help='GPUæœ€é©åŒ–ã‚’ç„¡åŠ¹åŒ–')
    parser.add_argument('--compare', action='store_true', help='å¾“æ¥ç‰ˆã¨ã®æ¯”è¼ƒå®Ÿè¡Œ')
    parser.add_argument('--output', type=str, help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    # CUDAåˆæœŸåŒ–ç¢ºèª
    try:
        cuda.current_context()
        print("âœ… CUDA context åˆæœŸåŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        sys.exit(1)
    
    # å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰é¸æŠ
    if args.compare:
        run_comparison_with_traditional()
    else:
        result = run_ultimate_benchmark(
            limit_rows=args.rows,
            compression=args.compression,
            use_rmm=not args.no_rmm,
            optimize_gpu=not args.no_gpu_opt,
            output_path=args.output
        )
        
        if result:
            print(f"\nğŸ¯ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {result['output_path']}")
            print("ğŸ‰ ç©¶æ¥µãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†ï¼")
        else:
            print("âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¤±æ•—")
            sys.exit(1)

if __name__ == "__main__":
    main()