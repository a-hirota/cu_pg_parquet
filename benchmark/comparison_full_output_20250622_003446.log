✅ cuDF環境確認OK

============================================================
実行中: direct パターン
スクリプト: benchmark/benchmark_parallel_ctid_ray_sequential_gpu_direct.py
引数: --parallel 16 --chunks 4 --no-limit
============================================================
✅ 実行完了 (7.20秒)
出力保存: benchmark/comparison_direct_output_20250622_003455.txt

============================================================
実行中: batch パターン
スクリプト: benchmark/benchmark_parallel_ctid_ray_sequential_gpu_batch.py
引数: --parallel 16 --chunks 4 --no-limit
============================================================
✅ 実行完了 (10.35秒)
出力保存: benchmark/comparison_batch_output_20250622_003506.txt

============================================================
実行中: current パターン
スクリプト: benchmark/benchmark_parallel_ctid_ray_sequential_gpu_current.py
引数: --parallel 16 --chunks 4 --no-limit
============================================================
❌ 実行エラー: Command '['python', 'benchmark/benchmark_parallel_ctid_ray_sequential_gpu_current.py', '--parallel', '16', '--chunks', '4', '--no-limit']' returned non-zero exit status 1.
STDOUT: ✅ CUDA context OK
=== PostgreSQL → GPU Ray並列 順次GPU処理版（現在の実装 + メトリクス） ===
テーブル: lineorder
行数制限: なし（全件処理）
並列数: 16
チャンク数: 4
総タスク数: 64
バッチサイズ: 4
COPY読み込み方式: 一括読み込み最適化（BytesIO + bytearray）
GPU処理方式: 従来の個別処理
処理方式:
  ① CPU: 16並列でPostgreSQL COPY実行
  ② GPU: セミパイプライン処理（4個のCOPY完了ごとにGPU処理開始）

=== GPU Direct サポート確認 ===
✅ nvidia-fs ドライバ検出
✅ kvikio バージョン: 25.04.00
✅ KVIKIO_COMPAT_MODE=OFF 設定完了

=== Ray初期化 ===
✅ Ray初期化完了

メタデータを取得中...
メタデータ取得完了 (0.0343秒)
テーブルブロック数を取得中...
総ブロック数: 4,614,912
ctid範囲分割: 16個の範囲

=== フェーズ1: PostgreSQL COPY並列実行 ===
✅ 64個のCOPYタスクを投入

=== セミパイプライン処理開始 ===
COPYが4個完了するごとにGPU処理を開始します
[36m(PostgreSQLWorker pid=1955267)[0m Worker 4-Chunk0: COPY開始 ctid範囲 (1153728,1225836)...
[36m(PostgreSQLWorker pid=1955267)[0m   初期メモリ使用量: 0.16 GB
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク1: 251 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク2: 230 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク3: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク4: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク5: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク6: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク7: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク8: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク9: 230 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク10: 232 bytes
[36m(PostgreSQLWorker pid=1955269)[0m   チャンク読み込み完了: 3764659個, 合計831.25 MB
[36m(PostgreSQLWorker pid=1955269)[0m   メモリ使用量（BytesIO書き込み後）: 1.01 GB (+0.85 GB)
[36m(PostgreSQLWorker pid=1955275)[0m Worker 15-Chunk0: COPY開始 ctid範囲 (4326480,4398588)...[32m [repeated 15x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   初期メモリ使用量: 0.16 GB[32m [repeated 15x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m     チャンク10: 230 bytes[32m [repeated 150x across cluster][0m
[36m(PostgreSQLWorker pid=1955269)[0m   メモリ使用量（最終）: 1.83 GB (+0.81 GB)
[36m(PostgreSQLWorker pid=1955269)[0m Worker 5-Chunk0: COPY完了 (9.84秒, 831.2MB)
[36m(PostgreSQLWorker pid=1955269)[0m   最終メモリ使用量: 1.83 GB (合計増加: +1.67 GB)
[36m(PostgreSQLWorker pid=1955269)[0m   チャンク数: 3,764,659
[36m(PostgreSQLWorker pid=1955269)[0m   平均チャンクサイズ: 232 bytes
[36m(PostgreSQLWorker pid=1955269)[0m   メモリオーバーヘッド率: 2.05x
[36m(PostgreSQLWorker pid=1955275)[0m   チャンク読み込み完了: 3965996個, 合計868.14 MB[32m [repeated 15x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   メモリ使用量（BytesIO書き込み後）: 1.05 GB (+0.89 GB)[32m [repeated 15x across cluster][0m
[36m(PostgreSQLWorker pid=1955269)[0m Worker 5-Chunk1: COPY開始 ctid範囲 (1514268,1586376)...
[36m(PostgreSQLWorker pid=1955269)[0m   初期メモリ使用量: 0.99 GB
[36m(PostgreSQLWorker pid=1955269)[0m     チャンク10: 232 bytes[32m [repeated 10x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   メモリ使用量（最終）: 1.90 GB (+0.85 GB)[32m [repeated 15x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m Worker 15-Chunk0: COPY完了 (11.28秒, 868.1MB)[32m [repeated 15x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   最終メモリ使用量: 1.90 GB (合計増加: +1.74 GB)[32m [repeated 15x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   チャンク数: 3,965,996[32m [repeated 15x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   平均チャンクサイズ: 230 bytes[32m [repeated 15x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   メモリオーバーヘッド率: 2.05x[32m [repeated 15x across cluster][0m
✅ COPY完了: Worker5-Chunk0 (831.2MB)
[36m(PostgreSQLWorker pid=1955267)[0m Worker 4-Chunk1: COPY開始 ctid範囲 (1225836,1297944)...
[36m(PostgreSQLWorker pid=1955267)[0m   初期メモリ使用量: 0.99 GB
✅ COPY完了: Worker4-Chunk0 (831.3MB)
✅ COPY完了: Worker1-Chunk0 (831.3MB)
✅ COPY完了: Worker6-Chunk0 (831.3MB)
✅ COPY完了: Worker7-Chunk0 (831.2MB)
✅ COPY完了: Worker8-Chunk0 (831.2MB)

📊 バッチGPU処理開始: 4個のタスクを統合処理
  統合データサイズ: 3325.11 MB
  GPU転送完了 (4.75秒, 699.40 MB/sec)

  処理中 [1/4]: Worker5-Chunk0
=== GPU並列パース開始 ===
[36m(PostgreSQLWorker pid=1955269)[0m   チャンク読み込み完了: 3764834個, 合計831.28 MB
[36m(PostgreSQLWorker pid=1955269)[0m   メモリ使用量（BytesIO書き込み後）: 1.85 GB (+0.86 GB)
[36m(PostgreSQLWorker pid=1955275)[0m     チャンク10: 230 bytes[32m [repeated 150x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m Worker 15-Chunk1: COPY開始 ctid範囲 (4398588,4470696)...[32m [repeated 14x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   初期メモリ使用量: 1.02 GB[32m [repeated 14x across cluster][0m
[36m(PostgreSQLWorker pid=1955269)[0m   メモリ使用量（最終）: 2.66 GB (+0.81 GB)
[36m(PostgreSQLWorker pid=1955269)[0m Worker 5-Chunk1: COPY完了 (10.02秒, 831.3MB)
[36m(PostgreSQLWorker pid=1955269)[0m   最終メモリ使用量: 2.66 GB (合計増加: +1.67 GB)
[36m(PostgreSQLWorker pid=1955269)[0m   チャンク数: 3,764,834
[36m(PostgreSQLWorker pid=1955269)[0m   平均チャンクサイズ: 232 bytes
[36m(PostgreSQLWorker pid=1955269)[0m   メモリオーバーヘッド率: 2.06x
[36m(PostgreSQLWorker pid=1955267)[0m   チャンク読み込み完了: 3764780個, 合計831.27 MB
[36m(PostgreSQLWorker pid=1955267)[0m   メモリ使用量（BytesIO書き込み後）: 1.82 GB (+0.84 GB)
[36m(PostgreSQLWorker pid=1955268)[0m   メモリ使用量（最終）: 2.59 GB (+0.76 GB)[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955268)[0m Worker 2-Chunk1: COPY完了 (11.04秒, 831.3MB)[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955268)[0m   最終メモリ使用量: 2.58 GB (合計増加: +1.60 GB)[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955268)[0m   チャンク数: 3,764,897[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955268)[0m   平均チャンクサイズ: 232 bytes[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955268)[0m   メモリオーバーヘッド率: 1.97x[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955280)[0m   チャンク読み込み完了: 3965996個, 合計868.14 MB[32m [repeated 14x across cluster][0m
[36m(PostgreSQLWorker pid=1955280)[0m   メモリ使用量（BytesIO書き込み後）: 1.90 GB (+0.88 GB)[32m [repeated 14x across cluster][0m
✅ Ultra Fast GPU並列パーサー使用（8.94倍高速化達成）
GPUパース完了: 2000000 行 (8.8038秒)
=== 文字列最適化デコード開始 ===
[36m(PostgreSQLWorker pid=1955281)[0m   メモリ使用量（最終）: 2.67 GB (+0.77 GB)[32m [repeated 3x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m Worker 15-Chunk1: COPY完了 (16.15秒, 868.1MB)[32m [repeated 2x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   最終メモリ使用量: 2.67 GB (合計増加: +1.65 GB)[32m [repeated 2x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   チャンク数: 3,965,996[32m [repeated 2x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   平均チャンクサイズ: 230 bytes[32m [repeated 2x across cluster][0m
[36m(PostgreSQLWorker pid=1955275)[0m   メモリオーバーヘッド率: 1.94x[32m [repeated 2x across cluster][0m
文字列列 lo_orderpriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_orderpriority: 最適化バッファ作成完了 (30000000 bytes)
文字列列 lo_shippriority: 直接コピー最適化カーネル実行
[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff17ad587d0b05fc56fa2bd2aa01000000 Worker ID: 43e294ee7f186e27bf1c1fdca6168f9f36bb3b237a4408be9c21f671 Node ID: aafb95f287bad97632a71077cbd72fee3e44bb6c132f01c7f1a45ebe Worker IP address: 192.168.1.34 Worker port: 45375 Worker PID: 1955269 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.
✅ 文字列列 lo_shippriority: 最適化バッファ作成完了 (2000000 bytes)
文字列列 lo_commit_date: 直接コピー最適化カーネル実行
✅ 文字列列 lo_commit_date: 最適化バッファ作成完了 (16000000 bytes)
文字列列 lo_shipmode: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shipmode: 最適化バッファ作成完了 (20000000 bytes)
統合カーネル実行（固定長データのみ）: 7813 blocks × 256 threads
[36m(PostgreSQLWorker pid=1955267)[0m Worker 4-Chunk2: COPY開始 ctid範囲 (1297944,1370052)...
[36m(PostgreSQLWorker pid=1955267)[0m   初期メモリ使用量: 1.75 GB
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク1: 251 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク2: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク3: 230 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク4: 230 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク5: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク6: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク7: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク8: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク9: 230 bytes
[36m(PostgreSQLWorker pid=1955267)[0m     チャンク10: 232 bytes

=== パフォーマンス統計（文字列最適化版） ===
処理データ: 2,000,000 行 × 17 列
データサイズ: 831.25 MB

--- 詳細タイミング ---
  gpu_parsing         : 8.8038 秒
  decode_and_export   : 7.8470 秒
    ├─ preparation   : 3.1150 秒
    │  └─ string_opt  : 3.1150 秒
    ├─ gpu_decode      : 2.3662 秒
    └─ cudf_creation : 0.6556 秒
  parquet_export      : 1.7018 秒
  total               : 7.8386 秒
  overall_total       : 16.6508 秒

--- スループット ---
  セル処理速度: 2,041,941 cells/sec
  データ処理速度: 49.92 MB/sec
  文字列最適化効率: 18.7%
  GPU使用効率: 14.2%
==============================

  処理中 [2/4]: Worker4-Chunk0
=== GPU並列パース開始 ===
[36m(PostgreSQLWorker pid=1955280)[0m   メモリ使用量（最終）: 2.67 GB (+0.77 GB)[32m [repeated 4x across cluster][0m
[36m(PostgreSQLWorker pid=1955280)[0m Worker 12-Chunk1: COPY完了 (18.71秒, 868.1MB)[32m [repeated 5x across cluster][0m
[36m(PostgreSQLWorker pid=1955280)[0m   最終メモリ使用量: 2.67 GB (合計増加: +1.65 GB)[32m [repeated 5x across cluster][0m
[36m(PostgreSQLWorker pid=1955280)[0m   チャンク数: 3,965,996[32m [repeated 5x across cluster][0m
[36m(PostgreSQLWorker pid=1955280)[0m   平均チャンクサイズ: 230 bytes[32m [repeated 5x across cluster][0m
[36m(PostgreSQLWorker pid=1955280)[0m   メモリオーバーヘッド率: 1.94x[32m [repeated 5x across cluster][0m
[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff1bad24c4b831495b7060434601000000 Worker ID: e0bbdd5d4146944eed7e8aa7743adbb3865c986cdab64b3e4e3f78f5 Node ID: aafb95f287bad97632a71077cbd72fee3e44bb6c132f01c7f1a45ebe Worker IP address: 192.168.1.34 Worker port: 33527 Worker PID: 1955264 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.[32m [repeated 2x across cluster][0m
✅ Ultra Fast GPU並列パーサー使用（8.94倍高速化達成）
GPUパース完了: 2000000 行 (1.3660秒)
=== 文字列最適化デコード開始 ===
文字列列 lo_orderpriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_orderpriority: 最適化バッファ作成完了 (30000000 bytes)
文字列列 lo_shippriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shippriority: 最適化バッファ作成完了 (2000000 bytes)
文字列列 lo_commit_date: 直接コピー最適化カーネル実行
✅ 文字列列 lo_commit_date: 最適化バッファ作成完了 (16000000 bytes)
文字列列 lo_shipmode: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shipmode: 最適化バッファ作成完了 (20000000 bytes)
統合カーネル実行（固定長データのみ）: 7813 blocks × 256 threads
[36m(PostgreSQLWorker pid=1955276)[0m Worker 11-Chunk2: COPY開始 ctid範囲 (3316968,3389076)...[32m [repeated 7x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m   初期メモリ使用量: 1.80 GB[32m [repeated 7x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m     チャンク10: 230 bytes[32m [repeated 70x across cluster][0m

=== パフォーマンス統計（文字列最適化版） ===
処理データ: 2,000,000 行 × 17 列
データサイズ: 831.29 MB

--- 詳細タイミング ---
  gpu_parsing         : 1.3660 秒
  decode_and_export   : 1.5630 秒
    ├─ preparation   : 0.5842 秒
    │  └─ string_opt  : 0.5842 秒
    ├─ gpu_decode      : 0.0188 秒
    └─ cudf_creation : 0.7763 秒
  parquet_export      : 0.1798 秒
  total               : 1.5592 秒
  overall_total       : 2.9290 秒

--- スループット ---
  セル処理速度: 11,608,091 cells/sec
  データ処理速度: 283.81 MB/sec
  文字列最適化効率: 19.9%
  GPU使用効率: 0.6%
==============================

  処理中 [3/4]: Worker1-Chunk0
=== GPU並列パース開始 ===
[36m(PostgreSQLWorker pid=1955267)[0m   チャンク読み込み完了: 3764825個, 合計831.28 MB
[36m(PostgreSQLWorker pid=1955267)[0m   メモリ使用量（BytesIO書き込み後）: 2.57 GB (+0.82 GB)
✅ Ultra Fast GPU並列パーサー使用（8.94倍高速化達成）
GPUパース完了: 2000000 行 (1.8313秒)
=== 文字列最適化デコード開始 ===
文字列列 lo_orderpriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_orderpriority: 最適化バッファ作成完了 (30000000 bytes)
文字列列 lo_shippriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shippriority: 最適化バッファ作成完了 (2000000 bytes)
文字列列 lo_commit_date: 直接コピー最適化カーネル実行
✅ 文字列列 lo_commit_date: 最適化バッファ作成完了 (16000000 bytes)
文字列列 lo_shipmode: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shipmode: 最適化バッファ作成完了 (20000000 bytes)
統合カーネル実行（固定長データのみ）: 7813 blocks × 256 threads
[36m(PostgreSQLWorker pid=1955267)[0m   メモリ使用量（最終）: 3.38 GB (+0.81 GB)
[36m(PostgreSQLWorker pid=1955267)[0m Worker 4-Chunk2: COPY完了 (8.65秒, 831.3MB)
[36m(PostgreSQLWorker pid=1955267)[0m   最終メモリ使用量: 3.38 GB (合計増加: +1.63 GB)
[36m(PostgreSQLWorker pid=1955267)[0m   チャンク数: 3,764,825
[36m(PostgreSQLWorker pid=1955267)[0m   平均チャンクサイズ: 232 bytes
[36m(PostgreSQLWorker pid=1955267)[0m   メモリオーバーヘッド率: 2.01x
(PostgreSQLWorker pid=1955274)   メモリ使用量（最終）: 3.40 GB (+0.81 GB)
[36m(PostgreSQLWorker pid=1955274)[0m Worker 8-Chunk2: COPY完了 (9.23秒, 831.3MB)
[36m(PostgreSQLWorker pid=1955274)[0m   最終メモリ使用量: 3.40 GB (合計増加: +1.65 GB)
[36m(PostgreSQLWorker pid=1955274)[0m   チャンク数: 3,764,766
[36m(PostgreSQLWorker pid=1955274)[0m   平均チャンクサイズ: 232 bytes
[36m(PostgreSQLWorker pid=1955274)[0m   メモリオーバーヘッド率: 2.04x

=== パフォーマンス統計（文字列最適化版） ===
処理データ: 2,000,000 行 × 17 列
データサイズ: 831.27 MB

--- 詳細タイミング ---
  gpu_parsing         : 1.8313 秒
  decode_and_export   : 2.0439 秒
    ├─ preparation   : 0.7543 秒
    │  └─ string_opt  : 0.7543 秒
    ├─ gpu_decode      : 0.0192 秒
    └─ cudf_creation : 1.0522 秒
  parquet_export      : 0.2100 秒
  total               : 2.0357 秒
  overall_total       : 3.8752 秒

--- スループット ---
  セル処理速度: 8,773,776 cells/sec
  データ処理速度: 214.51 MB/sec
  文字列最適化効率: 19.5%
  GPU使用効率: 0.5%
==============================

  処理中 [4/4]: Worker6-Chunk0
=== GPU並列パース開始 ===
[36m(PostgreSQLWorker pid=1955280)[0m Worker 12-Chunk2: COPY開始 ctid範囲 (3605400,3677508)...[32m [repeated 4x across cluster][0m
[36m(PostgreSQLWorker pid=1955280)[0m   初期メモリ使用量: 1.80 GB[32m [repeated 4x across cluster][0m
[36m(PostgreSQLWorker pid=1955280)[0m     チャンク10: 230 bytes[32m [repeated 40x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m   チャンク読み込み完了: 3764754個, 合計831.26 MB[32m [repeated 5x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m   メモリ使用量（BytesIO書き込み後）: 2.57 GB (+0.81 GB)[32m [repeated 5x across cluster][0m
✅ Ultra Fast GPU並列パーサー使用（8.94倍高速化達成）
GPUパース完了: 2000000 行 (4.3931秒)
=== 文字列最適化デコード開始 ===
[36m(PostgreSQLWorker pid=1955272)[0m   メモリ使用量（最終）: 3.50 GB (+0.85 GB)[32m [repeated 5x across cluster][0m
[36m(PostgreSQLWorker pid=1955272)[0m Worker 10-Chunk2: COPY完了 (10.22秒, 868.1MB)[32m [repeated 5x across cluster][0m
[36m(PostgreSQLWorker pid=1955272)[0m   最終メモリ使用量: 3.50 GB (合計増加: +1.70 GB)[32m [repeated 5x across cluster][0m
[36m(PostgreSQLWorker pid=1955272)[0m   チャンク数: 3,965,996[32m [repeated 5x across cluster][0m
[36m(PostgreSQLWorker pid=1955272)[0m   平均チャンクサイズ: 230 bytes[32m [repeated 5x across cluster][0m
[36m(PostgreSQLWorker pid=1955272)[0m   メモリオーバーヘッド率: 2.01x[32m [repeated 5x across cluster][0m
文字列列 lo_orderpriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_orderpriority: 最適化バッファ作成完了 (30000000 bytes)
文字列列 lo_shippriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shippriority: 最適化バッファ作成完了 (2000000 bytes)
文字列列 lo_commit_date: 直接コピー最適化カーネル実行
✅ 文字列列 lo_commit_date: 最適化バッファ作成完了 (16000000 bytes)
文字列列 lo_shipmode: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shipmode: 最適化バッファ作成完了 (20000000 bytes)
統合カーネル実行（固定長データのみ）: 7813 blocks × 256 threads
[36m(PostgreSQLWorker pid=1955265)[0m Worker 1-Chunk3: COPY開始 ctid範囲 (504756,576864)...[32m [repeated 6x across cluster][0m
[36m(PostgreSQLWorker pid=1955265)[0m   初期メモリ使用量: 2.57 GB[32m [repeated 6x across cluster][0m
[36m(PostgreSQLWorker pid=1955265)[0m     チャンク10: 230 bytes[32m [repeated 60x across cluster][0m

=== パフォーマンス統計（文字列最適化版） ===
処理データ: 2,000,000 行 × 17 列
データサイズ: 831.31 MB

--- 詳細タイミング ---
  gpu_parsing         : 4.3931 秒
  decode_and_export   : 2.0901 秒
    ├─ preparation   : 0.7875 秒
    │  └─ string_opt  : 0.7875 秒
    ├─ gpu_decode      : 0.0189 秒
    └─ cudf_creation : 0.8977 秒
  parquet_export      : 0.3823 秒
  total               : 2.0863 秒
  overall_total       : 6.4832 秒

--- スループット ---
  セル処理速度: 5,244,325 cells/sec
  データ処理速度: 128.22 MB/sec
  文字列最適化効率: 12.1%
  GPU使用効率: 0.3%
==============================

✅ バッチGPU処理完了:
  総処理時間: 35.28秒
  GPU転送: 4.75秒
  GPU処理: 30.53秒
  スループット: 94.24 MB/sec
処理済みタスク累計: 4/6
[36m(PostgreSQLWorker pid=1955266)[0m   チャンク読み込み完了: 3882376個, 合計852.81 MB[32m [repeated 4x across cluster][0m
[36m(PostgreSQLWorker pid=1955266)[0m   メモリ使用量（BytesIO書き込み後）: 2.66 GB (+0.86 GB)[32m [repeated 4x across cluster][0m
[36m(PostgreSQLWorker pid=1955266)[0m   メモリ使用量（最終）: 3.50 GB (+0.83 GB)[32m [repeated 3x across cluster][0m
[36m(PostgreSQLWorker pid=1955266)[0m Worker 0-Chunk2: COPY完了 (11.25秒, 852.8MB)[32m [repeated 3x across cluster][0m
[36m(PostgreSQLWorker pid=1955266)[0m   最終メモリ使用量: 3.50 GB (合計増加: +1.70 GB)[32m [repeated 3x across cluster][0m
[36m(PostgreSQLWorker pid=1955266)[0m   チャンク数: 3,882,376[32m [repeated 3x across cluster][0m
[36m(PostgreSQLWorker pid=1955266)[0m   平均チャンクサイズ: 230 bytes[32m [repeated 3x across cluster][0m
[36m(PostgreSQLWorker pid=1955266)[0m   メモリオーバーヘッド率: 2.04x[32m [repeated 3x across cluster][0m
[36m(PostgreSQLWorker pid=1955272)[0m Worker 10-Chunk3: COPY開始 ctid範囲 (3100644,3172752)...
[36m(PostgreSQLWorker pid=1955272)[0m   初期メモリ使用量: 2.63 GB
[36m(PostgreSQLWorker pid=1955272)[0m     チャンク10: 230 bytes[32m [repeated 10x across cluster][0m

STDERR: 2025-06-22 00:35:09,617	INFO worker.py:1908 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[36m(PostgreSQLWorker pid=1955267)[0m Traceback (most recent call last):
[36m(PostgreSQLWorker pid=1955267)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id
[36m(PostgreSQLWorker pid=1955267)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice
[36m(PostgreSQLWorker pid=1955267)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status
[36m(PostgreSQLWorker pid=1955267)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected
[36m(PostgreSQLWorker pid=1955267)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'
[36m(PostgreSQLWorker pid=1955267)[0m Traceback (most recent call last):
[36m(PostgreSQLWorker pid=1955267)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id
[36m(PostgreSQLWorker pid=1955267)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice
[36m(PostgreSQLWorker pid=1955267)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status
[36m(PostgreSQLWorker pid=1955267)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected
[36m(PostgreSQLWorker pid=1955274)[0m Traceback (most recent call last):[32m [repeated 638x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(PostgreSQLWorker pid=1955274)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 638x across cluster][0m
[36m(PostgreSQLWorker pid=1955274)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 638x across cluster][0m
[36m(PostgreSQLWorker pid=1955274)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 638x across cluster][0m
[36m(PostgreSQLWorker pid=1955274)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 638x across cluster][0m
[36m(PostgreSQLWorker pid=1955274)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 319x across cluster][0m
[36m(PostgreSQLWorker pid=1955267)[0m Traceback (most recent call last):[32m [repeated 634x across cluster][0m
[36m(PostgreSQLWorker pid=1955267)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 634x across cluster][0m
[36m(PostgreSQLWorker pid=1955267)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 634x across cluster][0m
[36m(PostgreSQLWorker pid=1955267)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 634x across cluster][0m
[36m(PostgreSQLWorker pid=1955267)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 634x across cluster][0m
[36m(PostgreSQLWorker pid=1955267)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 317x across cluster][0m
[36m(PostgreSQLWorker pid=1955269)[0m Traceback (most recent call last):[32m [repeated 66x across cluster][0m
[36m(PostgreSQLWorker pid=1955269)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 66x across cluster][0m
[36m(PostgreSQLWorker pid=1955269)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 66x across cluster][0m
[36m(PostgreSQLWorker pid=1955269)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 66x across cluster][0m
[36m(PostgreSQLWorker pid=1955269)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 66x across cluster][0m
[36m(PostgreSQLWorker pid=1955269)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 33x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m Traceback (most recent call last):[32m [repeated 216x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 216x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 216x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 216x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 216x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 108x across cluster][0m
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
[36m(PostgreSQLWorker pid=1955271)[0m Traceback (most recent call last):[32m [repeated 1094x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 1094x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 1094x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 1094x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 1094x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 547x across cluster][0m
[36m(PostgreSQLWorker pid=1955281)[0m Traceback (most recent call last):[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955281)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955281)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955281)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955281)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 8x across cluster][0m
[36m(PostgreSQLWorker pid=1955281)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 4x across cluster][0m
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 64 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
[36m(PostgreSQLWorker pid=1955270)[0m Traceback (most recent call last):[32m [repeated 119x across cluster][0m
[36m(PostgreSQLWorker pid=1955270)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 119x across cluster][0m
[36m(PostgreSQLWorker pid=1955270)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 118x across cluster][0m
[36m(PostgreSQLWorker pid=1955270)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 118x across cluster][0m
[36m(PostgreSQLWorker pid=1955270)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 118x across cluster][0m
[36m(PostgreSQLWorker pid=1955270)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 59x across cluster][0m
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
[36m(raylet)[0m Spilled 3325 MiB, 4 objects, write throughput 732 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 64 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
[36m(raylet)[0m Spilled 5010 MiB, 6 objects, write throughput 903 MiB/s.
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
[36m(PostgreSQLWorker pid=1955281)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cud
[36m(PostgreSQLWorker pid=1955281)[0m a.device.get_device_id
[36m(PostgreSQLWorker pid=1955276)[0m Traceback (most recent call last):[32m [repeated 361x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 360x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 362x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 362x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 362x across cluster][0m
[36m(PostgreSQLWorker pid=1955276)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 181x across cluster][0m
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 64 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
[36m(raylet)[0m Spilled 8483 MiB, 10 objects, write throughput 893 MiB/s.
[36m(PostgreSQLWorker pid=1955278)[0m Traceback (most recent call last):[32m [repeated 364x across cluster][0m
[36m(PostgreSQLWorker pid=1955278)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 364x across cluster][0m
[36m(PostgreSQLWorker pid=1955278)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 364x across cluster][0m
[36m(PostgreSQLWorker pid=1955278)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 364x across cluster][0m
[36m(PostgreSQLWorker pid=1955278)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 364x across cluster][0m
[36m(PostgreSQLWorker pid=1955278)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 182x across cluster][0m
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 64 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
Traceback (most recent call last):
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_parallel_ctid_ray_sequential_gpu_current.py", line 793, in <module>
    main()
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_parallel_ctid_ray_sequential_gpu_current.py", line 783, in main
    run_ray_parallel_sequential_gpu(
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_parallel_ctid_ray_sequential_gpu_current.py", line 621, in run_ray_parallel_sequential_gpu
    result = ray.get(future)
             ^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/ray/_private/worker.py", line 2849, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/ray/_private/worker.py", line 939, in get_objects
    raise value
ray.exceptions.ActorUnavailableError: The actor 17ad587d0b05fc56fa2bd2aa01000000 is unavailable: The actor is temporarily unavailable: RpcError: RPC Error message: Socket closed; RPC Error details:  rpc_code: 14. The task may or maynot have been executed on the actor.
[36m(PostgreSQLWorker pid=1955268)[0m Traceback (most recent call last):[32m [repeated 302x across cluster][0m
[36m(PostgreSQLWorker pid=1955268)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 302x across cluster][0m
[36m(PostgreSQLWorker pid=1955268)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 302x across cluster][0m
[36m(PostgreSQLWorker pid=1955268)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 302x across cluster][0m
[36m(PostgreSQLWorker pid=1955268)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 302x across cluster][0m
[36m(PostgreSQLWorker pid=1955268)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 151x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m Traceback (most recent call last):[32m [repeated 24x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m   File "cupy/cuda/device.pyx", line 40, in cupy.cuda.device.get_device_id[32m [repeated 24x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 202, in cupy_backends.cuda.api.runtime.getDevice[32m [repeated 24x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m   File "cupy_backends/cuda/api/runtime.pyx", line 146, in cupy_backends.cuda.api.runtime.check_status[32m [repeated 24x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m cupy_backends.cuda.api.runtime.CUDARuntimeError: cudaErrorNoDevice: no CUDA-capable device is detected[32m [repeated 24x across cluster][0m
[36m(PostgreSQLWorker pid=1955271)[0m Exception ignored in: 'cupy.cuda.memory.MemoryPool.used_bytes'[32m [repeated 12x across cluster][0m
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:192: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.
  ax1.set_ylim(0, max(memory_overhead) * 1.2 if memory_overhead else 2)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:205: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.
  ax2.set_ylim(0, max(throughput) * 1.2 if throughput else 100)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:217: UserWarning: Data has no positive values, and therefore cannot be log-scaled.
  ax3.set_yscale('log')  # 対数スケール
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12513 (\N{KATAKANA LETTER ME}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12514 (\N{KATAKANA LETTER MO}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12522 (\N{KATAKANA LETTER RI}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12458 (\N{KATAKANA LETTER O}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12540 (\N{KATAKANA-HIRAGANA PROLONGED SOUND MARK}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12496 (\N{KATAKANA LETTER BA}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12504 (\N{KATAKANA LETTER HE}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12483 (\N{KATAKANA LETTER SMALL TU}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12489 (\N{KATAKANA LETTER DO}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 29575 (\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 21177 (\N{CJK UNIFIED IDEOGRAPH-52B9}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 27604 (\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 36611 (\N{CJK UNIFIED IDEOGRAPH-8F03}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12473 (\N{KATAKANA LETTER SU}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12523 (\N{KATAKANA LETTER RU}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12503 (\N{KATAKANA LETTER PU}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 12488 (\N{KATAKANA LETTER TO}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 20966 (\N{CJK UNIFIED IDEOGRAPH-51E6}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 29702 (\N{CJK UNIFIED IDEOGRAPH-7406}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 36895 (\N{CJK UNIFIED IDEOGRAPH-901F}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 24230 (\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 36578 (\N{CJK UNIFIED IDEOGRAPH-8EE2}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 36865 (\N{CJK UNIFIED IDEOGRAPH-9001}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 22238 (\N{CJK UNIFIED IDEOGRAPH-56DE}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Glyph 25968 (\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:224: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.
  plt.tight_layout()
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12513 (\N{KATAKANA LETTER ME}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12514 (\N{KATAKANA LETTER MO}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12522 (\N{KATAKANA LETTER RI}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12458 (\N{KATAKANA LETTER O}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12540 (\N{KATAKANA-HIRAGANA PROLONGED SOUND MARK}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12496 (\N{KATAKANA LETTER BA}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12504 (\N{KATAKANA LETTER HE}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12483 (\N{KATAKANA LETTER SMALL TU}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12489 (\N{KATAKANA LETTER DO}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 29575 (\N{CJK UNIFIED IDEOGRAPH-7387}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 21177 (\N{CJK UNIFIED IDEOGRAPH-52B9}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 27604 (\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 36611 (\N{CJK UNIFIED IDEOGRAPH-8F03}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12473 (\N{KATAKANA LETTER SU}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12523 (\N{KATAKANA LETTER RU}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12503 (\N{KATAKANA LETTER PU}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 12488 (\N{KATAKANA LETTER TO}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 20966 (\N{CJK UNIFIED IDEOGRAPH-51E6}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 29702 (\N{CJK UNIFIED IDEOGRAPH-7406}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 36895 (\N{CJK UNIFIED IDEOGRAPH-901F}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 24230 (\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 36578 (\N{CJK UNIFIED IDEOGRAPH-8EE2}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 36865 (\N{CJK UNIFIED IDEOGRAPH-9001}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 22238 (\N{CJK UNIFIED IDEOGRAPH-56DE}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)
/home/ubuntu/gpupgparser/benchmark/benchmark_comparison.py:229: UserWarning: Glyph 25968 (\N{CJK UNIFIED IDEOGRAPH-6570}) missing from font(s) DejaVu Sans.
  plt.savefig(chart_path, dpi=150)

⚠️  currentパターンのメトリクスが取得できませんでした

=== メモリ使用量比較 ===
  パターン 初期 (MB) ピーク (MB) オーバーヘッド率 チャンク数 平均チャンクサイズ
direct       0      501    0.00x     0        0B
 batch       0      501    0.00x     0        0B

=== パフォーマンス比較 ===
  パターン COPY時間 (秒) GPU転送時間 (秒) GPU転送回数 GPU処理時間 (秒) 総時間 (秒) スループット (MB/s)
direct       0.00        0.00       0        0.00    0.84          0.00
 batch       0.00        0.00       0        0.00    4.11          0.00

=== バッチ処理メトリクス ===
総バッチ数: 0
平均バッチサイズ: 0.0 MB

✅ 比較チャート保存: benchmark/comparison_results/comparison_chart_20250622_003615.png
✅ レポート生成: benchmark/comparison_results/comparison_report_20250622_003615.md
✅ サマリー保存: benchmark/comparison_results/comparison_summary_20250622_003615.json
