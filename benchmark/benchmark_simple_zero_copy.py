"""
ã‚·ãƒ³ãƒ—ãƒ«ãªcuDF ZeroCopyçµ±åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

å¾“æ¥ç‰ˆãƒ‘ãƒ¼ã‚µãƒ¼ + cuDFã‚¼ãƒ­ã‚³ãƒ”ãƒ¼å¤‰æ› + GPUç›´æ¥Parquetæ›¸ãå‡ºã—
è¤‡é›‘ãªä¸¦åˆ—åŒ–ãªã—ã§ã€ZeroCopyã®æ ¸å¿ƒä¾¡å€¤ã‚’å®Ÿç¾
"""

import os
import sys
import time
import warnings
import numpy as np
import cudf
import psycopg
from numba import cuda

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from src.metadata import get_postgresql_table_metadata
from src.binary_parser import parse_binary_chunk_gpu, detect_pg_header_size
from src.cudf_zero_copy_processor import CuDFZeroCopyProcessor

def run_simple_zero_copy_benchmark(
    table_name: str = "lineorder",
    limit: int = 1000000,
    compression: str = 'snappy',
    output_path: str = None
):
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãªZeroCopyãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    
    å¾“æ¥ç‰ˆãƒ‘ãƒ¼ã‚µãƒ¼ + ZeroCopyå¤‰æ›ã§ç¢ºå®Ÿãªå‹•ä½œã‚’å®Ÿç¾
    """
    
    print("=" * 80)
    print("ğŸš€ ã‚·ãƒ³ãƒ—ãƒ«cuDF ZeroCopyãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ğŸš€")
    print("=" * 80)
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«        : {table_name}")
    print(f"åˆ¶é™è¡Œæ•°        : {limit:,}")
    print(f"åœ§ç¸®æ–¹å¼        : {compression}")
    
    if output_path is None:
        import time
        timestamp = int(time.time())
        output_path = f"benchmark/{table_name}_simple_zero_copy_{compression}_{timestamp}.parquet"
    
    print(f"å‡ºåŠ›ãƒ‘ã‚¹        : {output_path}")
    print("-" * 80)
    
    # ã‚¿ã‚¤ãƒŸãƒ³ã‚°æƒ…å ±
    timing_info = {}
    overall_start = time.time()
    
    try:
        # CUDAåˆæœŸåŒ–ç¢ºèª
        cuda.current_context()
        print("âœ… CUDA context åˆæœŸåŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        return None
    
    # === 1. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾— ===
    print("ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
    meta_start = time.time()
    
    dsn = os.environ.get('GPUPASER_PG_DSN')
    if not dsn:
        raise ValueError("ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    try:
        conn = psycopg.connect(dsn)
        columns = get_postgresql_table_metadata(conn, table_name)
        conn.close()
    except Exception as e:
        print(f"âŒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    timing_info['metadata'] = time.time() - meta_start
    ncols = len(columns)
    decimal_cols = sum(1 for col in columns if col.arrow_id == 701)  # DECIMAL128
    
    print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({timing_info['metadata']:.4f}ç§’)")
    print(f"   åˆ—æ•°: {ncols}, Decimalåˆ—æ•°: {decimal_cols}")
    
    # === 2. COPY BINARYå®Ÿè¡Œ ===
    print("ğŸ“¥ COPY BINARYå®Ÿè¡Œä¸­...")
    copy_start = time.time()
    
    try:
        conn = psycopg.connect(dsn)
        with conn.cursor() as cur:
            copy_sql = f"COPY (SELECT * FROM {table_name} LIMIT {limit}) TO STDOUT WITH (FORMAT BINARY)"
            with cur.copy(copy_sql) as copy:
                raw_host_data = copy.read()
        conn.close()
        
        raw_host = np.frombuffer(raw_host_data, dtype=np.uint8)
        
    except Exception as e:
        print(f"âŒ COPY BINARY ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    timing_info['copy_binary'] = time.time() - copy_start
    data_size_mb = len(raw_host) / (1024 * 1024)
    
    print(f"âœ… COPY BINARYå®Œäº† ({timing_info['copy_binary']:.4f}ç§’)")
    print(f"   ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {data_size_mb:.2f} MB")
    
    # === 3. GPUè»¢é€ ===
    print("ğŸš€ GPUè»¢é€ä¸­...")
    transfer_start = time.time()
    
    raw_dev = cuda.to_device(raw_host)
    
    timing_info['gpu_transfer'] = time.time() - transfer_start
    print(f"âœ… GPUè»¢é€å®Œäº† ({timing_info['gpu_transfer']:.4f}ç§’)")
    
    # === 4. ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºæ¤œå‡º ===
    header_size = detect_pg_header_size(raw_host[:128])
    print(f"ğŸ“ ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º: {header_size} ãƒã‚¤ãƒˆ")
    
    # === 5. å¾“æ¥ç‰ˆGPUãƒ‘ãƒ¼ã‚¹ ===
    print("âš™ï¸ å¾“æ¥ç‰ˆGPUãƒ‘ãƒ¼ã‚¹å®Ÿè¡Œä¸­...")
    parse_start = time.time()
    
    try:
        field_offsets_dev, field_lengths_dev = parse_binary_chunk_gpu(
            raw_dev, ncols, threads_per_block=256, header_size=header_size
        )
        rows = field_offsets_dev.shape[0]
        
    except Exception as e:
        print(f"âŒ GPUãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    timing_info['gpu_parse'] = time.time() - parse_start
    print(f"âœ… å¾“æ¥ç‰ˆãƒ‘ãƒ¼ã‚¹å®Œäº† ({timing_info['gpu_parse']:.4f}ç§’)")
    print(f"   æ¤œå‡ºè¡Œæ•°: {rows:,}")
    
    # === 6. cuDF ZeroCopyå¤‰æ› + GPUç›´æ¥Parquetæ›¸ãå‡ºã— ===
    print("ğŸ”„ cuDF ZeroCopyå¤‰æ› + GPUç›´æ¥æ›¸ãå‡ºã—...")
    zero_copy_start = time.time()
    
    try:
        # ZeroCopyãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–
        cudf_processor = CuDFZeroCopyProcessor(use_rmm=True)
        
        # GPUçµ±åˆãƒ‡ã‚³ãƒ¼ãƒ‰ + cuDFå¤‰æ›
        cudf_df = cudf_processor.decode_and_create_cudf_zero_copy(
            raw_dev, field_offsets_dev, field_lengths_dev, columns
        )
        
        # GPUç›´æ¥Parquetæ›¸ãå‡ºã—
        try:
            cudf_df.to_parquet(
                output_path,
                compression=compression,
                engine='cudf'  # cuDFã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚‹ç›´æ¥æ›¸ãå‡ºã—
            )
            print("âœ… cuDFã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚‹ç›´æ¥æ›¸ãå‡ºã—æˆåŠŸ")
            
        except Exception as cudf_error:
            warnings.warn(f"cuDFç›´æ¥æ›¸ãå‡ºã—å¤±æ•—: {cudf_error}")
            print("ğŸ”„ PyArrowãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸­...")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: PyArrowçµŒç”±
            arrow_table = cudf_df.to_arrow()
            import pyarrow.parquet as pq
            pq.write_table(arrow_table, output_path, compression=compression)
            print("âœ… PyArrowãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ›¸ãå‡ºã—æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ ZeroCopyå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    
    timing_info['zero_copy_export'] = time.time() - zero_copy_start
    timing_info['total'] = time.time() - overall_start
    
    print(f"âœ… ZeroCopyå¤‰æ›+æ›¸ãå‡ºã—å®Œäº† ({timing_info['zero_copy_export']:.4f}ç§’)")
    
    # === 7. çµæœã‚µãƒãƒªãƒ¼ ===
    print("\n" + "=" * 80)
    print("ğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    
    print(f"ç·å®Ÿè¡Œæ™‚é–“: {timing_info['total']:.4f} ç§’")
    print("\n--- è©³ç´°ã‚¿ã‚¤ãƒŸãƒ³ã‚° ---")
    for key, value in timing_info.items():
        if key != 'total':
            percentage = (value / timing_info['total']) * 100
            print(f"  {key:20}: {value:8.4f} ç§’ ({percentage:5.1f}%)")
    
    # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—
    total_cells = rows * ncols
    cell_throughput = total_cells / timing_info['total']
    data_throughput = data_size_mb / timing_info['total']
    
    print(f"\n--- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ ---")
    print(f"  å‡¦ç†è¡Œæ•°        : {rows:,}")
    print(f"  å‡¦ç†åˆ—æ•°        : {ncols}")
    print(f"  ç·ã‚»ãƒ«æ•°        : {total_cells:,}")
    print(f"  ã‚»ãƒ«å‡¦ç†é€Ÿåº¦    : {cell_throughput:,.0f} cells/sec")
    print(f"  ãƒ‡ãƒ¼ã‚¿å‡¦ç†é€Ÿåº¦  : {data_throughput:.2f} MB/sec")
    
    # === 8. çµæœæ¤œè¨¼ ===
    print(f"\n--- çµæœæ¤œè¨¼ ---")
    try:
        verify_df = cudf.read_parquet(output_path)
        print(f"âœ… Parquetãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {len(verify_df):,} è¡Œ")
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª: cuDF DataFrame â†’ Parquet â†’ cuDF å®Œäº†")
        
        # DataFrameæƒ…å ±è¡¨ç¤º
        print(f"\n--- cuDF DataFrame Info ---")
        print(verify_df.info())
        
        print(f"\n--- cuDF DataFrame Head ---")
        print(verify_df.head())
        
    except Exception as e:
        print(f"âŒ çµæœæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
    
    return {
        'timing': timing_info,
        'rows': rows,
        'columns': ncols,
        'data_size_mb': data_size_mb,
        'throughput': {
            'cells_per_sec': cell_throughput,
            'mb_per_sec': data_throughput
        },
        'output_file': output_path
    }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    import argparse
    parser = argparse.ArgumentParser(description='ã‚·ãƒ³ãƒ—ãƒ«cuDF ZeroCopyãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯')
    parser.add_argument('--table', default='lineorder', help='ãƒ†ãƒ¼ãƒ–ãƒ«å')
    parser.add_argument('--rows', type=int, default=1000000, help='åˆ¶é™è¡Œæ•°')
    parser.add_argument('--compression', default='snappy', 
                       choices=['snappy', 'gzip', 'lz4', 'brotli', 'zstd'],
                       help='åœ§ç¸®æ–¹å¼')
    parser.add_argument('--output', help='å‡ºåŠ›Parquetãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    try:
        result = run_simple_zero_copy_benchmark(
            table_name=args.table,
            limit=args.rows,
            compression=args.compression,
            output_path=args.output
        )
        
        if result:
            print(f"\nğŸ‰ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æˆåŠŸå®Œäº†!")
            print(f"   ç·æ™‚é–“: {result['timing']['total']:.2f}ç§’")
            print(f"   ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {result['throughput']['cells_per_sec']:,.0f} cells/sec")
        else:
            print(f"\nâŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¤±æ•—")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print(f"\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()