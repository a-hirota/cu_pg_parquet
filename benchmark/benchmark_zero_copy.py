"""
PostgreSQL â†’ GPU ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ç‰ˆ
libpqã‹ã‚‰ä¸€ç™ºã§å…¨ãƒ‡ãƒ¼ã‚¿å—ã‘å–ã‚Š

æœ€é©åŒ–:
- io.BytesIOã®æ’é™¤ï¼ˆãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼å›é¿ï¼‰
- libpqã‹ã‚‰ä¸€æ‹¬èª­ã¿å–ã‚Š
- 22GB RMM ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«
- çœŸã®ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼å®Ÿè£…

ç’°å¢ƒå¤‰æ•°:
GPUPASER_PG_DSN  : PostgreSQLæ¥ç¶šæ–‡å­—åˆ—
"""

import os
import time
import ctypes
import psycopg
import rmm
import numpy as np
import numba
from numba import cuda
import cupy as cp
import argparse

from src.metadata import fetch_column_meta
from src.cuda_kernels.postgresql_binary_parser import detect_pg_header_size
from src.main_postgres_to_parquet import postgresql_to_cudf_parquet

TABLE_NAME = "lineorder"
OUTPUT_PARQUET_PATH = "benchmark/lineorder_zero_copy.output.parquet"

def run_bandwidth_test():
    """CUDA bandwidthTest ã§PCIeæ€§èƒ½ç¢ºèª"""
    print("\n=== PCIeå¸¯åŸŸå¹…ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        print("ã‚·ãƒ³ãƒ—ãƒ«å¸¯åŸŸæ¸¬å®šå®Ÿè¡Œä¸­...")
        size_mb = 1024  # 1GB
        host_data = np.random.randint(0, 256, size_mb * 1024 * 1024, dtype=np.uint8)
        
        # Host to Device
        start_time = time.time()
        device_data = cuda.to_device(host_data)
        htod_time = time.time() - start_time
        htod_speed = size_mb / htod_time
        
        # Device to Host  
        start_time = time.time()
        result_data = device_data.copy_to_host()
        dtoh_time = time.time() - start_time
        dtoh_speed = size_mb / dtoh_time
        
        print(f"Hostâ†’Device: {htod_speed:.2f} MB/s")
        print(f"Deviceâ†’Host: {dtoh_speed:.2f} MB/s")
        
    except Exception as e:
        print(f"å¸¯åŸŸæ¸¬å®šã‚¨ãƒ©ãƒ¼: {e}")

def run_zero_copy_benchmark(limit_rows=1000000):
    """ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - libpqä¸€æ‹¬å—ã‘å–ã‚Š"""
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    print(f"=== PostgreSQL â†’ GPU ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ç‰ˆ ===")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME}")
    print(f"è¡Œæ•°åˆ¶é™: {limit_rows:,}")
    print(f"æœ€é©åŒ–è¨­å®š:")
    print(f"  ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼: ã‚¼ãƒ­ (libpqä¸€æ‹¬å—ã‘å–ã‚Š)")
    print(f"  ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«: 22GB")
    
    # PCIeå¸¯åŸŸãƒ†ã‚¹ãƒˆ
    run_bandwidth_test()
    
    # RMM 22GBåˆæœŸåŒ–
    try:
        if not rmm.is_initialized():
            rmm.reinitialize(
                pool_allocator=True, 
                initial_pool_size=22*1024**3  # 22GB
            )
            print("âœ… RMM ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–å®Œäº† (22GB)")
    except Exception as e:
        print(f"âŒ RMMåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return

    start_total_time = time.time()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    conn = psycopg.connect(dsn)
    try:
        print("\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        start_meta_time = time.time()
        columns = fetch_column_meta(conn, f"SELECT * FROM {TABLE_NAME}")
        meta_time = time.time() - start_meta_time
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({meta_time:.4f}ç§’)")
        ncols = len(columns)

        # COPY BINARY â†’ ä¸€æ‹¬å—ã‘å–ã‚Š (ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼)
        print("COPY BINARY â†’ ä¸€æ‹¬å—ã‘å–ã‚Šå®Ÿè¡Œä¸­...")
        start_copy_time = time.time()
        
        copy_sql = f"COPY (SELECT * FROM {TABLE_NAME} LIMIT {limit_rows}) TO STDOUT (FORMAT binary)"
        
        print("  ğŸš€ libpqä¸€æ‹¬å—ã‘å–ã‚Šé–‹å§‹...")
        
        with conn.cursor() as cur:
            with cur.copy(copy_sql) as copy_obj:
                # ã€ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ã€‘å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸€æ‹¬ãƒªã‚¹ãƒˆåé›†
                chunks = list(copy_obj)
                
                print(f"  ğŸ“¦ å…¨ãƒãƒ£ãƒ³ã‚¯å—ä¿¡å®Œäº†: {len(chunks):,} ãƒãƒ£ãƒ³ã‚¯")
                
                # ã€ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ã€‘b''.join()ã§ä¸€æ‹¬çµåˆ
                print("  ğŸ”— ãƒãƒ£ãƒ³ã‚¯ä¸€æ‹¬çµåˆä¸­...")
                host_bytes = b''.join(chunks)
                
                # ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆè§£æ”¾
                del chunks

        copy_time = time.time() - start_copy_time
        actual_data_size = len(host_bytes)
        
        print(f"âœ… COPY BINARY â†’ ä¸€æ‹¬å—ã‘å–ã‚Šå®Œäº† ({copy_time:.4f}ç§’)")
        print(f"  å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {actual_data_size / (1024*1024):.2f} MB")
        print(f"  ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦: {actual_data_size / (1024*1024) / copy_time:.2f} MB/sec")

    finally:
        conn.close()

    # GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ & 1å›ã‚³ãƒ”ãƒ¼
    print("GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ & 1å›ã‚³ãƒ”ãƒ¼å®Ÿè¡Œä¸­...")
    start_gpu_time = time.time()
    
    try:
        # GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºï¼‰
        devbuf = rmm.DeviceBuffer(size=actual_data_size)
        print(f"  GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿å®Œäº†: {actual_data_size / (1024*1024):.2f} MB")
        
        # ã€ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ã€‘1å›ã®ã¿ã‚³ãƒ”ãƒ¼
        devbuf.copy_from_host(host_bytes)
        print(f"  âœ… GPU 1å›ã‚³ãƒ”ãƒ¼å®Œäº† (ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼)!")
        
        # ãƒ›ã‚¹ãƒˆãƒ¡ãƒ¢ãƒªè§£æ”¾
        del host_bytes
        
    except Exception as e:
        print(f"âŒ GPU ã‚³ãƒ”ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    gpu_time = time.time() - start_gpu_time
    gpu_throughput = actual_data_size / (1024*1024) / gpu_time
    print(f"GPUè»¢é€å®Œäº† ({gpu_time:.4f}ç§’), é€Ÿåº¦: {gpu_throughput:.2f} MB/sec")

    # numba GPU ã‚¢ãƒ¬ã‚¤ã«å¤‰æ›
    print("GPU ãƒãƒƒãƒ•ã‚¡ã‚’ numba GPU ã‚¢ãƒ¬ã‚¤ã«å¤‰æ›ä¸­...")
    raw_dev = cuda.as_cuda_array(devbuf).view(dtype=np.uint8)
    print(f"GPU ã‚¢ãƒ¬ã‚¤å¤‰æ›å®Œäº†: {raw_dev.shape[0]:,} bytes")

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºæ¤œå‡º
    header_sample = raw_dev[:min(128, raw_dev.shape[0])].copy_to_host()
    header_size = detect_pg_header_size(header_sample)
    print(f"ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º: {header_size} ãƒã‚¤ãƒˆ")

    # GPUæœ€é©åŒ–å‡¦ç†
    print("GPUæœ€é©åŒ–å‡¦ç†ä¸­...")
    start_processing_time = time.time()
    
    try:
        cudf_df, detailed_timing = postgresql_to_cudf_parquet(
            raw_dev=raw_dev,
            columns=columns,
            ncols=ncols,
            header_size=header_size,
            output_path=OUTPUT_PARQUET_PATH,
            compression='snappy',
            use_rmm=True,
            optimize_gpu=True
        )
        
        processing_time = time.time() - start_processing_time
        rows = len(cudf_df)
        parse_time = detailed_timing.get('gpu_parsing', 0)
        decode_time = detailed_timing.get('cudf_creation', 0)
        write_time = detailed_timing.get('parquet_export', 0)
        
        print(f"GPUæœ€é©åŒ–å‡¦ç†å®Œäº† ({processing_time:.4f}ç§’), è¡Œæ•°: {rows}")
        
    except Exception as e:
        print(f"GPUæœ€é©åŒ–å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
        return

    total_time = time.time() - start_total_time
    decimal_cols = sum(1 for col in columns if col.arrow_id == 5)
    
    print(f"\n=== ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº† ===")
    print(f"ç·æ™‚é–“ = {total_time:.4f} ç§’")
    print("--- æ™‚é–“å†…è¨³ ---")
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—       : {meta_time:.4f} ç§’")
    print(f"  COPYâ†’ä¸€æ‹¬å—ã‘å–ã‚Š   : {copy_time:.4f} ç§’")
    print(f"  ä¸€æ‹¬â†’GPUè»¢é€        : {gpu_time:.4f} ç§’")
    print(f"  GPUãƒ‘ãƒ¼ã‚¹           : {parse_time:.4f} ç§’")
    print(f"  GPUãƒ‡ã‚³ãƒ¼ãƒ‰         : {decode_time:.4f} ç§’")
    print(f"  Parquetæ›¸ãè¾¼ã¿     : {write_time:.4f} ç§’")
    print("--- çµ±è¨ˆæƒ…å ± ---")
    print(f"  å‡¦ç†è¡Œæ•°      : {rows:,} è¡Œ")
    print(f"  å‡¦ç†åˆ—æ•°      : {len(columns)} åˆ—")
    print(f"  Decimalåˆ—æ•°   : {decimal_cols} åˆ—")
    print(f"  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º  : {actual_data_size / (1024*1024):.2f} MB")
    
    total_cells = rows * len(columns)
    throughput = total_cells / decode_time if decode_time > 0 else 0
    network_throughput = actual_data_size / (1024*1024) / copy_time
    
    print(f"  ã‚»ãƒ«å‡¦ç†é€Ÿåº¦     : {throughput:,.0f} cells/sec")
    print(f"  ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦ : {network_throughput:.2f} MB/sec")
    print(f"  GPUè»¢é€é€Ÿåº¦     : {gpu_throughput:.2f} MB/sec")
    
    # PCIeåŠ¹ç‡è¨ˆç®—ï¼ˆå®Ÿæ¸¬11.9GB/såŸºæº–ï¼‰
    pcie_efficiency = network_throughput / 11900 * 100
    print(f"  PCIeåŠ¹ç‡        : {pcie_efficiency:.1f}% (å¯¾11.9GB/så®Ÿæ¸¬)")
    
    print("--- ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼æœ€é©åŒ–åŠ¹æœ ---")
    print("  âœ… ãƒ•ã‚¡ã‚¤ãƒ« I/O: å®Œå…¨ã‚¼ãƒ­")
    print("  âœ… ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼: æœ€å°åŒ– (libpqâ†’listâ†’join)")
    print("  âœ… io.BytesIO: æ’é™¤ (ãƒ¡ãƒ¢ãƒªã‚³ãƒ”ãƒ¼å›é¿)")
    print("  âœ… ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«: 22GB (ååˆ†ãªå®¹é‡)")
    print("  âœ… GPUè»¢é€: 1å›ã®ã¿ï¼ˆæœ€å°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ï¼‰")
    print("  âœ… çœŸã®ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼: æœ€å¤§åŠ¹ç‡åŒ–")
    
    # æ€§èƒ½è©•ä¾¡
    if network_throughput > 5000:
        print("  ğŸ† 5GB/sè¶…é”æˆï¼")
    elif network_throughput > 1000:
        print("  ğŸ¥‡ 1GB/sè¶…é”æˆï¼")
    elif network_throughput > 500:
        print("  ğŸ¥ˆ 500MB/sè¶…é”æˆï¼")
    elif network_throughput > 200:
        print("  ğŸ¥‰ 200MB/sè¶…é”æˆï¼")
    else:
        print("  âš ï¸  è»¢é€é€Ÿåº¦æ”¹å–„ã®ä½™åœ°ã‚ã‚Š")
    
    print("=========================================")

    # æ¤œè¨¼ç”¨å‡ºåŠ›
    print(f"\ncuDFæ¤œè¨¼ç”¨å‡ºåŠ›:")
    try:
        print(f"å‡ºåŠ›Parquet: {OUTPUT_PARQUET_PATH}")
        print(f"èª­ã¿è¾¼ã¿ç¢ºèª: {len(cudf_df):,} è¡Œ Ã— {len(cudf_df.columns)} åˆ—")
        print("å…ˆé ­ãƒ‡ãƒ¼ã‚¿å‹:")
        for i, (col_name, dtype) in enumerate(cudf_df.dtypes.items()):
            if i < 3:  # æœ€åˆã®3åˆ—ã®ã¿
                print(f"  {col_name}: {dtype}")
        print("âœ… cuDFæ¤œè¨¼: æˆåŠŸ")
    except Exception as e:
        print(f"âŒ cuDFæ¤œè¨¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='PostgreSQL â†’ GPU ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ç‰ˆ')
    parser.add_argument('--rows', type=int, default=1000000, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    parser.add_argument('--bandwidth-test', action='store_true', help='å¸¯åŸŸãƒ†ã‚¹ãƒˆã®ã¿')
    
    args = parser.parse_args()
    
    try:
        cuda.current_context()
        print("âœ… CUDA context OK")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        exit(1)
    
    if args.bandwidth_test:
        run_bandwidth_test()
        return
    
    run_zero_copy_benchmark(limit_rows=args.rows)

if __name__ == "__main__":
    main()