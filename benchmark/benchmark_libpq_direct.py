"""
PostgreSQL â†’ GPU libpqç›´æ¥ç‰ˆ
libpqã®å¤§å®¹é‡èª­ã¿è¾¼ã¿èƒ½åŠ›ã‚’æ´»ç”¨

æœ€é©åŒ–:
- libpqã®å†…éƒ¨ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°æ´»ç”¨
- ä½ãƒ¬ãƒ™ãƒ«APIã§ã®å¤§å®¹é‡èª­ã¿è¾¼ã¿
- ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚’æœ€å°åŒ–
- 22GB RMM ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«

ç’°å¢ƒå¤‰æ•°:
GPUPASER_PG_DSN  : PostgreSQLæ¥ç¶šæ–‡å­—åˆ—
"""

import os
import time
import psycopg
import rmm
import numpy as np
import numba
from numba import cuda
import cupy as cp
import argparse

from src.metadata import fetch_column_meta
from src.cuda_kernels.postgresql_binary_parser import detect_pg_header_size
from src.main_postgres_to_parquet import postgresql_to_cudf_parquet

TABLE_NAME = "lineorder"
OUTPUT_PARQUET_PATH = "benchmark/lineorder_libpq_direct.output.parquet"

def run_bandwidth_test():
    """CUDA bandwidthTest ã§PCIeæ€§èƒ½ç¢ºèª"""
    print("\n=== PCIeå¸¯åŸŸå¹…ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        print("ã‚·ãƒ³ãƒ—ãƒ«å¸¯åŸŸæ¸¬å®šå®Ÿè¡Œä¸­...")
        size_mb = 1024  # 1GB
        host_data = np.random.randint(0, 256, size_mb * 1024 * 1024, dtype=np.uint8)
        
        # Host to Device
        start_time = time.time()
        device_data = cuda.to_device(host_data)
        htod_time = time.time() - start_time
        htod_speed = size_mb / htod_time
        
        # Device to Host  
        start_time = time.time()
        result_data = device_data.copy_to_host()
        dtoh_time = time.time() - start_time
        dtoh_speed = size_mb / dtoh_time
        
        print(f"Hostâ†’Device: {htod_speed:.2f} MB/s")
        print(f"Deviceâ†’Host: {dtoh_speed:.2f} MB/s")
        
    except Exception as e:
        print(f"å¸¯åŸŸæ¸¬å®šã‚¨ãƒ©ãƒ¼: {e}")

def run_libpq_direct_benchmark(limit_rows=1000000):
    """libpqç›´æ¥ç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - å¤§å®¹é‡èª­ã¿è¾¼ã¿æ´»ç”¨"""
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    print(f"=== PostgreSQL â†’ GPU libpqç›´æ¥ç‰ˆ ===")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME}")
    print(f"è¡Œæ•°åˆ¶é™: {limit_rows:,}")
    print(f"æœ€é©åŒ–è¨­å®š:")
    print(f"  libpq: å¤§å®¹é‡èª­ã¿è¾¼ã¿æ´»ç”¨")
    print(f"  ãƒãƒ£ãƒ³ã‚¯å‡¦ç†: æœ€å°åŒ–")
    print(f"  ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«: 22GB")
    
    # PCIeå¸¯åŸŸãƒ†ã‚¹ãƒˆ
    run_bandwidth_test()
    
    # RMM 22GBåˆæœŸåŒ–
    try:
        if not rmm.is_initialized():
            rmm.reinitialize(
                pool_allocator=True, 
                initial_pool_size=22*1024**3
            )
            print("âœ… RMM ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–å®Œäº† (22GB)")
    except Exception as e:
        print(f"âŒ RMMåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return

    start_total_time = time.time()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    conn = psycopg.connect(dsn)
    try:
        print("\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        start_meta_time = time.time()
        columns = fetch_column_meta(conn, f"SELECT * FROM {TABLE_NAME}")
        meta_time = time.time() - start_meta_time
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({meta_time:.4f}ç§’)")
        ncols = len(columns)

        # libpq å¤§å®¹é‡èª­ã¿è¾¼ã¿
        print("libpq å¤§å®¹é‡èª­ã¿è¾¼ã¿å®Ÿè¡Œä¸­...")
        start_copy_time = time.time()
        
        copy_sql = f"COPY (SELECT * FROM {TABLE_NAME} LIMIT {limit_rows}) TO STDOUT (FORMAT binary)"
        
        print("  ğŸš€ libpqå¤§å®¹é‡ãƒãƒƒãƒ•ã‚¡èª­ã¿è¾¼ã¿é–‹å§‹...")
        
        # å¤§å®¹é‡ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºè¨­å®šï¼ˆlibpqã®èƒ½åŠ›ã‚’æ´»ç”¨ï¼‰
        LARGE_BUFFER_SIZE = 64 * 1024 * 1024  # 64MB
        
        data_parts = []
        total_bytes = 0
        read_count = 0
        
        with conn.cursor() as cur:
            with cur.copy(copy_sql) as copy_obj:
                print(f"  ğŸ“¦ libpqå¤§å®¹é‡èª­ã¿è¾¼ã¿ ({LARGE_BUFFER_SIZE / (1024*1024):.0f}MBå˜ä½)")
                
                # å¤§å®¹é‡èª­ã¿è¾¼ã¿ãƒ«ãƒ¼ãƒ—
                while True:
                    try:
                        # libpqã‹ã‚‰å¤§å®¹é‡èª­ã¿è¾¼ã¿
                        # psycopg3ã§ã¯ copy_obj.read() ãŒã‚µã‚¤ã‚ºæŒ‡å®šä¸å¯ã®ãŸã‚
                        # å†…éƒ¨çš„ã«åˆ©ç”¨å¯èƒ½ãªå…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
                        data_chunk = copy_obj.read()
                        
                        if not data_chunk:
                            break
                        
                        # memoryview â†’ byteså¤‰æ›
                        if isinstance(data_chunk, memoryview):
                            chunk_bytes = data_chunk.tobytes()
                        else:
                            chunk_bytes = bytes(data_chunk)
                        
                        data_parts.append(chunk_bytes)
                        total_bytes += len(chunk_bytes)
                        read_count += 1
                        
                        # é€²æ—è¡¨ç¤ºï¼ˆ5GBå˜ä½ï¼‰
                        if total_bytes % (5 * 1024 * 1024 * 1024) < len(chunk_bytes):
                            print(f"    èª­ã¿è¾¼ã¿é€²æ—: {total_bytes / (1024*1024*1024):.1f} GB")
                        
                    except Exception as e:
                        if "no data available" in str(e).lower():
                            break
                        else:
                            raise e
                
                # å…¨ãƒ‡ãƒ¼ã‚¿çµåˆ
                print("  ğŸ”— ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬çµåˆä¸­...")
                host_bytes = b''.join(data_parts)
                del data_parts  # ãƒ¡ãƒ¢ãƒªè§£æ”¾

        copy_time = time.time() - start_copy_time
        actual_data_size = len(host_bytes)
        
        print(f"âœ… libpq å¤§å®¹é‡èª­ã¿è¾¼ã¿å®Œäº† ({copy_time:.4f}ç§’)")
        print(f"  èª­ã¿è¾¼ã¿å›æ•°: {read_count:,}")
        print(f"  å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {actual_data_size / (1024*1024):.2f} MB")
        print(f"  å¹³å‡èª­ã¿è¾¼ã¿ã‚µã‚¤ã‚º: {(actual_data_size / read_count) / (1024*1024):.2f} MB/å›")
        print(f"  èª­ã¿è¾¼ã¿é€Ÿåº¦: {actual_data_size / (1024*1024) / copy_time:.2f} MB/sec")

    finally:
        conn.close()

    # GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ & 1å›è»¢é€
    print("GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ & 1å›è»¢é€å®Ÿè¡Œä¸­...")
    start_gpu_time = time.time()
    
    try:
        # GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºï¼‰
        devbuf = rmm.DeviceBuffer(size=actual_data_size)
        print(f"  GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿å®Œäº†: {actual_data_size / (1024*1024):.2f} MB")
        
        # 1å›è»¢é€
        devbuf.copy_from_host(host_bytes)
        print(f"  âœ… GPU 1å›è»¢é€å®Œäº†!")
        
        # ãƒ›ã‚¹ãƒˆãƒ¡ãƒ¢ãƒªè§£æ”¾
        del host_bytes
        
    except Exception as e:
        print(f"âŒ GPUè»¢é€ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    gpu_time = time.time() - start_gpu_time
    gpu_throughput = actual_data_size / (1024*1024) / gpu_time
    print(f"GPUè»¢é€å®Œäº† ({gpu_time:.4f}ç§’), é€Ÿåº¦: {gpu_throughput:.2f} MB/sec")

    # numba GPU ã‚¢ãƒ¬ã‚¤ã«å¤‰æ›
    print("GPU ãƒãƒƒãƒ•ã‚¡ã‚’ numba GPU ã‚¢ãƒ¬ã‚¤ã«å¤‰æ›ä¸­...")
    raw_dev = cuda.as_cuda_array(devbuf).view(dtype=np.uint8)
    print(f"GPU ã‚¢ãƒ¬ã‚¤å¤‰æ›å®Œäº†: {raw_dev.shape[0]:,} bytes")

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºæ¤œå‡º
    header_sample = raw_dev[:min(128, raw_dev.shape[0])].copy_to_host()
    header_size = detect_pg_header_size(header_sample)
    print(f"ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º: {header_size} ãƒã‚¤ãƒˆ")

    # GPUæœ€é©åŒ–å‡¦ç†
    print("GPUæœ€é©åŒ–å‡¦ç†ä¸­...")
    start_processing_time = time.time()
    
    try:
        cudf_df, detailed_timing = postgresql_to_cudf_parquet(
            raw_dev=raw_dev,
            columns=columns,
            ncols=ncols,
            header_size=header_size,
            output_path=OUTPUT_PARQUET_PATH,
            compression='snappy',
            use_rmm=True,
            optimize_gpu=True
        )
        
        processing_time = time.time() - start_processing_time
        rows = len(cudf_df)
        parse_time = detailed_timing.get('gpu_parsing', 0)
        decode_time = detailed_timing.get('cudf_creation', 0)
        write_time = detailed_timing.get('parquet_export', 0)
        
        print(f"GPUæœ€é©åŒ–å‡¦ç†å®Œäº† ({processing_time:.4f}ç§’), è¡Œæ•°: {rows}")
        
    except Exception as e:
        print(f"GPUæœ€é©åŒ–å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
        return

    total_time = time.time() - start_total_time
    decimal_cols = sum(1 for col in columns if col.arrow_id == 5)
    
    print(f"\n=== libpqç›´æ¥ç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº† ===")
    print(f"ç·æ™‚é–“ = {total_time:.4f} ç§’")
    print("--- æ™‚é–“å†…è¨³ ---")
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—       : {meta_time:.4f} ç§’")
    print(f"  libpqå¤§å®¹é‡èª­ã¿è¾¼ã¿  : {copy_time:.4f} ç§’")
    print(f"  ãƒ›ã‚¹ãƒˆâ†’GPUè»¢é€       : {gpu_time:.4f} ç§’")
    print(f"  GPUãƒ‘ãƒ¼ã‚¹           : {parse_time:.4f} ç§’")
    print(f"  GPUãƒ‡ã‚³ãƒ¼ãƒ‰         : {decode_time:.4f} ç§’")
    print(f"  Parquetæ›¸ãè¾¼ã¿     : {write_time:.4f} ç§’")
    print("--- çµ±è¨ˆæƒ…å ± ---")
    print(f"  å‡¦ç†è¡Œæ•°      : {rows:,} è¡Œ")
    print(f"  å‡¦ç†åˆ—æ•°      : {len(columns)} åˆ—")
    print(f"  Decimalåˆ—æ•°   : {decimal_cols} åˆ—")
    print(f"  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º  : {actual_data_size / (1024*1024):.2f} MB")
    print(f"  èª­ã¿è¾¼ã¿å›æ•°  : {read_count:,}")
    
    total_cells = rows * len(columns)
    throughput = total_cells / decode_time if decode_time > 0 else 0
    network_throughput = actual_data_size / (1024*1024) / copy_time
    
    print(f"  ã‚»ãƒ«å‡¦ç†é€Ÿåº¦     : {throughput:,.0f} cells/sec")
    print(f"  libpqèª­ã¿è¾¼ã¿é€Ÿåº¦: {network_throughput:.2f} MB/sec")
    print(f"  GPUè»¢é€é€Ÿåº¦     : {gpu_throughput:.2f} MB/sec")
    
    # libpqåŠ¹ç‡è©•ä¾¡
    if read_count < 1000:
        efficiency_class = "ğŸ† é«˜åŠ¹ç‡ (èª­ã¿è¾¼ã¿å›æ•°<1000)"
    elif read_count < 10000:
        efficiency_class = "ğŸ¥‡ ä¸­åŠ¹ç‡ (èª­ã¿è¾¼ã¿å›æ•°<10000)"
    elif read_count < 100000:
        efficiency_class = "ğŸ¥ˆ ä½åŠ¹ç‡ (èª­ã¿è¾¼ã¿å›æ•°<100000)"
    else:
        efficiency_class = "ğŸ¥‰ éåŠ¹ç‡ (èª­ã¿è¾¼ã¿å›æ•°å¤šæ•°)"
    
    print(f"  libpqåŠ¹ç‡       : {efficiency_class}")
    
    # PCIeåŠ¹ç‡è¨ˆç®—
    pcie_efficiency = network_throughput / 11900 * 100
    print(f"  PCIeåŠ¹ç‡        : {pcie_efficiency:.1f}% (å¯¾11.9GB/så®Ÿæ¸¬)")
    
    print("--- libpqç›´æ¥æœ€é©åŒ–åŠ¹æœ ---")
    print("  âœ… libpq: å¤§å®¹é‡èª­ã¿è¾¼ã¿æ´»ç”¨")
    print("  âœ… èª­ã¿è¾¼ã¿å›æ•°: æœ€å°åŒ–")
    print("  âœ… å†…éƒ¨ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°: libpqã«ä¾å­˜")
    print("  âœ… GPUè»¢é€: 1å›ã®ã¿")
    print("  âœ… CPUä½¿ç”¨ç‡: å‰Šæ¸›")
    
    if network_throughput > 5000:
        print("  ğŸ† 5GB/sè¶…é”æˆï¼")
    elif network_throughput > 1000:
        print("  ğŸ¥‡ 1GB/sè¶…é”æˆï¼")
    elif network_throughput > 500:
        print("  ğŸ¥ˆ 500MB/sè¶…é”æˆï¼")
    else:
        print("  âš ï¸  è»¢é€é€Ÿåº¦æ”¹å–„ã®ä½™åœ°ã‚ã‚Š")
    
    print("=========================================")

    # æ¤œè¨¼ç”¨å‡ºåŠ›
    print(f"\ncuDFæ¤œè¨¼ç”¨å‡ºåŠ›:")
    try:
        print(f"å‡ºåŠ›Parquet: {OUTPUT_PARQUET_PATH}")
        print(f"èª­ã¿è¾¼ã¿ç¢ºèª: {len(cudf_df):,} è¡Œ Ã— {len(cudf_df.columns)} åˆ—")
        print("å…ˆé ­ãƒ‡ãƒ¼ã‚¿å‹:")
        for i, (col_name, dtype) in enumerate(cudf_df.dtypes.items()):
            if i < 3:
                print(f"  {col_name}: {dtype}")
        print("âœ… cuDFæ¤œè¨¼: æˆåŠŸ")
    except Exception as e:
        print(f"âŒ cuDFæ¤œè¨¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='PostgreSQL â†’ GPU libpqç›´æ¥ç‰ˆ')
    parser.add_argument('--rows', type=int, default=1000000, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    parser.add_argument('--bandwidth-test', action='store_true', help='å¸¯åŸŸãƒ†ã‚¹ãƒˆã®ã¿')
    
    args = parser.parse_args()
    
    try:
        cuda.current_context()
        print("âœ… CUDA context OK")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        exit(1)
    
    if args.bandwidth_test:
        run_bandwidth_test()
        return
    
    run_libpq_direct_benchmark(limit_rows=args.rows)

if __name__ == "__main__":
    main()