"""
PostgreSQL â†’ GPU 1å›ã‚³ãƒ”ãƒ¼æ–¹å¼
ã€Œãƒãƒƒãƒ•ã‚¡1å›ã‚³ãƒ”ãƒ¼ã€ã§ã‚·ãƒ³ãƒ—ãƒ«ã‹ã¤é«˜åŠ¹ç‡ãªå®Ÿè£…

RMM 25.x ã®æ­£ã—ã„ API:
- copy_from_host(host_bytes) # ä½ç½®å¼•æ•°1å€‹ã®ã¿
- dst_offset ã‚„ buffer= ã¯å­˜åœ¨ã—ãªã„

ç’°å¢ƒå¤‰æ•°:
GPUPASER_PG_DSN  : PostgreSQLæ¥ç¶šæ–‡å­—åˆ—
"""

import os
import time
import psycopg
import rmm
import numpy as np
from numba import cuda
import argparse
import io

from src.metadata import fetch_column_meta
from src.cuda_kernels.postgresql_binary_parser import detect_pg_header_size
from src.main_postgres_to_parquet import postgresql_to_cudf_parquet

TABLE_NAME = "lineorder"
OUTPUT_PARQUET_PATH = "benchmark/lineorder_single_copy.output.parquet"

def run_single_copy_benchmark(limit_rows=1000000):
    """
    ãƒãƒƒãƒ•ã‚¡1å›ã‚³ãƒ”ãƒ¼æ–¹å¼ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    - COPY ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å…¨ã¦å—ã‘å–ã£ã¦ã‹ã‚‰1å›ã§GPUã«ã‚³ãƒ”ãƒ¼
    - CPUä½¿ç”¨ç‡æœ€å°åŒ–ã€ã‚·ãƒ³ãƒ—ãƒ«ãªã‚³ãƒ¼ãƒ‰
    """
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    print(f"=== PostgreSQL â†’ GPU 1å›ã‚³ãƒ”ãƒ¼æ–¹å¼ ===")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME}")
    print(f"è¡Œæ•°åˆ¶é™: {limit_rows:,}")
    
    # RMM åˆæœŸåŒ–
    try:
        if not rmm.is_initialized():
            rmm.reinitialize(
                pool_allocator=True, 
                initial_pool_size=8*1024**3,  # 8GB
                logging=True  # ãƒ‡ãƒãƒƒã‚°ç”¨
            )
            print("âœ… RMM ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        print(f"âŒ RMMåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return

    start_total_time = time.time()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    conn = psycopg.connect(dsn)
    try:
        print("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        start_meta_time = time.time()
        columns = fetch_column_meta(conn, f"SELECT * FROM {TABLE_NAME}")
        meta_time = time.time() - start_meta_time
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({meta_time:.4f}ç§’)")
        ncols = len(columns)

        # COPY BINARY â†’ ãƒ›ã‚¹ãƒˆãƒãƒƒãƒ•ã‚¡ã«å…¨ãƒ‡ãƒ¼ã‚¿åé›†
        print("COPY BINARY â†’ ãƒ›ã‚¹ãƒˆãƒãƒƒãƒ•ã‚¡åé›†ä¸­...")
        start_copy_time = time.time()
        
        copy_sql = f"COPY (SELECT * FROM {TABLE_NAME} LIMIT {limit_rows}) TO STDOUT (FORMAT binary)"
        
        # æ–¹å¼1: b"".join() ã§ä¸€æ‹¬åé›†ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰
        with conn.cursor() as cur:
            with cur.copy(copy_sql) as copy_obj:
                print("  ğŸ“¡ COPY ã‚¹ãƒˆãƒªãƒ¼ãƒ å—ä¿¡é–‹å§‹...")
                
                # å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’åé›†
                chunks = []
                chunk_count = 0
                for chunk in copy_obj:
                    if chunk:
                        chunks.append(chunk)
                        chunk_count += 1
                        
                        # é€²æ—è¡¨ç¤ºã‚’ç„¡åŠ¹åŒ–
                        # if chunk_count % 1000 == 0:
                        #     total_size = sum(len(c) for c in chunks)
                        #     print(f"    ãƒãƒ£ãƒ³ã‚¯ {chunk_count:,} | {total_size / (1024*1024):.2f} MB")
                
                # ä¸€æ‹¬çµåˆ
                print("  ğŸ”— ãƒãƒ£ãƒ³ã‚¯çµåˆä¸­...")
                host_bytes = b"".join(chunks)
                chunks.clear()  # ãƒ¡ãƒ¢ãƒªè§£æ”¾

        copy_time = time.time() - start_copy_time
        total_size = len(host_bytes)
        
        print(f"âœ… COPY BINARY â†’ ãƒ›ã‚¹ãƒˆãƒãƒƒãƒ•ã‚¡å®Œäº† ({copy_time:.4f}ç§’)")
        print(f"  å‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_count:,}")
        print(f"  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size / (1024*1024):.2f} MB")
        print(f"  ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦: {total_size / (1024*1024) / copy_time:.2f} MB/sec")

    finally:
        conn.close()

    # GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ & 1å›ã‚³ãƒ”ãƒ¼
    print(f"GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ & 1å›ã‚³ãƒ”ãƒ¼å®Ÿè¡Œä¸­...")
    start_gpu_time = time.time()
    
    try:
        # GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã´ã£ãŸã‚Šï¼‰
        dbuf = rmm.DeviceBuffer(size=total_size)
        print(f"  GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿å®Œäº†: {total_size / (1024*1024):.2f} MB")
        
        # ã€é‡è¦ã€‘RMM 25.x æ­£ã—ã„ API - ä½ç½®å¼•æ•°1å€‹ã®ã¿
        dbuf.copy_from_host(host_bytes)
        print(f"  âœ… GPU 1å›ã‚³ãƒ”ãƒ¼å®Œäº†!")
        
        # ãƒ›ã‚¹ãƒˆãƒ¡ãƒ¢ãƒªè§£æ”¾
        del host_bytes
        
    except Exception as e:
        print(f"âŒ GPU ã‚³ãƒ”ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    gpu_time = time.time() - start_gpu_time
    gpu_throughput = total_size / (1024*1024) / gpu_time
    print(f"GPUè»¢é€å®Œäº† ({gpu_time:.4f}ç§’), é€Ÿåº¦: {gpu_throughput:.2f} MB/sec")

    # numba GPU ã‚¢ãƒ¬ã‚¤ã«å¤‰æ›
    print("GPU ãƒãƒƒãƒ•ã‚¡ã‚’ numba GPU ã‚¢ãƒ¬ã‚¤ã«å¤‰æ›ä¸­...")
    raw_dev = cuda.as_cuda_array(dbuf).view(dtype=np.uint8)
    print(f"GPU ã‚¢ãƒ¬ã‚¤å¤‰æ›å®Œäº†: {raw_dev.shape[0]:,} bytes")

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºæ¤œå‡º
    header_sample = raw_dev[:min(128, raw_dev.shape[0])].copy_to_host()
    header_size = detect_pg_header_size(header_sample)
    print(f"ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º: {header_size} ãƒã‚¤ãƒˆ")

    # GPUæœ€é©åŒ–å‡¦ç†
    print("GPUæœ€é©åŒ–å‡¦ç†ä¸­...")
    start_processing_time = time.time()
    
    try:
        cudf_df, detailed_timing = postgresql_to_cudf_parquet(
            raw_dev=raw_dev,
            columns=columns,
            ncols=ncols,
            header_size=header_size,
            output_path=OUTPUT_PARQUET_PATH,
            compression='snappy',
            use_rmm=True,
            optimize_gpu=True
        )
        
        processing_time = time.time() - start_processing_time
        rows = len(cudf_df)
        parse_time = detailed_timing.get('gpu_parsing', 0)
        decode_time = detailed_timing.get('cudf_creation', 0)
        write_time = detailed_timing.get('parquet_export', 0)
        
        print(f"GPUæœ€é©åŒ–å‡¦ç†å®Œäº† ({processing_time:.4f}ç§’), è¡Œæ•°: {rows}")
        
    except Exception as e:
        print(f"GPUæœ€é©åŒ–å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return

    total_time = time.time() - start_total_time
    decimal_cols = sum(1 for col in columns if col.arrow_id == 5)
    
    print(f"\n=== ãƒãƒƒãƒ•ã‚¡1å›ã‚³ãƒ”ãƒ¼æ–¹å¼ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº† ===")
    print(f"ç·æ™‚é–“ = {total_time:.4f} ç§’")
    print("--- æ™‚é–“å†…è¨³ ---")
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—    : {meta_time:.4f} ç§’")
    print(f"  COPYâ†’ãƒ›ã‚¹ãƒˆåé›†  : {copy_time:.4f} ç§’")
    print(f"  ãƒ›ã‚¹ãƒˆâ†’GPUè»¢é€   : {gpu_time:.4f} ç§’")
    print(f"  GPUãƒ‘ãƒ¼ã‚¹        : {parse_time:.4f} ç§’")
    print(f"  GPUãƒ‡ã‚³ãƒ¼ãƒ‰      : {decode_time:.4f} ç§’")
    print(f"  Parquetæ›¸ãè¾¼ã¿  : {write_time:.4f} ç§’")
    print("--- çµ±è¨ˆæƒ…å ± ---")
    print(f"  å‡¦ç†è¡Œæ•°      : {rows:,} è¡Œ")
    print(f"  å‡¦ç†åˆ—æ•°      : {len(columns)} åˆ—")
    print(f"  Decimalåˆ—æ•°   : {decimal_cols} åˆ—")
    print(f"  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º  : {total_size / (1024*1024):.2f} MB")
    print(f"  å‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_count:,}")
    
    total_cells = rows * len(columns)
    throughput = total_cells / decode_time if decode_time > 0 else 0
    print(f"  ã‚»ãƒ«å‡¦ç†é€Ÿåº¦  : {throughput:,.0f} cells/sec")
    print(f"  ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦: {total_size / (1024*1024) / copy_time:.2f} MB/sec")
    print(f"  GPUè»¢é€é€Ÿåº¦    : {gpu_throughput:.2f} MB/sec")
    
    print("--- æœ€é©åŒ–åŠ¹æœï¼ˆ1å›ã‚³ãƒ”ãƒ¼æ–¹å¼ï¼‰ ---")
    print("  âœ… ãƒ•ã‚¡ã‚¤ãƒ« I/O: å®Œå…¨ã‚¼ãƒ­")
    print("  âœ… ãƒ›ã‚¹ãƒˆãƒ¡ãƒ¢ãƒª: ä¸€æ™‚çš„ã«å…¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã€è»¢é€å¾Œå³è§£æ”¾")
    print("  âœ… GPUè»¢é€: 1å›ã®ã¿ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰æœ€å°ï¼‰")
    print("  âœ… CPUä½¿ç”¨ç‡: æœ€å°åŒ–ï¼ˆè¤‡é›‘ãªã‚ªãƒ•ã‚»ãƒƒãƒˆå‡¦ç†ãªã—ï¼‰") 
    print("  âœ… RMM API: æ­£ã—ã„ä½ç½®å¼•æ•°ä½¿ç”¨")
    print("=========================================")

    # æ¤œè¨¼ç”¨ã®ç°¡å˜ãªå‡ºåŠ›
    print(f"\ncuDFæ¤œè¨¼ç”¨å‡ºåŠ›:")
    try:
        print(f"å‡ºåŠ›Parquet: {OUTPUT_PARQUET_PATH}")
        print(f"èª­ã¿è¾¼ã¿ç¢ºèª: {len(cudf_df):,} è¡Œ Ã— {len(cudf_df.columns)} åˆ—")
        print("å…ˆé ­ãƒ‡ãƒ¼ã‚¿å‹:")
        for i, (col_name, dtype) in enumerate(cudf_df.dtypes.items()):
            if i < 5:  # æœ€åˆã®5åˆ—ã®ã¿
                print(f"  {col_name}: {dtype}")
        print("âœ… cuDFæ¤œè¨¼: æˆåŠŸ")
    except Exception as e:
        print(f"âŒ cuDFæ¤œè¨¼: {e}")

def run_memory_optimized_single_copy(limit_rows=1000000):
    """
    ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç‰ˆï¼šbytearray ã‚’äº‹å‰ç¢ºä¿ã—ã¦readinto() ä½¿ç”¨
    å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨
    """
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    print(f"=== ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç‰ˆ 1å›ã‚³ãƒ”ãƒ¼æ–¹å¼ ===")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºæ¨å®š
    rows_est = limit_rows
    row_bytes = 17*8 + 17*4  # æ¦‚ç®—
    header_est = 19
    estimated_size = header_est + rows_est * row_bytes
    
    print(f"æ¨å®šãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {estimated_size / (1024*1024):.2f} MB")
    
    # RMM åˆæœŸåŒ–
    if not rmm.is_initialized():
        rmm.reinitialize(pool_allocator=True, initial_pool_size=8*1024**3)
        print("âœ… RMM åˆæœŸåŒ–å®Œäº†")

    # äº‹å‰ã«bytearrayç¢ºä¿
    print("ãƒ›ã‚¹ãƒˆãƒãƒƒãƒ•ã‚¡äº‹å‰ç¢ºä¿ä¸­...")
    host_buffer = bytearray(estimated_size)
    
    conn = psycopg.connect(dsn)
    try:
        copy_sql = f"COPY (SELECT * FROM {TABLE_NAME} LIMIT {limit_rows}) TO STDOUT (FORMAT binary)"
        
        print("COPY BINARY â†’ äº‹å‰ç¢ºä¿ãƒãƒƒãƒ•ã‚¡ã«ç›´æ¥æ›¸ãè¾¼ã¿ä¸­...")
        start_time = time.time()
        
        offset = 0
        with conn.cursor() as cur:
            with cur.copy(copy_sql) as copy_obj:
                for chunk in copy_obj:
                    if chunk:
                        chunk_size = len(chunk)
                        if offset + chunk_size > len(host_buffer):
                            # ãƒãƒƒãƒ•ã‚¡æ‹¡å¼µ
                            host_buffer.extend(b'\x00' * (chunk_size * 2))
                        
                        # ç›´æ¥æ›¸ãè¾¼ã¿
                        host_buffer[offset:offset+chunk_size] = chunk
                        offset += chunk_size
        
        # å®Ÿéš›ã®ã‚µã‚¤ã‚ºã«ãƒˆãƒªãƒŸãƒ³ã‚°
        actual_data = bytes(host_buffer[:offset])
        del host_buffer  # æ—©æœŸè§£æ”¾
        
        copy_time = time.time() - start_time
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº† ({copy_time:.4f}ç§’)")
        print(f"å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(actual_data) / (1024*1024):.2f} MB")
        
    finally:
        conn.close()
    
    # GPU 1å›ã‚³ãƒ”ãƒ¼
    print("GPU 1å›ã‚³ãƒ”ãƒ¼å®Ÿè¡Œä¸­...")
    start_gpu_time = time.time()
    
    dbuf = rmm.DeviceBuffer(size=len(actual_data))
    dbuf.copy_from_host(actual_data)  # ä½ç½®å¼•æ•°1å€‹ã®ã¿
    
    gpu_time = time.time() - start_gpu_time
    print(f"âœ… GPUè»¢é€å®Œäº† ({gpu_time:.4f}ç§’)")
    print(f"GPUè»¢é€é€Ÿåº¦: {len(actual_data) / (1024*1024) / gpu_time:.2f} MB/sec")
    
    return dbuf, len(actual_data)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='PostgreSQL â†’ GPU 1å›ã‚³ãƒ”ãƒ¼æ–¹å¼')
    parser.add_argument('--rows', type=int, default=1000000, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    parser.add_argument('--memory-optimized', action='store_true', help='ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç‰ˆã‚’ä½¿ç”¨')
    
    args = parser.parse_args()
    
    try:
        cuda.current_context()
        print("âœ… CUDA context OK")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        exit(1)
    
    if args.memory_optimized:
        run_memory_optimized_single_copy(limit_rows=args.rows)
    else:
        run_single_copy_benchmark(limit_rows=args.rows)

if __name__ == "__main__":
    main()