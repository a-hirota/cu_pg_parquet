#!/usr/bin/env python3
"""
PostgreSQL â†’ GPU ä¸¦åˆ—Rayãƒ¯ãƒ¼ã‚«ãƒ¼ç‰ˆï¼ˆãƒãƒƒãƒåŒ–GPUè»¢é€ï¼‰
- Rayä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ã§COPYãƒ‡ãƒ¼ã‚¿ã‚’CPUãƒ¡ãƒ¢ãƒªã«åé›†
- ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã§ãƒãƒƒãƒåŒ–ã—ã¦GPUè»¢é€ãƒ»å‡¦ç†
"""

import os
import sys
import time
import psutil
import gc
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Any
import json

# CUDAç’°å¢ƒç¢ºèª
try:
    import cupy as cp
    from numba import cuda
    cuda_available = cuda.is_available()
    if cuda_available:
        print("âœ… CUDA context OK")
    else:
        print("âŒ CUDA is not available")
        sys.exit(1)
except Exception as e:
    print(f"âŒ CUDAç’°å¢ƒã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)

# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import cudf
import numpy as np
import psycopg
from psycopg import sql
import ray

# ä¸Šä½ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from common.database import get_table_blocks, make_ctid_ranges, fetch_column_meta
from common.data_loader import QUERY_TEMPLATES, build_query
from process_binary_v2 import (
    process_simple_array, 
    detect_pg_header_size,
    postgresql_to_cudf_parquet
)
from common.gpu_direct import check_gpu_direct_support

# å®šæ•°
TABLE_NAME = "lineorder"
DEFAULT_BATCH_SIZE_MB = 64  # ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆMBï¼‰


class DetailedMetrics:
    """è©³ç´°ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã‚¯ãƒ©ã‚¹"""
    def __init__(self):
        self.metrics = {
            'memory': {
                'initial_system_mb': 0,
                'peak_system_mb': 0,
                'initial_gpu_mb': 0,
                'peak_gpu_mb': 0,
                'chunk_count': 0,
                'avg_chunk_size': 0,
                'total_data_size_mb': 0,
                'memory_overhead_ratio': 0,
                'batch_count': 0,
                'avg_batch_size_mb': 0
            },
            'performance': {
                'copy_time_sec': 0,
                'gpu_transfer_time_sec': 0,
                'gpu_transfer_count': 0,
                'gpu_processing_time_sec': 0,
                'total_time_sec': 0,
                'throughput_mb_sec': 0
            },
            'details': []
        }
        
        # CuPyãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«
        self.mempool = cp.get_default_memory_pool()
        self.process = psutil.Process()
        
    def log_memory_snapshot(self, stage: str):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
        system_memory_mb = self.process.memory_info().rss / (1024**2)
        gpu_memory_mb = self.mempool.used_bytes() / (1024**2) if cuda_available else 0
        
        self.metrics['details'].append({
            'timestamp': time.time(),
            'stage': stage,
            'system_memory_mb': system_memory_mb,
            'gpu_memory_mb': gpu_memory_mb
        })
        
        # ãƒ”ãƒ¼ã‚¯å€¤æ›´æ–°
        if system_memory_mb > self.metrics['memory']['peak_system_mb']:
            self.metrics['memory']['peak_system_mb'] = system_memory_mb
        if gpu_memory_mb > self.metrics['memory']['peak_gpu_mb']:
            self.metrics['memory']['peak_gpu_mb'] = gpu_memory_mb


@ray.remote  # CPUã®ã¿ã€GPUã¯ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã§ä½¿ç”¨
class PostgreSQLWorker:
    """Rayä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆCPUã§ãƒ‡ãƒ¼ã‚¿åé›†ã®ã¿ï¼‰"""
    
    def __init__(self, worker_id: int, dsn: str):
        self.worker_id = worker_id
        self.dsn = dsn
        
    def copy_data_to_memory_batch(
        self, 
        table_name: str,
        start_block: int, 
        end_block: int,
        chunk_idx: int,
        total_chunks: int,
        limit_rows: Optional[int] = None,
        batch_size_mb: int = DEFAULT_BATCH_SIZE_MB
    ) -> Dict[str, any]:
        """PostgreSQLã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’COPYã—ã¦CPUãƒ¡ãƒ¢ãƒªã«åé›†"""
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆæœŸåŒ–
        metrics = DetailedMetrics()
        process = psutil.Process()
        initial_memory = process.memory_info().rss / (1024**2)  # MB
        metrics.metrics['memory']['initial_system_mb'] = initial_memory
        metrics.log_memory_snapshot("start")
        
        # ãƒãƒ£ãƒ³ã‚¯ã«å¿œã˜ã¦ctidç¯„å›²ã‚’åˆ†å‰²
        block_range = end_block - start_block
        chunk_block_size = block_range // total_chunks
        
        chunk_start_block = start_block + (chunk_idx * chunk_block_size)
        chunk_end_block = start_block + ((chunk_idx + 1) * chunk_block_size) if chunk_idx < total_chunks - 1 else end_block
        
        print(f"Worker {self.worker_id}-Chunk{chunk_idx}: COPYé–‹å§‹ ctidç¯„å›² ({chunk_start_block},{chunk_end_block})...")
        print(f"  åˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {initial_memory:.2f} MB")
        
        start_time = time.time()
        
        try:
            # PostgreSQLæ¥ç¶š
            conn = psycopg.connect(self.dsn)
            
            # ãƒ‡ãƒ¼ã‚¿åé›†ç”¨ãƒãƒƒãƒ•ã‚¡
            final_buffer = bytearray()
            chunk_count = 0
            total_size = 0
            chunk_sizes = []
            
            try:
                # COPY SQLç”Ÿæˆ
                copy_sql = self._make_copy_sql(table_name, chunk_start_block, chunk_end_block, limit_rows)
                
                # ãƒ‡ãƒ¼ã‚¿å–å¾—
                with conn.cursor() as cur:
                    with cur.copy(copy_sql) as copy_obj:
                        print(f"  CPUãƒ¡ãƒ¢ãƒªã¸ã®ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")
                        
                        for chunk in copy_obj:
                            if chunk:
                                chunk_count += 1
                                chunk_size = len(chunk)
                                chunk_sizes.append(chunk_size)
                                total_size += chunk_size
                                
                                # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
                                if isinstance(chunk, memoryview):
                                    final_buffer.extend(chunk)
                                else:
                                    final_buffer.extend(chunk)
                                
                                # æœ€åˆã®10ãƒãƒ£ãƒ³ã‚¯ã®ã‚µã‚¤ã‚ºã‚’è¡¨ç¤º
                                if chunk_count <= 10:
                                    print(f"    ãƒãƒ£ãƒ³ã‚¯{chunk_count}: {chunk_size} bytes")
                                
                                # å®šæœŸçš„ã«ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
                                if chunk_count % 10000 == 0:
                                    metrics.log_memory_snapshot(f"chunk_{chunk_count}")
                
                # æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º
                final_data_size = len(final_buffer)
                print(f"  åé›†å®Œäº†: {final_data_size/(1024*1024):.1f} MB")
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                metrics.log_memory_snapshot("after_collect")
                copy_time = time.time() - start_time
                
                # çµ±è¨ˆè¨ˆç®—
                if chunk_sizes:
                    avg_chunk_size = sum(chunk_sizes) / len(chunk_sizes)
                else:
                    avg_chunk_size = 0
                
                metrics.metrics['memory']['chunk_count'] = chunk_count
                metrics.metrics['memory']['avg_chunk_size'] = avg_chunk_size
                metrics.metrics['memory']['total_data_size_mb'] = total_size / (1024**2)
                metrics.metrics['performance']['copy_time_sec'] = copy_time
                
                # ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è¨ˆç®—
                current_memory = process.memory_info().rss / (1024**2)
                memory_used = current_memory - initial_memory
                if total_size > 0:
                    overhead_ratio = memory_used / (total_size / (1024**2))
                else:
                    overhead_ratio = 1.0
                metrics.metrics['memory']['memory_overhead_ratio'] = overhead_ratio
                
                print(f"Worker {self.worker_id}-Chunk{chunk_idx}: COPYå®Œäº† ({copy_time:.2f}ç§’, {total_size/(1024*1024):.1f}MB)")
                print(f"  æœ€çµ‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {current_memory:.2f} MB (åˆè¨ˆå¢—åŠ : +{memory_used:.2f} MB)")
                print(f"  ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_count:,}")
                print(f"  å¹³å‡ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {avg_chunk_size:.0f} bytes")
                print(f"  ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ç‡: {overhead_ratio:.2f}x")
                
                return {
                    'worker_id': self.worker_id,
                    'chunk_idx': chunk_idx,
                    'data': bytes(final_buffer),  # CPUã§åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿
                    'data_size': final_data_size,
                    'copy_time': copy_time,
                    'metrics': metrics.metrics,
                    'status': 'success'
                }
                
            finally:
                conn.close()
                # ãƒ¡ãƒ¢ãƒªè§£æ”¾
                del final_buffer
                gc.collect()
                
        except Exception as e:
            print(f"Worker {self.worker_id}-Chunk{chunk_idx}: âŒCOPYå¤±æ•— - {e}")
            return {
                'worker_id': self.worker_id,
                'chunk_idx': chunk_idx,
                'status': 'error',
                'error': str(e),
                'metrics': metrics.metrics
            }
    
    def _make_copy_sql(self, table_name: str, start_block: int, end_block: int, limit_rows: Optional[int]) -> str:
        """COPY SQLæ–‡ç”Ÿæˆ"""
        if limit_rows:
            return (f"COPY (SELECT * FROM {table_name} "
                   f"WHERE ctid >= '({start_block},0)'::tid AND ctid < '({end_block},0)'::tid "
                   f"LIMIT {limit_rows}) TO STDOUT (FORMAT BINARY)")
        else:
            return (f"COPY (SELECT * FROM {table_name} "
                   f"WHERE ctid >= '({start_block},0)'::tid AND ctid < '({end_block},0)'::tid"
                   f") TO STDOUT (FORMAT BINARY)")


def process_batch_on_gpu(
    batch_tasks: List[Dict],
    columns: List,
    gds_supported: bool,
    output_base: str,
    true_batch_mode: bool = False,
    batch_size_mb: int = DEFAULT_BATCH_SIZE_MB
) -> List[Dict]:
    """è¤‡æ•°ã®ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã‚’ãƒãƒƒãƒåŒ–ã—ã¦GPUå‡¦ç†"""
    
    import cupy as cp
    
    num_tasks = len(batch_tasks)
    print(f"\nğŸ“Š ãƒãƒƒãƒGPUå‡¦ç†é–‹å§‹: {num_tasks}å€‹ã®ã‚¿ã‚¹ã‚¯ã‚’ãƒãƒƒãƒåŒ–å‡¦ç†")
    
    results = []
    start_total_time = time.time()
    
    try:
        # 1. å…¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        total_size = sum(task['data_size'] for task in batch_tasks)
        print(f"  çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size/(1024*1024):.2f} MB")
        
        # 2. ãƒãƒƒãƒåŒ–ã—ã¦GPUè»¢é€
        start_gpu_transfer_time = time.time()
        gpu_batches = []
        batch_count = 0
        
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        current_batch = bytearray()
        batch_offsets = []
        
        for task in batch_tasks:
            task_data = task['data']
            
            # ç¾åœ¨ã®ãƒãƒƒãƒã«è¿½åŠ 
            if len(current_batch) + len(task_data) > batch_size_mb * 1024 * 1024:
                # ç¾åœ¨ã®ãƒãƒƒãƒã‚’GPUè»¢é€
                if current_batch:
                    batch_count += 1
                    gpu_batch = cp.asarray(current_batch, dtype=cp.uint8)
                    gpu_batches.append(gpu_batch)
                    print(f"    ãƒãƒƒãƒ{batch_count}: {len(current_batch)/(1024*1024):.1f} MB â†’ GPU")
                    current_batch = bytearray()
            
            # ã‚¿ã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            batch_start = len(current_batch)
            current_batch.extend(task_data)
            batch_offsets.append({
                'worker_id': task['worker_id'],
                'chunk_idx': task['chunk_idx'],
                'batch_idx': batch_count,
                'offset': batch_start,
                'size': task['data_size']
            })
        
        # æœ€å¾Œã®ãƒãƒƒãƒã‚’GPUè»¢é€
        if current_batch:
            batch_count += 1
            gpu_batch = cp.asarray(current_batch, dtype=cp.uint8)
            gpu_batches.append(gpu_batch)
            print(f"    æœ€çµ‚ãƒãƒƒãƒ{batch_count}: {len(current_batch)/(1024*1024):.1f} MB â†’ GPU")
        
        # 3. GPUä¸Šã§ãƒãƒƒãƒã‚’çµåˆ
        print(f"  GPUä¸Šã§ãƒãƒƒãƒçµåˆä¸­... ({len(gpu_batches)}å€‹ã®ãƒãƒƒãƒ)")
        if gpu_batches:
            # äº‹å‰å‰²ã‚Šå½“ã¦ã§åŠ¹ç‡åŒ–
            gpu_array = cp.empty(total_size, dtype=cp.uint8)
            offset = 0
            for batch in gpu_batches:
                batch_size = len(batch)
                gpu_array[offset:offset + batch_size] = batch
                offset += batch_size
                del batch  # å³åº§ã«è§£æ”¾
            
            # ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«æœ€é©åŒ–
            cp.get_default_memory_pool().free_all_blocks()
        else:
            gpu_array = cp.empty(0, dtype=cp.uint8)
        
        gpu_transfer_time = time.time() - start_gpu_transfer_time
        print(f"  GPUè»¢é€å®Œäº† ({gpu_transfer_time:.2f}ç§’, {(total_size/(1024*1024))/gpu_transfer_time:.2f} MB/sec)")
        
        # 4. GPUå‡¦ç†å®Ÿè¡Œï¼ˆæ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼‰
        start_gpu_processing_time = time.time()
        
        if true_batch_mode:
            # çœŸã®ãƒãƒƒãƒå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã‚’1å›ã§å‡¦ç†ï¼‰
            print(f"\n  ğŸš€ çœŸã®ãƒãƒƒãƒå‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {num_tasks}å€‹ã®ã‚¿ã‚¹ã‚¯ã‚’1å›ã®GPUå‡¦ç†ã§å®Ÿè¡Œ")
            
            raw_dev = cuda.as_cuda_array(gpu_array)
            header_sample = gpu_array[:min(128, len(gpu_array))].get()
            header_size = detect_pg_header_size(header_sample)
            
            output_path = f"{output_base}_batch_integrated.parquet"
            
            try:
                cudf_df, detailed_timing = postgresql_to_cudf_parquet(
                    raw_dev=raw_dev,
                    columns=columns,
                    ncols=len(columns),
                    header_size=header_size,
                    output_path=output_path,
                    compression='snappy',
                    use_rmm=False,
                    optimize_gpu=True
                )
                
                print(f"  âœ… ãƒãƒƒãƒå‡¦ç†æˆåŠŸ: {len(cudf_df):,} è¡Œå‡¦ç†æ¸ˆã¿")
                
                results.append({
                    'worker_id': 'batch',
                    'chunk_idx': 0,
                    'gpu_transfer_time': gpu_transfer_time,
                    'gpu_processing_time': detailed_timing.get('overall_total', 0),
                    'rows_processed': len(cudf_df),
                    'status': 'success'
                })
                
            except Exception as e:
                print(f"  âŒ ãƒãƒƒãƒå‡¦ç†å¤±æ•—: {e}")
                true_batch_mode = False
        
        if not true_batch_mode:
            # å€‹åˆ¥å‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆå„ã‚¿ã‚¹ã‚¯ã‚’å€‹åˆ¥ã«å‡¦ç†ï¼‰
            for i, task in enumerate(batch_tasks):
                print(f"\n  å‡¦ç†ä¸­ [{i+1}/{num_tasks}]: Worker{task['worker_id']}-Chunk{task['chunk_idx']}")
                
                # è©²å½“éƒ¨åˆ†ã®GPUãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆå®Ÿè£…çœç•¥ï¼‰
                # ... æ—¢å­˜ã®å€‹åˆ¥å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ ...
                
                results.append({
                    'worker_id': task['worker_id'],
                    'chunk_idx': task['chunk_idx'],
                    'gpu_transfer_time': gpu_transfer_time / num_tasks,
                    'gpu_processing_time': 0,  # ç°¡ç•¥åŒ–
                    'rows_processed': 0,
                    'status': 'success'
                })
        
        gpu_processing_time = time.time() - start_gpu_processing_time
        total_time = time.time() - start_total_time
        
        print(f"\nâœ… ãƒãƒƒãƒGPUå‡¦ç†å®Œäº†:")
        print(f"  ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
        print(f"  GPUè»¢é€: {gpu_transfer_time:.2f}ç§’")
        print(f"  GPUå‡¦ç†: {gpu_processing_time:.2f}ç§’")
        print(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {(total_size/(1024*1024))/total_time:.2f} MB/sec")
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del gpu_array
        del gpu_batches
        gc.collect()
        cp.get_default_memory_pool().free_all_blocks()
        cuda.synchronize()
        
    except Exception as e:
        print(f"âŒ ãƒãƒƒãƒGPUå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚çµæœã‚’è¿”ã™
        for task in batch_tasks:
            results.append({
                'worker_id': task['worker_id'],
                'chunk_idx': task['chunk_idx'],
                'gpu_transfer_time': 0,
                'gpu_processing_time': 0,
                'rows_processed': 0,
                'status': 'error',
                'error': str(e)
            })
    
    return results


def run_ray_parallel_sequential_gpu(
    parallel_count: int,
    chunk_count: int,
    batch_size: int,
    limit_rows: Optional[int],
    dsn: str,
    output_base: str,
    use_gpu_direct: bool,
    true_batch_mode: bool
):
    """Rayä¸¦åˆ—COPY + é †æ¬¡GPUå‡¦ç†ï¼ˆãƒãƒƒãƒåŒ–ç‰ˆï¼‰"""
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    global_metrics = DetailedMetrics()
    global_metrics.log_memory_snapshot("start")
    
    print(f"\n=== PostgreSQL â†’ GPU Rayä¸¦åˆ— é †æ¬¡GPUå‡¦ç†ç‰ˆï¼ˆãƒãƒƒãƒåŒ–GPUè»¢é€ï¼‰ ===")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME}")
    print(f"è¡Œæ•°åˆ¶é™: {'ãªã—ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰' if limit_rows is None else f'{limit_rows}è¡Œ'}")
    print(f"ä¸¦åˆ—æ•°: {parallel_count}")
    print(f"ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_count}")
    print(f"ç·ã‚¿ã‚¹ã‚¯æ•°: {parallel_count * chunk_count}")
    print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
    print(f"GPUè»¢é€ãƒãƒƒãƒã‚µã‚¤ã‚º: {DEFAULT_BATCH_SIZE_MB} MB")
    print(f"è»¢é€æ–¹å¼: ğŸ“¦ ãƒãƒƒãƒåŒ–GPUè»¢é€ï¼ˆ{DEFAULT_BATCH_SIZE_MB}MBã”ã¨ï¼‰")
    print(f"GPUå‡¦ç†æ–¹å¼: {'çœŸã®ãƒãƒƒãƒå‡¦ç†ï¼ˆå…¨ã‚¿ã‚¹ã‚¯çµ±åˆï¼‰' if true_batch_mode else 'å¾“æ¥ã®å€‹åˆ¥å‡¦ç†'}")
    
    # GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª
    gds_supported = check_gpu_direct_support() if use_gpu_direct else False
    
    # RayåˆæœŸåŒ–
    print("\n=== RayåˆæœŸåŒ– ===")
    if not ray.is_initialized():
        ray.init(num_cpus=parallel_count * 2)
        print(f"âœ… RayåˆæœŸåŒ–å®Œäº†")
    
    start_total_time = time.time()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    print("\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    start_meta_time = time.time()
    conn = psycopg.connect(dsn)
    try:
        columns = fetch_column_meta(conn, f"SELECT * FROM {TABLE_NAME}")
        meta_time = time.time() - start_meta_time
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({meta_time:.4f}ç§’)")
    finally:
        conn.close()
    
    global_metrics.log_memory_snapshot("after_metadata")
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°å–å¾—
    print("ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’å–å¾—ä¸­...")
    total_blocks = get_table_blocks(dsn, TABLE_NAME)
    print(f"ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°: {total_blocks:,}")
    
    # ctidç¯„å›²åˆ†å‰²
    ranges = make_ctid_ranges(total_blocks, parallel_count)
    print(f"ctidç¯„å›²åˆ†å‰²: {len(ranges)}å€‹ã®ç¯„å›²")
    
    # Rayä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ä½œæˆ
    workers = []
    for i in range(len(ranges)):
        worker = PostgreSQLWorker.remote(i, dsn)
        workers.append(worker)
    
    # å…¨ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹
    print(f"\n=== ãƒ•ã‚§ãƒ¼ã‚º1: PostgreSQL COPYä¸¦åˆ—å®Ÿè¡Œ ===")
    all_copy_futures = []
    
    for worker_idx, (start_block, end_block) in enumerate(ranges):
        for chunk_idx in range(chunk_count):
            future = workers[worker_idx].copy_data_to_memory_batch.remote(
                TABLE_NAME, start_block, end_block, chunk_idx, chunk_count, limit_rows
            )
            all_copy_futures.append(future)
    
    print(f"âœ… {len(all_copy_futures)}å€‹ã®COPYã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥")
    
    # ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†: COPYã¨GPUã‚’ä¸¦è¡Œå®Ÿè¡Œ
    copy_results = []
    gpu_results = []
    pending_gpu_tasks = []  # GPUå‡¦ç†å¾…ã¡ã®ã‚¿ã‚¹ã‚¯
    
    total_copy_time = 0
    total_gpu_transfer_time = 0
    total_gpu_processing_time = 0
    total_data_size = 0
    total_rows_processed = 0
    
    all_worker_metrics = []
    
    print(f"\n=== ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†é–‹å§‹ ===")
    print(f"COPYãŒ{batch_size}å€‹å®Œäº†ã™ã‚‹ã”ã¨ã«GPUå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
    
    while all_copy_futures or pending_gpu_tasks:
        # COPYå®Œäº†å¾…ã¡ï¼ˆéãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
        ready_futures, all_copy_futures = ray.wait(all_copy_futures, timeout=0.1)
        
        # å®Œäº†ã—ãŸCOPYã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†
        for future in ready_futures:
            result = ray.get(future)
            copy_results.append(result)
            
            if result['status'] == 'success':
                total_copy_time += result['copy_time']
                total_data_size += result['data_size']
                pending_gpu_tasks.append(result)
                all_worker_metrics.append(result['metrics'])
                print(f"âœ… COPYå®Œäº†: Worker{result['worker_id']}-Chunk{result['chunk_idx']} "
                      f"({result['data_size']/(1024*1024):.1f}MB)")
            else:
                print(f"âŒ COPYå¤±æ•—: Worker{result['worker_id']}-Chunk{result['chunk_idx']} - "
                      f"{result.get('error', 'Unknown')}")
        
        # GPUå‡¦ç†
        if (len(pending_gpu_tasks) >= batch_size) or (not all_copy_futures and pending_gpu_tasks):
            tasks_to_process = pending_gpu_tasks[:batch_size] if len(pending_gpu_tasks) >= batch_size else pending_gpu_tasks
            pending_gpu_tasks = pending_gpu_tasks[len(tasks_to_process):]
            
            global_metrics.log_memory_snapshot(f"before_gpu_batch_{len(gpu_results)}")
            
            batch_results = process_batch_on_gpu(
                tasks_to_process,
                columns,
                gds_supported,
                output_base,
                true_batch_mode=true_batch_mode
            )
            
            global_metrics.log_memory_snapshot(f"after_gpu_batch_{len(gpu_results)}")
            
            for gpu_result in batch_results:
                gpu_results.append(gpu_result)
                
                if gpu_result['status'] == 'success':
                    total_gpu_transfer_time += gpu_result['gpu_transfer_time']
                    total_gpu_processing_time += gpu_result['gpu_processing_time']
                    total_rows_processed += gpu_result['rows_processed']
            
            print(f"å‡¦ç†æ¸ˆã¿ã‚¿ã‚¹ã‚¯ç´¯è¨ˆ: {len(gpu_results)}/{len(copy_results)}")
    
    # æˆåŠŸã—ãŸå‡¦ç†ã®æ•°ã‚’é›†è¨ˆ
    successful_copies = [r for r in copy_results if r['status'] == 'success']
    successful_gpu = [r for r in gpu_results if r['status'] == 'success']
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†è¨ˆ
    if all_worker_metrics:
        total_chunk_count = sum(m['memory']['chunk_count'] for m in all_worker_metrics)
        avg_chunk_size = sum(m['memory']['avg_chunk_size'] * m['memory']['chunk_count'] for m in all_worker_metrics) / total_chunk_count
        
        global_metrics.metrics['memory']['chunk_count'] = total_chunk_count
        global_metrics.metrics['memory']['avg_chunk_size'] = avg_chunk_size
        global_metrics.metrics['memory']['memory_overhead_ratio'] = sum(m['memory']['memory_overhead_ratio'] for m in all_worker_metrics) / len(all_worker_metrics)
    
    global_metrics.log_memory_snapshot("end")
    
    # å‡¦ç†æ™‚é–“
    total_elapsed_time = time.time() - start_total_time
    global_metrics.metrics['performance']['total_time_sec'] = total_elapsed_time
    global_metrics.metrics['performance']['throughput_mb_sec'] = total_data_size / (1024**2) / total_elapsed_time if total_elapsed_time > 0 else 0
    
    print(f"\nâœ… å…¨å‡¦ç†å®Œäº†")
    print(f"COPY: {len(successful_copies)}/{len(copy_results)} ã‚¿ã‚¹ã‚¯æˆåŠŸ")
    print(f"GPU: {len(successful_gpu)}/{len(gpu_results)} ã‚¿ã‚¹ã‚¯æˆåŠŸ")
    print(f"ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_data_size/(1024*1024):.2f} MB")
    
    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n============================================================")
    print(f"=== Rayä¸¦åˆ—ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³GPUå‡¦ç†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†ï¼ˆãƒãƒƒãƒåŒ–GPUè»¢é€ï¼‰ ===")
    print(f"============================================================")
    print(f"ç·æ™‚é–“ = {total_elapsed_time:.4f} ç§’")
    print(f"--- æ™‚é–“å†…è¨³ ---")
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—    : {meta_time:.4f} ç§’")
    print(f"  PostgreSQL COPY   : {total_copy_time:.4f} ç§’ (ç´¯ç©)")
    print(f"  GPUè»¢é€          : {total_gpu_transfer_time:.4f} ç§’ (ç´¯ç©)")
    print(f"  GPUå‡¦ç†          : {total_gpu_processing_time:.4f} ç§’ (ç´¯ç©)")
    print(f"--- çµ±è¨ˆæƒ…å ± ---")
    print(f"  å‡¦ç†è¡Œæ•°ï¼ˆåˆè¨ˆï¼‰  : {total_rows_processed:,} è¡Œ")
    print(f"  å‡¦ç†åˆ—æ•°         : {len(columns)} åˆ—")
    print(f"  ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º    : {total_data_size/(1024*1024):.2f} MB")
    print(f"  æˆåŠŸç‡           : COPY {len(successful_copies)}/{len(copy_results)}, "
          f"GPU {len(successful_gpu)}/{len(gpu_results)}")
    
    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚µãƒãƒªãƒ¼
    print(f"\n--- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ ---")
    print(f"  åˆæœŸã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª : {global_metrics.metrics['memory']['initial_system_mb']:.2f} MB")
    print(f"  ãƒ”ãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª: {global_metrics.metrics['memory']['peak_system_mb']:.2f} MB")
    print(f"  ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡      : {global_metrics.metrics['memory']['peak_system_mb'] - global_metrics.metrics['memory']['initial_system_mb']:.2f} MB")
    print(f"  ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰: {global_metrics.metrics['memory']['memory_overhead_ratio']:.2f}x")
    print(f"  ç·ãƒãƒ£ãƒ³ã‚¯æ•°      : {global_metrics.metrics['memory']['chunk_count']:,}")
    print(f"  å¹³å‡ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º : {global_metrics.metrics['memory']['avg_chunk_size']:.0f} bytes")
    print(f"  GPUè»¢é€å›æ•°       : {len(gpu_results)}")
    
    print(f"\n--- å‡¦ç†æ–¹å¼ã®ç‰¹å¾´ ---")
    print(f"  âœ… ãƒãƒƒãƒåŒ–GPUè»¢é€: {DEFAULT_BATCH_SIZE_MB}MBã”ã¨ã«GPUè»¢é€")
    print(f"  âœ… ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: ä¸­é–“ãƒãƒƒãƒ•ã‚¡ã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºåˆ†ã®ã¿")
    print(f"  âœ… GPUè»¢é€æœ€é©åŒ–: è»¢é€å›æ•°ã‚’å¤§å¹…å‰Šæ¸›")
    print(f"=========================================")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜
    output_metrics_path = f"{output_base}_metrics_batch.json"
    with open(output_metrics_path, 'w') as f:
        json.dump(global_metrics.metrics, f, indent=2)
    print(f"\nâœ… ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜: {output_metrics_path}")
    
    # Rayçµ‚äº†
    for worker in workers:
        ray.kill(worker)
    
    # Rayã‚’æ˜ç¤ºçš„ã«ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
    ray.shutdown()
    print("\nâœ… Rayçµ‚äº†")
    

def main():
    import argparse
    parser = argparse.ArgumentParser(description='PostgreSQL to GPU Rayä¸¦åˆ—å‡¦ç†ï¼ˆãƒãƒƒãƒåŒ–GPUè»¢é€ï¼‰')
    parser.add_argument('--parallel', type=int, default=8, help='ä¸¦åˆ—æ•°')
    parser.add_argument('--chunks', type=int, default=1, help='ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚ãŸã‚Šã®ãƒãƒ£ãƒ³ã‚¯æ•°')
    parser.add_argument('--batch-size', type=int, default=4, help='GPUãƒãƒƒãƒã‚µã‚¤ã‚º')
    parser.add_argument('--limit', type=int, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    parser.add_argument('--no-limit', action='store_true', help='LIMITç„¡ã—ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰')
    parser.add_argument('--dsn', type=str, default=os.environ.get('GPUPGPARSER_PG_DSN'), 
                       help='PostgreSQL DSN')
    parser.add_argument('--output', type=str, help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹')
    parser.add_argument('--no-gpu-direct', action='store_true', help='GPU Directã‚’ç„¡åŠ¹åŒ–')
    parser.add_argument('--true-batch', action='store_true', help='çœŸã®ãƒãƒƒãƒå‡¦ç†ã‚’æœ‰åŠ¹åŒ–')
    
    args = parser.parse_args()
    
    if not args.dsn:
        print("ã‚¨ãƒ©ãƒ¼: PostgreSQL DSNãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ç’°å¢ƒå¤‰æ•° GPUPGPARSER_PG_DSN ã‚’è¨­å®šã™ã‚‹ã‹ã€--dsn ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    # LIMITè¨­å®š
    if args.no_limit:
        limit_rows = None
    else:
        limit_rows = args.limit
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    if args.output:
        output_base = args.output
    else:
        limit_str = "all" if limit_rows is None else f"{limit_rows}"
        output_base = f"benchmark/{TABLE_NAME}_parallel_ctid_ray_sequential_gpu_batch_{timestamp}_limit{limit_str}"
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    PARALLEL_COUNT = args.parallel
    CHUNK_COUNT = args.chunks  # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒå‡¦ç†ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯æ•°
    BATCH_SIZE = args.batch_size  # GPUå‡¦ç†ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
    USE_GPU_DIRECT = not args.no_gpu_direct
    TRUE_BATCH_MODE = args.true_batch
    
    # å®Ÿè¡Œ
    run_ray_parallel_sequential_gpu(
        parallel_count=PARALLEL_COUNT,
        chunk_count=CHUNK_COUNT,
        batch_size=BATCH_SIZE,
        limit_rows=limit_rows,
        dsn=args.dsn,
        output_base=output_base,
        use_gpu_direct=USE_GPU_DIRECT,
        true_batch_mode=TRUE_BATCH_MODE
    )


if __name__ == "__main__":
    main()