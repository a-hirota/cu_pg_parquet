"""
PostgreSQL â†’ GPU pg2arrowå®Œå…¨å¯¾å¿œç‰ˆ
pg2arrowæˆåŠŸãƒ¢ãƒ‡ãƒ«ã®å®Œå…¨å®Ÿè£…

æœ€é©åŒ–:
- ctid offset=1é–‹å§‹ï¼ˆpg2arrowæ–¹å¼ï¼‰
- ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—åŒ–ï¼ˆPython GILå›é¿ï¼‰
- 4MiBèª­ã¿å–ã‚Šãƒãƒ£ãƒ³ã‚¯
- å…±æœ‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
- UNIXãƒ‰ãƒ¡ã‚¤ãƒ³ã‚½ã‚±ãƒƒãƒˆ

æœŸå¾…åŠ¹æœ: 2-3 GB/s (pg2arrowåŒç­‰)
"""

import os
import time
import math
import tempfile
import multiprocessing
import psycopg
import rmm
import numpy as np
import numba
from numba import cuda
import cupy as cp
import argparse
from concurrent.futures import ProcessPoolExecutor

from src.metadata import fetch_column_meta
from src.cuda_kernels.postgresql_binary_parser import detect_pg_header_size
from src.main_postgres_to_parquet import postgresql_to_cudf_parquet

TABLE_NAME = "lineorder"
OUTPUT_PARQUET_PATH = "benchmark/lineorder_pg2arrow_style.output.parquet"

# pg2arrowè¨­å®š
DEFAULT_PARALLEL = 8
UNIX_SOCKET_DSN = "dbname=postgres user=postgres host="
CHUNK_SIZE = 400 * 1024 * 1024  # 400MBï¼ˆå¤§å®¹é‡æœ€é©åŒ–ï¼‰

def check_gpu_direct_support():
    """GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª"""
    print("\n=== GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª ===")
    
    try:
        if os.path.exists("/proc/driver/nvidia-fs/stats"):
            print("âœ… nvidia-fs ãƒ‰ãƒ©ã‚¤ãƒæ¤œå‡º")
        else:
            print("âŒ nvidia-fs ãƒ‰ãƒ©ã‚¤ãƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
    except Exception:
        print("âŒ nvidia-fs ç¢ºèªã‚¨ãƒ©ãƒ¼")
        return False
    
    try:
        import kvikio
        print(f"âœ… kvikio ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {kvikio.__version__}")
        os.environ["KVIKIO_COMPAT_MODE"] = "OFF"
        print("âœ… KVIKIO_COMPAT_MODE=OFF è¨­å®šå®Œäº†")
        return True
    except ImportError:
        print("âŒ kvikio ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False

def get_table_blocks(dsn, table_name):
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’å–å¾—"""
    conn = psycopg.connect(dsn)
    try:
        with conn.cursor() as cur:
            cur.execute(f"SELECT pg_relation_size('{table_name}') / 8192 AS blocks")
            blocks = cur.fetchone()[0]
            return int(blocks)
    finally:
        conn.close()

def make_ctid_ranges(total_blocks, parallel_count):
    """ctidç¯„å›²ãƒªã‚¹ãƒˆç”Ÿæˆï¼ˆpg2arrowæ–¹å¼ï¼‰"""
    chunk_size = math.ceil(total_blocks / parallel_count)
    ranges = []
    
    for i in range(parallel_count):
        start_block = i * chunk_size
        end_block = min((i + 1) * chunk_size, total_blocks)
        if start_block < total_blocks:
            ranges.append((start_block, end_block))
    
    return ranges

def make_copy_sql_pg2arrow(table_name, start_block, end_block):
    """pg2arrowå®Œå…¨äº’æ›COPY SQLç”Ÿæˆ"""
    # pg2arrowæ–¹å¼: (block,1) ... < (end_block+1,1)
    sql = f"""
    COPY (
        SELECT * FROM {table_name}
        WHERE ctid >= '({start_block},1)'::tid
          AND ctid < '({end_block+1},1)'::tid
    ) TO STDOUT (FORMAT binary)
    """
    return sql

def worker_process(args):
    """ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆpg2arrowæ–¹å¼ï¼‰"""
    worker_id, dsn, start_block, end_block, shared_snapshot = args
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
    temp_file = os.path.join(
        tempfile.gettempdir(),
        f"pg2arrow_worker_{worker_id}_{start_block}_{end_block}.bin"
    )
    
    print(f"  Worker {worker_id}: ctidç¯„å›² ({start_block},{end_block}) é–‹å§‹... [ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—]")
    
    start_time = time.time()
    data_size = 0
    read_count = 0
    
    try:
        # pg2arrowæ–¹å¼: UNIXã‚½ã‚±ãƒƒãƒˆæ¥ç¶š
        conn = psycopg.connect(dsn)
        
        try:
            with conn.cursor() as cur:
                # å…±æœ‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆè¨­å®š
                if shared_snapshot:
                    cur.execute(f"BEGIN ISOLATION LEVEL REPEATABLE READ")
                    cur.execute(f"SET TRANSACTION SNAPSHOT '{shared_snapshot}'")
                    print(f"    Worker {worker_id}: å…±æœ‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆè¨­å®šå®Œäº†")
                
                # pg2arrowæ–¹å¼COPY SQL
                copy_sql = make_copy_sql_pg2arrow(TABLE_NAME, start_block, end_block)
                
                with cur.copy(copy_sql) as copy_obj:
                    with open(temp_file, 'wb') as f:
                        # pg2arrowæ–¹å¼: 4MiBãƒãƒ£ãƒ³ã‚¯èª­ã¿å–ã‚Š
                        buffer = bytearray()
                        
                        for chunk in copy_obj:
                            if chunk:
                                if isinstance(chunk, memoryview):
                                    chunk_bytes = chunk.tobytes()
                                else:
                                    chunk_bytes = bytes(chunk)
                                
                                buffer.extend(chunk_bytes)
                                
                                # 4MiBè“„ç©ã—ãŸã‚‰æ›¸ãè¾¼ã¿
                                if len(buffer) >= CHUNK_SIZE:
                                    f.write(buffer)
                                    data_size += len(buffer)
                                    read_count += 1
                                    
                                    if read_count <= 3:
                                        print(f"    Worker {worker_id}: ä¸€æ™‚ãƒãƒƒãƒ•ã‚¡æ›¸ãè¾¼ã¿{read_count}: {len(buffer)/(1024*1024):.1f}MB")
                                    
                                    buffer.clear()
                        
                        # æ®‹ã‚Šãƒãƒƒãƒ•ã‚¡
                        if buffer:
                            f.write(buffer)
                            data_size += len(buffer)
                            read_count += 1
                            print(f"    Worker {worker_id}: æœ€çµ‚ãƒãƒƒãƒ•ã‚¡æ›¸ãè¾¼ã¿: {len(buffer)/(1024*1024):.1f}MB")
        
        finally:
            conn.close()
    
    except Exception as e:
        print(f"  Worker {worker_id}: âŒã‚¨ãƒ©ãƒ¼ - {e}")
        return None
    
    duration = time.time() - start_time
    speed = data_size / (1024*1024) / duration if duration > 0 else 0
    
    print(f"  Worker {worker_id}: âœ…å®Œäº† ({duration:.2f}ç§’, {data_size/(1024*1024):.1f}MB, {speed:.1f}MB/sec)")
    
    return {
        'worker_id': worker_id,
        'temp_file': temp_file,
        'data_size': data_size,
        'duration': duration,
        'read_count': read_count,
        'speed': speed
    }

def run_bandwidth_test():
    """PCIeå¸¯åŸŸãƒ†ã‚¹ãƒˆ"""
    print("\n=== PCIeå¸¯åŸŸå¹…ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        size_mb = 1024
        host_data = np.random.randint(0, 256, size_mb * 1024 * 1024, dtype=np.uint8)
        
        start_time = time.time()
        device_data = cuda.to_device(host_data)
        htod_time = time.time() - start_time
        htod_speed = size_mb / htod_time
        
        start_time = time.time()
        result_data = device_data.copy_to_host()
        dtoh_time = time.time() - start_time
        dtoh_speed = size_mb / dtoh_time
        
        print(f"Hostâ†’Device: {htod_speed:.2f} MB/s")
        print(f"Deviceâ†’Host: {dtoh_speed:.2f} MB/s")
        
    except Exception as e:
        print(f"å¸¯åŸŸæ¸¬å®šã‚¨ãƒ©ãƒ¼: {e}")

def run_pg2arrow_benchmark(limit_rows=None, parallel_count=DEFAULT_PARALLEL):
    """pg2arrowå®Œå…¨å¯¾å¿œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    
    # DSNè¨­å®šï¼ˆUNIXã‚½ã‚±ãƒƒãƒˆå„ªå…ˆï¼‰
    dsn = os.environ.get("GPUPASER_PG_DSN", UNIX_SOCKET_DSN)
    if "host=" not in dsn or "host=" in dsn and dsn.split("host=")[1].split()[0] == "":
        print(f"âœ… UNIXãƒ‰ãƒ¡ã‚¤ãƒ³ã‚½ã‚±ãƒƒãƒˆæ¥ç¶šä½¿ç”¨")
    else:
        print(f"âš ï¸  TCPæ¥ç¶šä½¿ç”¨ï¼ˆUNIXã‚½ã‚±ãƒƒãƒˆæ¨å¥¨ï¼‰")
    
    print(f"=== PostgreSQL â†’ GPU pg2arrowå®Œå…¨å¯¾å¿œç‰ˆ ===")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME}")
    print(f"è¡Œæ•°åˆ¶é™: ãªã—ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰")
    print(f"ä¸¦åˆ—æ•°: {parallel_count}")
    print(f"æœ€é©åŒ–è¨­å®š:")
    print(f"  ctidæ–¹å¼: pg2arrowå®Œå…¨äº’æ› offset=1é–‹å§‹")
    print(f"  ä¸¦åˆ—åŒ–: ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—ï¼ˆPython GILå›é¿ï¼‰")
    print(f"  ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {CHUNK_SIZE/(1024*1024):.0f}MBï¼ˆå¤§å®¹é‡æœ€é©åŒ–ï¼‰")
    print(f"  æ¥ç¶š: UNIXãƒ‰ãƒ¡ã‚¤ãƒ³ã‚½ã‚±ãƒƒãƒˆ")
    
    # GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª
    gds_supported = check_gpu_direct_support()

    # PCIeå¸¯åŸŸãƒ†ã‚¹ãƒˆ
    run_bandwidth_test()
    
    # RMMåˆæœŸåŒ–
    try:
        if not rmm.is_initialized():
            rmm.reinitialize(
                pool_allocator=True, 
                initial_pool_size=22*1024**3
            )
            print("âœ… RMM ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–å®Œäº† (22GB)")
    except Exception as e:
        print(f"âŒ RMMåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return

    start_total_time = time.time()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    conn = psycopg.connect(dsn)
    try:
        print("\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        start_meta_time = time.time()
        columns = fetch_column_meta(conn, f"SELECT * FROM {TABLE_NAME}")
        meta_time = time.time() - start_meta_time
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({meta_time:.4f}ç§’)")
        ncols = len(columns)
    finally:
        conn.close()

    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°å–å¾—
    print("ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’å–å¾—ä¸­...")
    total_blocks = get_table_blocks(dsn, TABLE_NAME)
    print(f"ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°: {total_blocks:,}")
    
    # å…±æœ‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆï¼ˆpg2arrowæ–¹å¼ï¼‰
    print("å…±æœ‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆä¸­...")
    conn_snap = psycopg.connect(dsn)
    try:
        with conn_snap.cursor() as cur:
            cur.execute("BEGIN ISOLATION LEVEL REPEATABLE READ")
            cur.execute("SELECT pg_export_snapshot()")
            shared_snapshot = cur.fetchone()[0]
            print(f"âœ… å…±æœ‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆ: {shared_snapshot}")
    except Exception as e:
        print(f"âš ï¸  å…±æœ‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä½œæˆå¤±æ•—ï¼ˆç¶šè¡Œï¼‰: {e}")
        shared_snapshot = None
    finally:
        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿æŒã®ãŸã‚æ¥ç¶šç¶­æŒ
        pass
    
    # ctidç¯„å›²åˆ†å‰²
    ranges = make_ctid_ranges(total_blocks, parallel_count)
    print(f"ctidç¯„å›²åˆ†å‰²: {len(ranges)}å€‹ã®ç¯„å›² [pg2arrowæ–¹å¼]")
    for i, (start, end) in enumerate(ranges[:5]):
        print(f"  ç¯„å›² {i}: ãƒ–ãƒ­ãƒƒã‚¯ {start:,} - {end:,} (offset=1é–‹å§‹)")
    if len(ranges) > 5:
        print(f"  ... (æ®‹ã‚Š {len(ranges)-5} ç¯„å›²)")

    # ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—å®Ÿè¡Œï¼ˆpg2arrowæ–¹å¼ï¼‰
    print(f"\n{parallel_count}ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—COPYå‡¦ç†é–‹å§‹...")
    
    # ãƒ¯ãƒ¼ã‚«ãƒ¼å¼•æ•°æº–å‚™
    worker_args = []
    for i, (start_block, end_block) in enumerate(ranges):
        worker_args.append((i, dsn, start_block, end_block, shared_snapshot))
    
    # ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—å®Ÿè¡Œ
    start_copy_time = time.time()
    
    with ProcessPoolExecutor(max_workers=parallel_count) as executor:
        results = list(executor.map(worker_process, worker_args))
    
    copy_time = time.time() - start_copy_time
    
    # å…±æœ‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ¥ç¶šã‚¯ãƒ­ãƒ¼ã‚º
    try:
        conn_snap.close()
    except:
        pass
    
    # çµæœé›†è¨ˆ
    successful_results = [r for r in results if r is not None]
    failed_count = len(results) - len(successful_results)
    
    if not successful_results:
        print("âŒ ã™ã¹ã¦ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒå¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    total_data_size = sum(r['data_size'] for r in successful_results)
    total_read_count = sum(r['read_count'] for r in successful_results)
    
    print(f"âœ… {parallel_count}ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—COPYå®Œäº† ({copy_time:.4f}ç§’)")
    print(f"  æˆåŠŸãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {len(successful_results)}/{parallel_count}")
    if failed_count > 0:
        print(f"  å¤±æ•—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {failed_count}")
    print(f"  ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_data_size / (1024*1024):.2f} MB")
    print(f"  ç·èª­ã¿è¾¼ã¿å›æ•°: {total_read_count:,}")
    
    parallel_copy_speed = total_data_size / (1024*1024) / copy_time
    print(f"  ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—è»¢é€é€Ÿåº¦: {parallel_copy_speed:.2f} MB/sec")
    
    if parallel_count > 0:
        single_equiv_speed = parallel_copy_speed / parallel_count
        print(f"  å˜ä¸€ãƒ¯ãƒ¼ã‚«ãƒ¼æ›ç®—: {single_equiv_speed:.2f} MB/sec")

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ« â†’ GPUè»¢é€
    print(f"\nä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ« â†’ GPUè»¢é€é–‹å§‹...")
    start_gpu_time = time.time()
    
    if total_data_size > 0:
        gpu_buffer = rmm.DeviceBuffer(size=total_data_size)
        print(f"GPUãƒãƒƒãƒ•ã‚¡ç¢ºä¿å®Œäº†: {total_data_size / (1024*1024):.2f} MB")
        
        current_offset = 0
        gpu_transferred = 0
        
        for result in successful_results:
            temp_file = result['temp_file']
            file_size = result['data_size']
            
            try:
                if gds_supported:
                    # GPU Directè»¢é€
                    import kvikio
                    from kvikio import CuFile
                    
                    with CuFile(temp_file, "r") as cufile:
                        temp_buffer = rmm.DeviceBuffer(size=file_size)
                        future = cufile.pread(temp_buffer)
                        bytes_read = future.get()
                        
                        cp.cuda.runtime.memcpy(
                            gpu_buffer.ptr + current_offset,
                            temp_buffer.ptr,
                            file_size,
                            cp.cuda.runtime.memcpyDeviceToDevice
                        )
                        gpu_transferred += bytes_read
                else:
                    # é€šå¸¸è»¢é€
                    with open(temp_file, 'rb') as f:
                        file_data = f.read()
                    
                    host_array = np.frombuffer(file_data, dtype=np.uint8)
                    cp.cuda.runtime.memcpy(
                        gpu_buffer.ptr + current_offset,
                        host_array.ctypes.data,
                        file_size,
                        cp.cuda.runtime.memcpyHostToDevice
                    )
                    gpu_transferred += file_size
                
                current_offset += file_size
                os.remove(temp_file)
                
            except Exception as e:
                print(f"  Worker {result['worker_id']}: GPUè»¢é€ã‚¨ãƒ©ãƒ¼ - {e}")
    
    gpu_time = time.time() - start_gpu_time
    
    if gpu_transferred > 0:
        gpu_speed = gpu_transferred / (1024*1024) / gpu_time
        print(f"âœ… GPUè»¢é€å®Œäº† ({gpu_time:.4f}ç§’)")
        print(f"  GPUè»¢é€é€Ÿåº¦: {gpu_speed:.2f} MB/sec")
        
        # numba GPU ã‚¢ãƒ¬ã‚¤ã«å¤‰æ›
        print("GPU ãƒãƒƒãƒ•ã‚¡ã‚’ numba GPU ã‚¢ãƒ¬ã‚¤ã«å¤‰æ›ä¸­...")
        raw_dev = cuda.as_cuda_array(gpu_buffer).view(dtype=np.uint8)
        print(f"GPU ã‚¢ãƒ¬ã‚¤å¤‰æ›å®Œäº†: {raw_dev.shape[0]:,} bytes")

        # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºæ¤œå‡º
        header_sample = raw_dev[:min(128, raw_dev.shape[0])].copy_to_host()
        header_size = detect_pg_header_size(header_sample)
        print(f"ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º: {header_size} ãƒã‚¤ãƒˆ")

        # GPUæœ€é©åŒ–å‡¦ç†
        print("GPUæœ€é©åŒ–å‡¦ç†ä¸­...")
        start_processing_time = time.time()
        
        try:
            cudf_df, detailed_timing = postgresql_to_cudf_parquet(
                raw_dev=raw_dev,
                columns=columns,
                ncols=ncols,
                header_size=header_size,
                output_path=OUTPUT_PARQUET_PATH,
                compression='snappy',
                use_rmm=True,
                optimize_gpu=True
            )
            
            processing_time = time.time() - start_processing_time
            rows = len(cudf_df)
            parse_time = detailed_timing.get('gpu_parsing', 0)
            decode_time = detailed_timing.get('cudf_creation', 0)
            write_time = detailed_timing.get('parquet_export', 0)
            
            print(f"GPUæœ€é©åŒ–å‡¦ç†å®Œäº† ({processing_time:.4f}ç§’), è¡Œæ•°: {rows}")
            
        except Exception as e:
            print(f"GPUæœ€é©åŒ–å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
            return

        total_time = time.time() - start_total_time
        decimal_cols = sum(1 for col in columns if col.arrow_id == 5)
        
        print(f"\n=== pg2arrowå®Œå…¨å¯¾å¿œç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº† ===")
        print(f"ç·æ™‚é–“ = {total_time:.4f} ç§’")
        print("--- æ™‚é–“å†…è¨³ ---")
        print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—       : {meta_time:.4f} ç§’")
        print(f"  {parallel_count}ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—COPY  : {copy_time:.4f} ç§’")
        print(f"  GPUè»¢é€             : {gpu_time:.4f} ç§’")
        print(f"  GPUãƒ‘ãƒ¼ã‚¹           : {parse_time:.4f} ç§’")
        print(f"  GPUãƒ‡ã‚³ãƒ¼ãƒ‰         : {decode_time:.4f} ç§’")
        print(f"  Parquetæ›¸ãè¾¼ã¿     : {write_time:.4f} ç§’")
        print("--- çµ±è¨ˆæƒ…å ± ---")
        print(f"  å‡¦ç†è¡Œæ•°      : {rows:,} è¡Œ")
        print(f"  å‡¦ç†åˆ—æ•°      : {len(columns)} åˆ—")
        print(f"  Decimalåˆ—æ•°   : {decimal_cols} åˆ—")
        print(f"  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º  : {total_data_size / (1024*1024):.2f} MB")
        print(f"  ä¸¦åˆ—æ•°        : {parallel_count}")
        print(f"  æˆåŠŸãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {len(successful_results)}")
        
        total_cells = rows * len(columns)
        throughput = total_cells / decode_time if decode_time > 0 else 0
        
        print(f"  ã‚»ãƒ«å‡¦ç†é€Ÿåº¦        : {throughput:,.0f} cells/sec")
        print(f"  {parallel_count}ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—é€Ÿåº¦   : {parallel_copy_speed:.2f} MB/sec")
        print(f"  å˜ä¸€æ›ç®—é€Ÿåº¦        : {single_equiv_speed:.2f} MB/sec")
        print(f"  GPUè»¢é€é€Ÿåº¦         : {gpu_speed:.2f} MB/sec")
        
        # æ€§èƒ½å‘ä¸Šè©•ä¾¡
        baseline_speed = 129.1  # PostgreSQLå˜ä¸€COPYé€Ÿåº¦
        improvement_ratio = parallel_copy_speed / baseline_speed
        
        print(f"  æ€§èƒ½å‘ä¸Šå€ç‡        : {improvement_ratio:.1f}å€ (å¯¾PostgreSQLå˜ä¸€ {baseline_speed} MB/sec)")
        
        if parallel_copy_speed > 2000:
            performance_class = "ğŸ† pg2arrowç´š (2GB/s+)"
        elif parallel_copy_speed > 1000:
            performance_class = "ğŸ¥‡ é«˜é€Ÿ (1GB/s+)"
        elif parallel_copy_speed > 500:
            performance_class = "ğŸ¥ˆ ä¸­é€Ÿ (500MB/s+)"
        else:
            performance_class = "ğŸ¥‰ æ”¹å–„ä¸­"
        
        print(f"  æ€§èƒ½ã‚¯ãƒ©ã‚¹          : {performance_class}")
        
        print("--- pg2arrowå®Œå…¨å¯¾å¿œæœ€é©åŒ–åŠ¹æœ ---")
        print("  âœ… ctidç¯„å›²: pg2arrowæ–¹å¼ offset=1é–‹å§‹")
        print("  âœ… ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—: Python GILå®Œå…¨å›é¿")
        print("  âœ… 4MiBãƒãƒ£ãƒ³ã‚¯: pg2arrowåŒç­‰èª­ã¿å–ã‚Š")
        print("  âœ… å…±æœ‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ: MVCCæ•´åˆæ€§")
        print("  âœ… UNIXã‚½ã‚±ãƒƒãƒˆ: æœ€é«˜é€Ÿæ¥ç¶š")
        print("=========================================")

        # æ¤œè¨¼ç”¨å‡ºåŠ›
        print(f"\ncuDFæ¤œè¨¼ç”¨å‡ºåŠ›:")
        try:
            print(f"å‡ºåŠ›Parquet: {OUTPUT_PARQUET_PATH}")
            print(f"èª­ã¿è¾¼ã¿ç¢ºèª: {len(cudf_df):,} è¡Œ Ã— {len(cudf_df.columns)} åˆ—")
            print("âœ… cuDFæ¤œè¨¼: æˆåŠŸ")
        except Exception as e:
            print(f"âŒ cuDFæ¤œè¨¼: {e}")
    else:
        print("âŒ GPUè»¢é€ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='PostgreSQL â†’ GPU pg2arrowå®Œå…¨å¯¾å¿œç‰ˆ')
    parser.add_argument('--parallel', type=int, default=DEFAULT_PARALLEL, help='ä¸¦åˆ—æ•°')
    parser.add_argument('--bandwidth-test', action='store_true', help='å¸¯åŸŸãƒ†ã‚¹ãƒˆã®ã¿')
    parser.add_argument('--check-support', action='store_true', help='GPU Directã‚µãƒãƒ¼ãƒˆç¢ºèªã®ã¿')
    parser.add_argument('--check-blocks', action='store_true', help='ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°ç¢ºèªã®ã¿')
    
    args = parser.parse_args()
    
    try:
        cuda.current_context()
        print("âœ… CUDA context OK")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        exit(1)
    
    if args.check_support:
        check_gpu_direct_support()
        return
    
    if args.bandwidth_test:
        run_bandwidth_test()
        return
    
    if args.check_blocks:
        dsn = os.environ.get("GPUPASER_PG_DSN", UNIX_SOCKET_DSN)
        blocks = get_table_blocks(dsn, TABLE_NAME)
        print(f"ãƒ†ãƒ¼ãƒ–ãƒ« {TABLE_NAME} ã®ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°: {blocks:,}")
        ranges = make_ctid_ranges(blocks, args.parallel)
        print(f"{args.parallel}ä¸¦åˆ—ã§ã®ctidç¯„å›²åˆ†å‰²:")
        for i, (start, end) in enumerate(ranges):
            print(f"  ç¯„å›² {i}: ãƒ–ãƒ­ãƒƒã‚¯ {start:,} - {end:,}")
        return
    
    # pg2arrowå®Œå…¨å¯¾å¿œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    run_pg2arrow_benchmark(
        limit_rows=None,
        parallel_count=args.parallel
    )

if __name__ == "__main__":
    main()