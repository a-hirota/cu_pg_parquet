/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
Traceback (most recent call last):
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 147, in process_chunk_unified
    cudf_df, detailed_timing = postgresql_to_cudf_parquet(
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/main_postgres_to_parquet.py", line 560, in postgresql_to_cudf_parquet
    return processor.process_postgresql_to_parquet(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/main_postgres_to_parquet.py", line 420, in process_postgresql_to_parquet
    cudf_df, decode_timing = self.decode_and_export(
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/main_postgres_to_parquet.py", line 298, in decode_and_export
    buffer_info = self.gmm.initialize_buffers(columns, rows)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/memory_manager.py", line 228, in initialize_buffers
    var_data_buffer, var_offset_arrays = self.create_variable_buffers(var_layouts, rows)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/memory_manager.py", line 194, in create_variable_buffers
    var_data_buffer = cuda.device_array(total_size, dtype=np.uint8)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devices.py", line 232, in _require_cuda_context
    return fn(*args, **kws)
           ^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/api.py", line 144, in device_array
    return devicearray.DeviceNDArray(shape=shape, strides=strides, dtype=dtype,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 103, in __init__
    gpu_data = devices.get_context().memalloc(self.alloc_size)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/driver.py", line 1372, in memalloc
    return self.memory_manager.memalloc(bytesize)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/rmm/allocators/numba.py", line 73, in memalloc
    buf = pylibrmm.DeviceBuffer(size=size)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "device_buffer.pyx", line 102, in rmm.pylibrmm.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 7436376000 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 257, in main
    gpu_time, _, rows, timing = process_chunk_unified(chunk_info, columns)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 147, in process_chunk_unified
    cudf_df, detailed_timing = postgresql_to_cudf_parquet(
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/main_postgres_to_parquet.py", line 560, in postgresql_to_cudf_parquet
    return processor.process_postgresql_to_parquet(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/main_postgres_to_parquet.py", line 420, in process_postgresql_to_parquet
    cudf_df, decode_timing = self.decode_and_export(
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/main_postgres_to_parquet.py", line 298, in decode_and_export
    buffer_info = self.gmm.initialize_buffers(columns, rows)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/memory_manager.py", line 228, in initialize_buffers
    var_data_buffer, var_offset_arrays = self.create_variable_buffers(var_layouts, rows)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/memory_manager.py", line 194, in create_variable_buffers
    var_data_buffer = cuda.device_array(total_size, dtype=np.uint8)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devices.py", line 232, in _require_cuda_context
    return fn(*args, **kws)
           ^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/api.py", line 144, in device_array
    return devicearray.DeviceNDArray(shape=shape, strides=strides, dtype=dtype,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 103, in __init__
    gpu_data = devices.get_context().memalloc(self.alloc_size)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/driver.py", line 1372, in memalloc
    return self.memory_manager.memalloc(bytesize)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/rmm/allocators/numba.py", line 73, in memalloc
    buf = pylibrmm.DeviceBuffer(size=size)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "device_buffer.pyx", line 102, in rmm.pylibrmm.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 7436376000 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
=== PostgreSQL â†’ Rust â†’ GPU çµ±ä¸€å‡¦ç†ç‰ˆ ===
ãƒãƒ£ãƒ³ã‚¯æ•°: 6
å„ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: ç´„8.8 GB
å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: /dev/shm

æ”¹å–„å†…å®¹:
  - cuda.to_device()ã§ç›´æ¥GPUè»¢é€
  - postgresql_to_cudf_parquet()ã§ä¸€æ‹¬å‡¦ç†
  - cuDF DataFrameä½œæˆã®CPUã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰å•é¡Œã‚’è§£æ±º
RMMæ—¢ã«åˆæœŸåŒ–æ¸ˆã¿

âœ… CUDA context OK

[Rust] ãƒãƒ£ãƒ³ã‚¯ 1/6 è»¢é€é–‹å§‹
[Rust] ãƒãƒ£ãƒ³ã‚¯ 1 è»¢é€å®Œäº†: 8.75 GB, 6.22ç§’ (1.41 GB/ç§’)
ã‚«ãƒ©ãƒ æ•°: 17

[GPU] ãƒãƒ£ãƒ³ã‚¯ 1 çµ±ä¸€å‡¦ç†é–‹å§‹
  ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: 4.61ç§’ (1.90 GB/ç§’)
  GPUè»¢é€: 0.70ç§’ (12.42 GB/ç§’)
=== GPUä¸¦åˆ—ãƒ‘ãƒ¼ã‚¹é–‹å§‹ ===
âœ… Ultra Fast GPUä¸¦åˆ—ãƒ‘ãƒ¼ã‚µãƒ¼ä½¿ç”¨ï¼ˆ8.94å€é«˜é€ŸåŒ–é”æˆï¼‰
GPUãƒ‘ãƒ¼ã‚¹å®Œäº†: 18590940 è¡Œ (6.7340ç§’)
=== æ–‡å­—åˆ—æœ€é©åŒ–ãƒ‡ã‚³ãƒ¼ãƒ‰é–‹å§‹ ===
æ–‡å­—åˆ—åˆ— lo_orderpriority: ç›´æ¥ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
âœ… æ–‡å­—åˆ—åˆ— lo_orderpriority: æœ€é©åŒ–ãƒãƒƒãƒ•ã‚¡ä½œæˆå®Œäº† (278864100 bytes)
æ–‡å­—åˆ—åˆ— lo_shippriority: ç›´æ¥ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
âœ… æ–‡å­—åˆ—åˆ— lo_shippriority: æœ€é©åŒ–ãƒãƒƒãƒ•ã‚¡ä½œæˆå®Œäº† (18590940 bytes)
æ–‡å­—åˆ—åˆ— lo_commit_date: ç›´æ¥ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
âœ… æ–‡å­—åˆ—åˆ— lo_commit_date: æœ€é©åŒ–ãƒãƒƒãƒ•ã‚¡ä½œæˆå®Œäº† (148727520 bytes)
æ–‡å­—åˆ—åˆ— lo_shipmode: ç›´æ¥ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
âœ… æ–‡å­—åˆ—åˆ— lo_shipmode: æœ€é©åŒ–ãƒãƒƒãƒ•ã‚¡ä½œæˆå®Œäº† (185909400 bytes)
âŒ GPUå‡¦ç†ã‚¨ãƒ©ãƒ¼: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 7436376000 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp

âŒ ã‚¨ãƒ©ãƒ¼: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 7436376000 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 292, in <module>
    main()
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 257, in main
    gpu_time, _, rows, timing = process_chunk_unified(chunk_info, columns)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 147, in process_chunk_unified
    cudf_df, detailed_timing = postgresql_to_cudf_parquet(
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/main_postgres_to_parquet.py", line 560, in postgresql_to_cudf_parquet
    return processor.process_postgresql_to_parquet(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/main_postgres_to_parquet.py", line 420, in process_postgresql_to_parquet
    cudf_df, decode_timing = self.decode_and_export(
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/main_postgres_to_parquet.py", line 298, in decode_and_export
    buffer_info = self.gmm.initialize_buffers(columns, rows)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/memory_manager.py", line 228, in initialize_buffers
    var_data_buffer, var_offset_arrays = self.create_variable_buffers(var_layouts, rows)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/src/memory_manager.py", line 194, in create_variable_buffers
    var_data_buffer = cuda.device_array(total_size, dtype=np.uint8)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devices.py", line 232, in _require_cuda_context
    return fn(*args, **kws)
           ^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/api.py", line 144, in device_array
    return devicearray.DeviceNDArray(shape=shape, strides=strides, dtype=dtype,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 103, in __init__
    gpu_data = devices.get_context().memalloc(self.alloc_size)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/driver.py", line 1372, in memalloc
    return self.memory_manager.memalloc(bytesize)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/rmm/allocators/numba.py", line 73, in memalloc
    buf = pylibrmm.DeviceBuffer(size=size)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "device_buffer.pyx", line 102, in rmm.pylibrmm.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 7436376000 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
