"""
PostgreSQL â†’ GPU Rayä¸¦åˆ— é †æ¬¡GPUå‡¦ç†ç‰ˆï¼ˆè©³ç´°ãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰
psycopg3ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æç”¨ã®è©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ©Ÿèƒ½ä»˜ã

æœ€é©åŒ–:
- 16ä¸¦åˆ—ã§PostgreSQL COPYã‚’å®Ÿè¡Œ
- GPUå‡¦ç†ã¯1ã¤ãšã¤é †æ¬¡å®Ÿè¡Œï¼ˆãƒ¡ãƒ¢ãƒªç«¶åˆå›é¿ï¼‰
- CuPyé…åˆ—ã«ã‚ˆã‚‹å®‰å®šã—ãŸãƒ¡ãƒ¢ãƒªç®¡ç†
- 64å€‹ã®ç‹¬ç«‹ã—ãŸParquetãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›

ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½:
- psycopg3ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºå¯è¦–åŒ–
- è©³ç´°ã‚¿ã‚¤ãƒŸãƒ³ã‚°æ¸¬å®š
- CSV/JSONçµæœå‡ºåŠ›

ç’°å¢ƒå¤‰æ•°:
GPUPASER_PG_DSN  : PostgreSQLæ¥ç¶šæ–‡å­—åˆ—
"""

import os
import time
import math
import tempfile
import psycopg
import ray
import gc
import numpy as np
from numba import cuda
import argparse
from typing import List, Dict, Tuple, Optional
import json
import csv
from datetime import datetime

from src.metadata import fetch_column_meta
from src.cuda_kernels.postgresql_binary_parser import detect_pg_header_size
from src.main_postgres_to_parquet import postgresql_to_cudf_parquet

TABLE_NAME = "lineorder"
OUTPUT_PARQUET_PATH = "benchmark/lineorder_parallel_ctid_ray_sequential_gpu_debug.output"
DEBUG_OUTPUT_DIR = "benchmark/debug_output"

# ä¸¦åˆ—è¨­å®š
DEFAULT_PARALLEL = 16
CHUNK_COUNT = 4  # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ctidç¯„å›²ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²

# ãƒ‡ãƒãƒƒã‚°ç”¨ã‚°ãƒ­ãƒ¼ãƒãƒ«çµ±è¨ˆ
DEBUG_STATS = {
    'chunk_sizes': [],
    'chunk_times': [],
    'connection_times': [],
    'copy_init_times': [],
    'buffer_operations': []
}

@ray.remote
class PostgreSQLWorker:
    """Rayä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼: PostgreSQL COPYå°‚ç”¨ï¼ˆãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ä»˜ãï¼‰"""
    
    def __init__(self, worker_id: int, dsn: str):
        self.worker_id = worker_id
        self.dsn = dsn
        self.debug_stats = {
            'chunks_received': [],
            'chunk_times': [],
            'buffer_resizes': 0
        }
        
    def copy_data_to_memory(
        self, 
        table_name: str,
        start_block: int, 
        end_block: int,
        chunk_idx: int,
        total_chunks: int,
        limit_rows: Optional[int] = None,
        initial_buffer_size: int = 64 * 1024 * 1024,  # 64MB
        debug_mode: bool = True
    ) -> Dict[str, any]:
        """PostgreSQLã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’COPYã—ã¦ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ï¼ˆè©³ç´°ãƒ‡ãƒãƒƒã‚°ä»˜ãï¼‰"""
        
        # ãƒãƒ£ãƒ³ã‚¯ã«å¿œã˜ã¦ctidç¯„å›²ã‚’åˆ†å‰²
        block_range = end_block - start_block
        chunk_block_size = block_range // total_chunks
        
        chunk_start_block = start_block + (chunk_idx * chunk_block_size)
        chunk_end_block = start_block + ((chunk_idx + 1) * chunk_block_size) if chunk_idx < total_chunks - 1 else end_block
        
        print(f"Worker {self.worker_id}-Chunk{chunk_idx}: COPYé–‹å§‹ ctidç¯„å›² ({chunk_start_block},{chunk_end_block})...")
        
        start_time = time.time()
        timing_details = {
            'connection': 0,
            'copy_init': 0,
            'chunk_reads': [],
            'buffer_ops': 0,
            'total': 0
        }
        
        try:
            # PostgreSQLæ¥ç¶š
            conn_start = time.time()
            conn = psycopg.connect(self.dsn)
            timing_details['connection'] = time.time() - conn_start
            
            # é€šå¸¸ã®bytearrayã‚’ä½¿ç”¨ï¼ˆRayãƒ¯ãƒ¼ã‚«ãƒ¼ã§ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªç¢ºä¿ã¯å›°é›£ï¼‰
            buffer = bytearray()
            chunk_count = 0
            total_bytes = 0
            
            try:
                # COPY SQLç”Ÿæˆ
                copy_sql = self._make_copy_sql(table_name, chunk_start_block, chunk_end_block, limit_rows)
                
                # ãƒ‡ãƒ¼ã‚¿å–å¾—
                copy_init_start = time.time()
                with conn.cursor() as cur:
                    with cur.copy(copy_sql) as copy_obj:
                        timing_details['copy_init'] = time.time() - copy_init_start
                        
                        for chunk in copy_obj:
                            chunk_start = time.time()
                            if chunk:
                                # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºè¨˜éŒ²
                                chunk_size = len(chunk)
                                chunk_count += 1
                                
                                # memoryview â†’ byteså¤‰æ›
                                if isinstance(chunk, memoryview):
                                    chunk_bytes = chunk.tobytes()
                                else:
                                    chunk_bytes = bytes(chunk)
                                
                                # bytearrayã«è¿½åŠ 
                                buffer_start = time.time()
                                buffer.extend(chunk_bytes)
                                buffer_time = time.time() - buffer_start
                                
                                chunk_time = time.time() - chunk_start
                                total_bytes += chunk_size
                                
                                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¨˜éŒ²
                                if debug_mode:
                                    timing_details['chunk_reads'].append({
                                        'chunk_num': chunk_count,
                                        'size': chunk_size,
                                        'time': chunk_time,
                                        'buffer_time': buffer_time,
                                        'cumulative_size': total_bytes
                                    })
                                    
                                    # 10ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«é€²æ—è¡¨ç¤º
                                    if chunk_count % 10 == 0:
                                        avg_chunk_size = total_bytes / chunk_count
                                        print(f"  Worker{self.worker_id}-Chunk{chunk_idx}: "
                                              f"{chunk_count}ãƒãƒ£ãƒ³ã‚¯èª­è¾¼æ¸ˆ "
                                              f"(å¹³å‡{avg_chunk_size/1024:.1f}KB/chunk, "
                                              f"åˆè¨ˆ{total_bytes/(1024*1024):.1f}MB)")
                
                copy_time = time.time() - start_time
                data_size = len(buffer)  # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º
                
                print(f"Worker {self.worker_id}-Chunk{chunk_idx}: COPYå®Œäº† "
                      f"({copy_time:.2f}ç§’, {data_size/(1024*1024):.1f}MB, "
                      f"{chunk_count}ãƒãƒ£ãƒ³ã‚¯)")
                
                # ãƒ‡ãƒãƒƒã‚°çµ±è¨ˆã‚µãƒãƒªãƒ¼
                if debug_mode and timing_details['chunk_reads']:
                    avg_chunk_size = np.mean([c['size'] for c in timing_details['chunk_reads']])
                    max_chunk_size = max([c['size'] for c in timing_details['chunk_reads']])
                    min_chunk_size = min([c['size'] for c in timing_details['chunk_reads']])
                    
                    print(f"  ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºçµ±è¨ˆ: å¹³å‡{avg_chunk_size/1024:.1f}KB, "
                          f"æœ€å°{min_chunk_size/1024:.1f}KB, æœ€å¤§{max_chunk_size/1024:.1f}KB")
                
                timing_details['total'] = copy_time
                
                # bytearrayã‚’bytesã«å¤‰æ›ã—ã¦è¿”ã™
                return {
                    'worker_id': self.worker_id,
                    'chunk_idx': chunk_idx,
                    'data': bytes(buffer),  # bytesã«å¤‰æ›ã—ã¦ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ã«
                    'data_size': data_size,
                    'copy_time': copy_time,
                    'chunk_count': chunk_count,
                    'timing_details': timing_details,
                    'status': 'success'
                }
                
            finally:
                conn.close()
                
        except Exception as e:
            print(f"Worker {self.worker_id}-Chunk{chunk_idx}: âŒCOPYå¤±æ•— - {e}")
            return {
                'worker_id': self.worker_id,
                'chunk_idx': chunk_idx,
                'status': 'error',
                'error': str(e),
                'copy_time': time.time() - start_time,
                'timing_details': timing_details
            }
    
    def _make_copy_sql(self, table_name: str, start_block: int, end_block: int, limit_rows: Optional[int]) -> str:
        """COPY SQLç”Ÿæˆ"""
        sql = f"""
        COPY (
            SELECT * FROM {table_name}
            WHERE ctid >= '({start_block},1)'::tid
              AND ctid < '({end_block+1},1)'::tid
        """
        
        if limit_rows:
            # 64ã‚¿ã‚¹ã‚¯å…¨ä½“ã§ã®è¡Œæ•°åˆ¶é™
            sql += f" LIMIT {limit_rows // (DEFAULT_PARALLEL * CHUNK_COUNT)}"
        
        sql += ") TO STDOUT (FORMAT binary)"
        return sql


def process_batch_on_gpu(
    batch_tasks: List[Dict],
    columns: List,
    gds_supported: bool,
    output_base: str,
    debug_mode: bool = True
) -> List[Dict]:
    """è¤‡æ•°ã®ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã‚’çµåˆã—ã¦1å›ã®GPUå‡¦ç†ã§å®Ÿè¡Œï¼ˆãƒ‡ãƒãƒƒã‚°ä»˜ãï¼‰"""
    
    import cupy as cp  # ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    
    num_tasks = len(batch_tasks)
    print(f"\nğŸ“Š ãƒãƒƒãƒGPUå‡¦ç†é–‹å§‹: {num_tasks}å€‹ã®ã‚¿ã‚¹ã‚¯ã‚’çµ±åˆå‡¦ç†")
    
    results = []
    start_total_time = time.time()
    timing_breakdown = {
        'pinned_alloc': 0,
        'data_copy_to_pinned': 0,
        'gpu_alloc': 0,
        'gpu_transfer': 0,
        'gpu_processing': [],
        'memory_cleanup': 0
    }
    
    try:
        # 1. å…¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        total_size = sum(task['data_size'] for task in batch_tasks)
        print(f"  çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size/(1024*1024):.2f} MB")
        
        # 2. cupyxã®é«˜ãƒ¬ãƒ™ãƒ«APIã‚’ä½¿ç”¨ã—ã¦ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªé…åˆ—ã‚’ä½œæˆ
        pinned_start = time.time()
        import cupyx
        pinned_array = cupyx.zeros_pinned(total_size, dtype=np.uint8)
        timing_breakdown['pinned_alloc'] = time.time() - pinned_start
        
        # 3. å„ã‚¿ã‚¹ã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªã«ã‚³ãƒ”ãƒ¼
        copy_start = time.time()
        task_offsets = []
        current_offset = 0
        
        for task in batch_tasks:
            # ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªã«ã‚³ãƒ”ãƒ¼
            data_len = task['data_size']
            pinned_array[current_offset:current_offset + data_len] = np.frombuffer(task['data'], dtype=np.uint8)
            
            task_offsets.append({
                'worker_id': task['worker_id'],
                'chunk_idx': task['chunk_idx'],
                'offset': current_offset,
                'size': task['data_size']
            })
            current_offset += task['data_size']
        
        timing_breakdown['data_copy_to_pinned'] = time.time() - copy_start
        
        # 4. GPUé…åˆ—ã‚’ç¢ºä¿ã—ã€ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªã‹ã‚‰é«˜é€Ÿè»¢é€ï¼ˆset()ã‚’ä½¿ç”¨ï¼‰
        gpu_alloc_start = time.time()
        gpu_array = cp.empty(total_size, dtype=cp.uint8)
        timing_breakdown['gpu_alloc'] = time.time() - gpu_alloc_start
        
        gpu_transfer_start = time.time()
        gpu_array.set(pinned_array)  # åŠ¹ç‡çš„ãªã‚³ãƒ”ãƒ¼æ–¹æ³•
        cuda.synchronize()  # è»¢é€å®Œäº†ã‚’å¾…ã¤
        timing_breakdown['gpu_transfer'] = time.time() - gpu_transfer_start
        
        gpu_transfer_bandwidth = (total_size / (1024**3)) / timing_breakdown['gpu_transfer']  # GB/s
        print(f"  GPUè»¢é€å®Œäº† ({timing_breakdown['gpu_transfer']:.2f}ç§’, {gpu_transfer_bandwidth:.2f} GB/s)")
        
        # 5. çµ±åˆãƒ‡ãƒ¼ã‚¿ã§1å›ã®GPUå‡¦ç†ã‚’å®Ÿè¡Œ
        start_gpu_processing_time = time.time()
        
        # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å€‹åˆ¥ã«å‡¦ç†ï¼ˆå°†æ¥çš„ã«ã¯çµ±åˆå‡¦ç†ã«æ‹¡å¼µå¯èƒ½ï¼‰
        for i, (task, offset_info) in enumerate(zip(batch_tasks, task_offsets)):
            gpu_task_start = time.time()
            print(f"\n  å‡¦ç†ä¸­ [{i+1}/{num_tasks}]: Worker{offset_info['worker_id']}-Chunk{offset_info['chunk_idx']}")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ‡ã‚Šå‡ºã—
            dataset_gpu = gpu_array[offset_info['offset']:offset_info['offset'] + offset_info['size']]
            
            # numbaç”¨ã®é…åˆ—ã«å¤‰æ›
            raw_dev = cuda.as_cuda_array(dataset_gpu)
            header_sample = dataset_gpu[:min(128, len(dataset_gpu))].get()
            header_size = detect_pg_header_size(header_sample)
            
            # å‡ºåŠ›ãƒ‘ã‚¹
            output_path = f"{output_base}_worker{offset_info['worker_id']}_chunk{offset_info['chunk_idx']}.parquet"
            
            # GPUæœ€é©åŒ–å‡¦ç†
            cudf_df, detailed_timing = postgresql_to_cudf_parquet(
                raw_dev=raw_dev,
                columns=columns,
                ncols=len(columns),
                header_size=header_size,
                output_path=output_path,
                compression='snappy',
                use_rmm=False,
                optimize_gpu=True
            )
            
            gpu_task_time = time.time() - gpu_task_start
            timing_breakdown['gpu_processing'].append({
                'task_id': f"Worker{offset_info['worker_id']}-Chunk{offset_info['chunk_idx']}",
                'time': gpu_task_time,
                'rows': len(cudf_df),
                'detailed': detailed_timing
            })
            
            results.append({
                'worker_id': offset_info['worker_id'],
                'chunk_idx': offset_info['chunk_idx'],
                'gpu_transfer_time': timing_breakdown['gpu_transfer'] / num_tasks,  # è»¢é€æ™‚é–“ã‚’åˆ†é…
                'gpu_processing_time': gpu_task_time,
                'rows_processed': len(cudf_df),
                'status': 'success'
            })
        
        gpu_processing_time = time.time() - start_gpu_processing_time
        total_time = time.time() - start_total_time
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        cleanup_start = time.time()
        del gpu_array
        gc.collect()
        cp.get_default_memory_pool().free_all_blocks()
        cuda.synchronize()
        timing_breakdown['memory_cleanup'] = time.time() - cleanup_start
        
        print(f"\nâœ… ãƒãƒƒãƒGPUå‡¦ç†å®Œäº†:")
        print(f"  ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
        if debug_mode:
            print(f"  --- è©³ç´°ã‚¿ã‚¤ãƒŸãƒ³ã‚° ---")
            print(f"  ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªç¢ºä¿: {timing_breakdown['pinned_alloc']:.3f}ç§’")
            print(f"  ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼: {timing_breakdown['data_copy_to_pinned']:.3f}ç§’")
            print(f"  GPUé…åˆ—ç¢ºä¿: {timing_breakdown['gpu_alloc']:.3f}ç§’")
            print(f"  GPUè»¢é€: {timing_breakdown['gpu_transfer']:.3f}ç§’ ({gpu_transfer_bandwidth:.2f} GB/s)")
            print(f"  GPUå‡¦ç†: {gpu_processing_time:.3f}ç§’")
            print(f"  ãƒ¡ãƒ¢ãƒªè§£æ”¾: {timing_breakdown['memory_cleanup']:.3f}ç§’")
        print(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {(total_size/(1024*1024))/total_time:.2f} MB/sec")
        
        # ã‚¿ã‚¤ãƒŸãƒ³ã‚°è©³ç´°ã‚’çµæœã«è¿½åŠ 
        for result in results:
            result['timing_breakdown'] = timing_breakdown
        
        return results
        
    except Exception as e:
        print(f"  âŒãƒãƒƒãƒGPUå‡¦ç†å¤±æ•—: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å€‹åˆ¥ã«ã‚¨ãƒ©ãƒ¼çµæœã‚’è¿”ã™
        for task in batch_tasks:
            results.append({
                'worker_id': task['worker_id'],
                'chunk_idx': task['chunk_idx'],
                'status': 'error',
                'error': str(e),
                'timing_breakdown': timing_breakdown
            })
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾ã‚’è©¦ã¿ã‚‹
        try:
            gc.collect()
            cp.get_default_memory_pool().free_all_blocks()
            cuda.synchronize()
        except:
            pass
            
        return results


def save_debug_results(all_results: Dict, output_dir: str = DEBUG_OUTPUT_DIR):
    """ãƒ‡ãƒãƒƒã‚°çµæœã‚’CSVã¨JSONã§ä¿å­˜"""
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # JSONå‡ºåŠ›ï¼ˆå…¨è©³ç´°ï¼‰
    json_path = os.path.join(output_dir, f"debug_results_{timestamp}.json")
    with open(json_path, 'w') as f:
        json.dump(all_results, f, indent=2)
    print(f"\nâœ… è©³ç´°çµæœã‚’JSONä¿å­˜: {json_path}")
    
    # CSVå‡ºåŠ›ï¼ˆã‚µãƒãƒªãƒ¼ï¼‰
    csv_path = os.path.join(output_dir, f"debug_summary_{timestamp}.csv")
    with open(csv_path, 'w', newline='') as f:
        writer = csv.writer(f)
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow([
            'worker_id', 'chunk_idx', 'status',
            'data_size_mb', 'copy_time', 'chunk_count',
            'avg_chunk_kb', 'connection_time', 'copy_init_time',
            'gpu_transfer_time', 'gpu_processing_time', 'rows_processed'
        ])
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for copy_result in all_results['copy_results']:
            if copy_result['status'] == 'success':
                # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºçµ±è¨ˆ
                chunk_reads = copy_result.get('timing_details', {}).get('chunk_reads', [])
                avg_chunk_kb = 0
                if chunk_reads:
                    avg_chunk_kb = np.mean([c['size'] for c in chunk_reads]) / 1024
                
                # å¯¾å¿œã™ã‚‹GPUçµæœã‚’æ¢ã™
                gpu_result = next(
                    (g for g in all_results['gpu_results'] 
                     if g['worker_id'] == copy_result['worker_id'] 
                     and g['chunk_idx'] == copy_result['chunk_idx']),
                    {}
                )
                
                writer.writerow([
                    copy_result['worker_id'],
                    copy_result['chunk_idx'],
                    copy_result['status'],
                    copy_result['data_size'] / (1024*1024),
                    copy_result['copy_time'],
                    copy_result.get('chunk_count', 0),
                    avg_chunk_kb,
                    copy_result.get('timing_details', {}).get('connection', 0),
                    copy_result.get('timing_details', {}).get('copy_init', 0),
                    gpu_result.get('gpu_transfer_time', 0),
                    gpu_result.get('gpu_processing_time', 0),
                    gpu_result.get('rows_processed', 0)
                ])
    
    print(f"âœ… ã‚µãƒãƒªãƒ¼ã‚’CSVä¿å­˜: {csv_path}")
    
    # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºåˆ†æ
    analyze_chunk_sizes(all_results, output_dir, timestamp)


def analyze_chunk_sizes(all_results: Dict, output_dir: str, timestamp: str):
    """ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®è©³ç´°åˆ†æ"""
    chunk_sizes = []
    
    for copy_result in all_results['copy_results']:
        if copy_result['status'] == 'success':
            chunk_reads = copy_result.get('timing_details', {}).get('chunk_reads', [])
            chunk_sizes.extend([c['size'] for c in chunk_reads])
    
    if chunk_sizes:
        print(f"\n=== psycopg3ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºåˆ†æ ===")
        print(f"ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {len(chunk_sizes)}")
        print(f"å¹³å‡ã‚µã‚¤ã‚º: {np.mean(chunk_sizes)/1024:.1f} KB")
        print(f"ä¸­å¤®å€¤: {np.median(chunk_sizes)/1024:.1f} KB")
        print(f"æœ€å°: {min(chunk_sizes)/1024:.1f} KB")
        print(f"æœ€å¤§: {max(chunk_sizes)/1024:.1f} KB")
        print(f"æ¨™æº–åå·®: {np.std(chunk_sizes)/1024:.1f} KB")
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ºåŠ›
        hist_path = os.path.join(output_dir, f"chunk_size_histogram_{timestamp}.txt")
        with open(hist_path, 'w') as f:
            f.write("=== ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºåˆ†å¸ƒ ===\n")
            hist, bins = np.histogram(chunk_sizes, bins=20)
            for i in range(len(hist)):
                size_kb = bins[i] / 1024
                count = hist[i]
                f.write(f"{size_kb:6.1f}KB - {bins[i+1]/1024:6.1f}KB: {'#' * min(count, 50)} ({count})\n")
        
        print(f"âœ… ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºåˆ†å¸ƒã‚’ä¿å­˜: {hist_path}")


def get_table_blocks(dsn: str, table_name: str) -> int:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’å–å¾—"""
    conn = psycopg.connect(dsn)
    try:
        with conn.cursor() as cur:
            cur.execute(f"SELECT pg_relation_size('{table_name}') / 8192 AS blocks")
            blocks = cur.fetchone()[0]
            return int(blocks)
    finally:
        conn.close()


def make_ctid_ranges(total_blocks: int, parallel_count: int) -> List[Tuple[int, int]]:
    """ctidç¯„å›²ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    chunk_size = math.ceil(total_blocks / parallel_count)
    ranges = []
    
    for i in range(parallel_count):
        start_block = i * chunk_size
        end_block = min((i + 1) * chunk_size, total_blocks)
        if start_block < total_blocks:
            ranges.append((start_block, end_block))
    
    return ranges


def check_gpu_direct_support() -> bool:
    """GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª"""
    print("\n=== GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª ===")
    
    try:
        if os.path.exists("/proc/driver/nvidia-fs/stats"):
            print("âœ… nvidia-fs ãƒ‰ãƒ©ã‚¤ãƒæ¤œå‡º")
        else:
            print("âš ï¸  nvidia-fs ãƒ‰ãƒ©ã‚¤ãƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
    except Exception:
        print("âš ï¸  nvidia-fs ç¢ºèªã‚¨ãƒ©ãƒ¼")
        return False
    
    try:
        import kvikio
        print(f"âœ… kvikio ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {kvikio.__version__}")
        os.environ["KVIKIO_COMPAT_MODE"] = "OFF"
        print("âœ… KVIKIO_COMPAT_MODE=OFF è¨­å®šå®Œäº†")
        return True
    except ImportError:
        print("âš ï¸  kvikio ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False


def run_ray_parallel_sequential_gpu_debug(
    limit_rows: int = 10000000,
    parallel_count: int = DEFAULT_PARALLEL,
    use_gpu_direct: bool = True,
    batch_size: int = 4,
    debug_mode: bool = True
):
    """Rayä¸¦åˆ—COPY + é †æ¬¡GPUå‡¦ç†ï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
    
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    print(f"=== PostgreSQL â†’ GPU Rayä¸¦åˆ— é †æ¬¡GPUå‡¦ç†ç‰ˆï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰ ===")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME}")
    print(f"è¡Œæ•°åˆ¶é™: {limit_rows:,}" if limit_rows else "è¡Œæ•°åˆ¶é™: ãªã—ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰")
    print(f"ä¸¦åˆ—æ•°: {parallel_count}")
    print(f"ãƒãƒ£ãƒ³ã‚¯æ•°: {CHUNK_COUNT}")
    print(f"ç·ã‚¿ã‚¹ã‚¯æ•°: {parallel_count * CHUNK_COUNT}")
    print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
    print(f"ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: {'ON' if debug_mode else 'OFF'}")
    print(f"å‡¦ç†æ–¹å¼:")
    print(f"  â‘  CPU: {parallel_count}ä¸¦åˆ—ã§PostgreSQL COPYå®Ÿè¡Œ")
    print(f"  â‘¡ GPU: ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ï¼ˆ{batch_size}å€‹ã®COPYå®Œäº†ã”ã¨ã«GPUå‡¦ç†é–‹å§‹ï¼‰")
    
    # GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª
    gds_supported = check_gpu_direct_support() if use_gpu_direct else False
    
    # RayåˆæœŸåŒ–ï¼ˆGPUæŒ‡å®šãªã—ï¼‰
    print("\n=== RayåˆæœŸåŒ– ===")
    if not ray.is_initialized():
        ray.init(num_cpus=parallel_count * 2)
        print(f"âœ… RayåˆæœŸåŒ–å®Œäº†")
    
    start_total_time = time.time()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    print("\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    start_meta_time = time.time()
    conn = psycopg.connect(dsn)
    try:
        columns = fetch_column_meta(conn, f"SELECT * FROM {TABLE_NAME}")
        meta_time = time.time() - start_meta_time
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({meta_time:.4f}ç§’)")
    finally:
        conn.close()
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°å–å¾—
    print("ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’å–å¾—ä¸­...")
    total_blocks = get_table_blocks(dsn, TABLE_NAME)
    print(f"ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°: {total_blocks:,}")
    
    # ctidç¯„å›²åˆ†å‰²
    ranges = make_ctid_ranges(total_blocks, parallel_count)
    print(f"ctidç¯„å›²åˆ†å‰²: {len(ranges)}å€‹ã®ç¯„å›²")
    
    # Rayä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ä½œæˆ
    workers = []
    for i in range(len(ranges)):
        worker = PostgreSQLWorker.remote(i, dsn)
        workers.append(worker)
    
    # å…¨ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹
    print(f"\n=== ãƒ•ã‚§ãƒ¼ã‚º1: PostgreSQL COPYä¸¦åˆ—å®Ÿè¡Œ ===")
    all_copy_futures = []
    
    for worker_idx, (start_block, end_block) in enumerate(ranges):
        for chunk_idx in range(CHUNK_COUNT):
            future = workers[worker_idx].copy_data_to_memory.remote(
                TABLE_NAME, start_block, end_block, chunk_idx, CHUNK_COUNT, 
                limit_rows, debug_mode=debug_mode
            )
            all_copy_futures.append(future)
    
    print(f"âœ… {len(all_copy_futures)}å€‹ã®COPYã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥")
    
    # ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†: COPYã¨GPUã‚’ä¸¦è¡Œå®Ÿè¡Œ
    copy_results = []
    gpu_results = []
    pending_gpu_tasks = []  # GPUå‡¦ç†å¾…ã¡ã®ã‚¿ã‚¹ã‚¯
    
    total_copy_time = 0
    total_data_size = 0
    total_gpu_transfer_time = 0
    total_gpu_processing_time = 0
    total_rows_processed = 0
    
    output_base = OUTPUT_PARQUET_PATH
    
    print(f"\n=== ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†é–‹å§‹ ===")
    print(f"COPYãŒ{batch_size}å€‹å®Œäº†ã™ã‚‹ã”ã¨ã«GPUå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
    
    while all_copy_futures or pending_gpu_tasks:
        # COPYã‚¿ã‚¹ã‚¯ãŒã¾ã ã‚ã‚‹å ´åˆ
        if all_copy_futures:
            # å®Œäº†ã—ãŸCOPYã‚¿ã‚¹ã‚¯ã‚’ãƒãƒƒãƒã‚µã‚¤ã‚ºã¾ã§åé›†
            num_to_wait = min(batch_size, len(all_copy_futures))
            ready_futures, remaining_futures = ray.wait(all_copy_futures, num_returns=num_to_wait, timeout=0.1)
            all_copy_futures = remaining_futures
            
            # COPYçµæœã‚’å‡¦ç†
            for future in ready_futures:
                result = ray.get(future)
                copy_results.append(result)
                
                if result['status'] == 'success':
                    total_copy_time += result['copy_time']
                    total_data_size += result['data_size']
                    pending_gpu_tasks.append(result)
                    print(f"âœ… COPYå®Œäº†: Worker{result['worker_id']}-Chunk{result['chunk_idx']} "
                          f"({result['data_size']/(1024*1024):.1f}MB, "
                          f"{result.get('chunk_count', 0)}ãƒãƒ£ãƒ³ã‚¯)")
                else:
                    print(f"âŒ COPYå¤±æ•—: Worker{result['worker_id']}-Chunk{result['chunk_idx']} - "
                          f"{result.get('error', 'Unknown')}")
        
        # GPUå‡¦ç†å¾…ã¡ã‚¿ã‚¹ã‚¯ãŒãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸå ´åˆã€ã¾ãŸã¯COPYãŒå…¨ã¦å®Œäº†ã—ãŸå ´åˆ
        if (len(pending_gpu_tasks) >= batch_size) or (not all_copy_futures and pending_gpu_tasks):
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºåˆ†ã®ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            tasks_to_process = pending_gpu_tasks[:batch_size] if len(pending_gpu_tasks) >= batch_size else pending_gpu_tasks
            pending_gpu_tasks = pending_gpu_tasks[len(tasks_to_process):]
            
            # ãƒãƒƒãƒGPUå‡¦ç†ã‚’å®Ÿè¡Œ
            batch_results = process_batch_on_gpu(
                tasks_to_process,
                columns,
                gds_supported,
                output_base,
                debug_mode=debug_mode
            )
            
            # çµæœã‚’é›†è¨ˆ
            for gpu_result in batch_results:
                gpu_results.append(gpu_result)
                
                if gpu_result['status'] == 'success':
                    total_gpu_transfer_time += gpu_result['gpu_transfer_time']
                    total_gpu_processing_time += gpu_result['gpu_processing_time']
                    total_rows_processed += gpu_result['rows_processed']
            
            print(f"å‡¦ç†æ¸ˆã¿ã‚¿ã‚¹ã‚¯ç´¯è¨ˆ: {len(gpu_results)}/{len(copy_results)}")
    
    # æˆåŠŸã—ãŸå‡¦ç†ã®æ•°ã‚’é›†è¨ˆ
    successful_copies = [r for r in copy_results if r['status'] == 'success']
    successful_gpu = [r for r in gpu_results if r['status'] == 'success']
    
    print(f"\nâœ… å…¨å‡¦ç†å®Œäº†")
    print(f"COPY: {len(successful_copies)}/{len(copy_results)} ã‚¿ã‚¹ã‚¯æˆåŠŸ")
    print(f"GPU: {len(successful_gpu)}/{len(gpu_results)} ã‚¿ã‚¹ã‚¯æˆåŠŸ")
    print(f"ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_data_size / (1024*1024):.2f} MB")
    
    # ç·åˆçµæœ
    total_time = time.time() - start_total_time
    
    # ãƒ‡ãƒãƒƒã‚°çµæœã®ä¿å­˜
    if debug_mode:
        all_results = {
            'metadata': {
                'table_name': TABLE_NAME,
                'limit_rows': limit_rows,
                'parallel_count': parallel_count,
                'chunk_count': CHUNK_COUNT,
                'batch_size': batch_size,
                'total_blocks': total_blocks,
                'total_time': total_time,
                'timestamp': datetime.now().isoformat()
            },
            'copy_results': copy_results,
            'gpu_results': gpu_results,
            'summary': {
                'total_data_size_mb': total_data_size / (1024*1024),
                'total_copy_time': total_copy_time,
                'total_gpu_transfer_time': total_gpu_transfer_time,
                'total_gpu_processing_time': total_gpu_processing_time,
                'total_rows_processed': total_rows_processed
            }
        }
        save_debug_results(all_results)
    
    print(f"\n{'='*60}")
    print(f"=== Rayä¸¦åˆ—ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³GPUå‡¦ç†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº† ===")
    print(f"{'='*60}")
    print(f"ç·æ™‚é–“ = {total_time:.4f} ç§’")
    print("--- æ™‚é–“å†…è¨³ ---")
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—    : {meta_time:.4f} ç§’")
    print(f"  PostgreSQL COPY   : {total_copy_time:.4f} ç§’ (ç´¯ç©)")
    print(f"  GPUè»¢é€          : {total_gpu_transfer_time:.4f} ç§’ (ç´¯ç©)")
    print(f"  GPUå‡¦ç†          : {total_gpu_processing_time:.4f} ç§’ (ç´¯ç©)")
    print("--- çµ±è¨ˆæƒ…å ± ---")
    print(f"  å‡¦ç†è¡Œæ•°ï¼ˆåˆè¨ˆï¼‰  : {total_rows_processed:,} è¡Œ")
    print(f"  å‡¦ç†åˆ—æ•°         : {len(columns)} åˆ—")
    print(f"  ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º    : {total_data_size / (1024*1024):.2f} MB")
    print(f"  æˆåŠŸç‡           : COPY {len(successful_copies)}/{len(copy_results)}, "
          f"GPU {len(successful_gpu)}/{len(gpu_results)}")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
    if total_data_size > 0:
        overall_throughput = (total_data_size / (1024*1024)) / total_time
        print("\n--- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ ---")
        print(f"  å…¨ä½“ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ  : {overall_throughput:.2f} MB/sec")
    
    print("\n--- å‡¦ç†æ–¹å¼ã®ç‰¹å¾´ ---")
    print("  âœ… ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: COPYã¨GPUå‡¦ç†ã‚’ä¸¦è¡Œå®Ÿè¡Œ")
    print(f"  âœ… ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}å€‹ã®COPYå®Œäº†ã”ã¨ã«GPUå‡¦ç†é–‹å§‹")
    print("  âœ… ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: GPUãƒ¡ãƒ¢ãƒªç«¶åˆã‚’å›é¿")
    print("  âœ… ç¢ºå®Ÿãªå‡¦ç†: 64å€‹ã®Parquetãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ")
    print("=========================================")
    
    # Rayçµ‚äº†
    ray.shutdown()
    print("\nâœ… Rayçµ‚äº†")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='PostgreSQL â†’ GPU Rayä¸¦åˆ— ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ç‰ˆï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰')
    parser.add_argument('--rows', type=int, default=10000000, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    parser.add_argument('--parallel', type=int, default=DEFAULT_PARALLEL, help='ä¸¦åˆ—æ•°')
    parser.add_argument('--chunks', type=int, default=4, help='ãƒãƒ£ãƒ³ã‚¯æ•°')
    parser.add_argument('--batch-size', type=int, default=4, help='ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒãƒƒãƒã‚µã‚¤ã‚º')
    parser.add_argument('--no-limit', action='store_true', help='LIMITç„¡ã—ï¼ˆå…¨ä»¶é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼‰')
    parser.add_argument('--check-support', action='store_true', help='GPU Directã‚µãƒãƒ¼ãƒˆç¢ºèªã®ã¿')
    parser.add_argument('--no-gpu-direct', action='store_true', help='GPU Directç„¡åŠ¹åŒ–')
    parser.add_argument('--no-debug', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ç„¡åŠ¹åŒ–')
    
    args = parser.parse_args()
    
    # CUDAç¢ºèª
    try:
        cuda.current_context()
        print("âœ… CUDA context OK")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        exit(1)
    
    if args.check_support:
        check_gpu_direct_support()
        return
    
    # ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’è¨­å®š
    global CHUNK_COUNT
    CHUNK_COUNT = args.chunks
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    final_limit_rows = None if args.no_limit else args.rows
    run_ray_parallel_sequential_gpu_debug(
        limit_rows=final_limit_rows,
        parallel_count=args.parallel,
        use_gpu_direct=not args.no_gpu_direct,
        batch_size=args.batch_size,
        debug_mode=not args.no_debug
    )

if __name__ == "__main__":
    main()