"""
RMM ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›å¯¾å¿œç‰ˆ
PostgreSQL â†’ GPUç›´æ¥ã‚³ãƒ”ãƒ¼ ï¼ˆRMM 21.x ï½ 25.x å¯¾å¿œï¼‰

RMM 25.x ã§ copy_from_host ã® API ãŒå¤‰æ›´ã•ã‚ŒãŸãŸã‚ã€
å®Ÿè¡Œæ™‚ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’åˆ¤å®šã—ã¦é©åˆ‡ãª API ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

ç’°å¢ƒå¤‰æ•°:
GPUPASER_PG_DSN  : PostgreSQLæ¥ç¶šæ–‡å­—åˆ—
"""

import os
import time
import inspect
import psycopg
import rmm
import numpy as np
from numba import cuda
import argparse

from src.metadata import fetch_column_meta
from src.cuda_kernels.postgresql_binary_parser import detect_pg_header_size
from src.main_postgres_to_parquet import postgresql_to_cudf_parquet

TABLE_NAME = "lineorder"
OUTPUT_PARQUET_PATH = "benchmark/lineorder_rmm_compatible.output.parquet"

def get_rmm_copy_method():
    """RMM ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å¿œã˜ãŸé©åˆ‡ãªã‚³ãƒ”ãƒ¼æ–¹æ³•ã‚’è¿”ã™"""
    try:
        # copy_from_host ã®ã‚·ã‚°ãƒãƒãƒ£ã‚’ç¢ºèª
        sig = inspect.signature(rmm.DeviceBuffer.copy_from_host)
        if 'dst_offset' in sig.parameters:
            print("âœ… RMM æ—§API (21.xç³») æ¤œå‡º")
            return "old_api"
        else:
            print("âœ… RMM æ–°API (25.xç³») æ¤œå‡º - Numba CUDA Driverä½¿ç”¨")
            return "numba_driver"
    except Exception as e:
        print(f"âš ï¸  RMM APIæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e} - Numba CUDA Driverä½¿ç”¨")
        return "numba_driver"

def copy_chunk_to_gpu_buffer(dbuf, chunk, offset, method):
    """
    ãƒãƒ£ãƒ³ã‚¯ã‚’GPUãƒãƒƒãƒ•ã‚¡ã®æŒ‡å®šã‚ªãƒ•ã‚»ãƒƒãƒˆã«ã‚³ãƒ”ãƒ¼
    
    Args:
        dbuf: rmm.DeviceBuffer
        chunk: bytes (ãƒ›ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿)
        offset: int (GPU ãƒãƒƒãƒ•ã‚¡å†…ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆ)
        method: str ("old_api" | "numba_driver")
    """
    chunk_size = len(chunk)
    
    if method == "old_api":
        # RMM 21.x ç³»ã®æ—§API
        dbuf.copy_from_host(buffer=chunk, dst_offset=offset)
        
    elif method == "numba_driver":
        # RMM 25.x ç³»å¯¾å¿œ - Numba CUDA Driverä½¿ç”¨
        cuda.cudadrv.driver.memcpy_htod(
            int(dbuf.ptr) + offset,  # dst GPU ptr + ã‚ªãƒ•ã‚»ãƒƒãƒˆ
            chunk,                   # src host bytes
            chunk_size               # ã‚µã‚¤ã‚º
        )
    else:
        raise ValueError(f"æœªå¯¾å¿œã®ã‚³ãƒ”ãƒ¼æ–¹æ³•: {method}")

def run_rmm_compatible_benchmark(limit_rows=1000000):
    """RMM ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›å¯¾å¿œç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    # RMM ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±è¡¨ç¤º
    print(f"=== RMM ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›å¯¾å¿œç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ===")
    try:
        print(f"RMM ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {rmm.__version__}")
    except AttributeError:
        print("RMM ãƒãƒ¼ã‚¸ãƒ§ãƒ³: ä¸æ˜")
    
    copy_method = get_rmm_copy_method()
    
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME}")
    print(f"è¡Œæ•°åˆ¶é™: {limit_rows:,}")
    
    # RMM åˆæœŸåŒ–
    try:
        if not rmm.is_initialized():
            rmm.reinitialize(pool_allocator=True, initial_pool_size=8*1024**3)
            print("âœ… RMM ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–å®Œäº†")
    except Exception as e:
        print(f"âŒ RMMåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return

    start_total_time = time.time()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    conn = psycopg.connect(dsn)
    try:
        print("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        start_meta_time = time.time()
        columns = fetch_column_meta(conn, f"SELECT * FROM {TABLE_NAME}")
        meta_time = time.time() - start_meta_time
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({meta_time:.4f}ç§’)")
        
        ncols = len(columns)

        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºæ¨å®š
        rows_est = limit_rows
        row_bytes = 17*8 + 17*4  # æ¦‚ç®—
        header_est = 19
        total_size_est = header_est + rows_est * row_bytes + 1024
        
        print(f"æ¨å®šãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size_est / (1024*1024):.2f} MB")
        
        # GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿
        print("GPU ãƒãƒƒãƒ•ã‚¡ã‚’ç¢ºä¿ä¸­...")
        dbuf = rmm.DeviceBuffer(size=total_size_est)
        print(f"GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿å®Œäº†: {total_size_est / (1024*1024):.2f} MB")

        # COPY BINARY â†’ GPUç›´æ¥æ›¸ãè¾¼ã¿
        print("COPY BINARY â†’ GPUç›´æ¥æ›¸ãè¾¼ã¿å®Ÿè¡Œä¸­...")
        print(f"ä½¿ç”¨ã‚³ãƒ”ãƒ¼æ–¹æ³•: {copy_method}")
        start_copy_time = time.time()
        
        copy_sql = f"COPY (SELECT * FROM {TABLE_NAME} LIMIT {limit_rows}) TO STDOUT (FORMAT binary)"
        
        offset = 0
        total_chunks = 0
        
        with conn.cursor() as cur:
            with cur.copy(copy_sql) as copy:
                for chunk in copy:
                    if chunk:
                        chunk_size = len(chunk)
                        if offset + chunk_size > dbuf.size:
                            print(f"âš ï¸  è­¦å‘Š: ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºä¸è¶³")
                            break
                        
                        # RMM ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¯¾å¿œã®ã‚³ãƒ”ãƒ¼
                        copy_chunk_to_gpu_buffer(dbuf, chunk, offset, copy_method)
                        offset += chunk_size
                        total_chunks += 1
                        
                        # é€²æ—è¡¨ç¤º
                        if total_chunks % 1000 == 0:
                            print(f"  ğŸ“Š ãƒãƒ£ãƒ³ã‚¯ {total_chunks:,} | {offset / (1024*1024):.2f} MB")
        
        copy_time = time.time() - start_copy_time
        actual_data_size = offset
        
        print(f"âœ… COPY BINARY â†’ GPUç›´æ¥æ›¸ãè¾¼ã¿å®Œäº† ({copy_time:.4f}ç§’)")
        print(f"  å‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks:,}")
        print(f"  å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {actual_data_size / (1024*1024):.2f} MB")
        print(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {actual_data_size / (1024*1024) / copy_time:.2f} MB/sec")

    finally:
        conn.close()

    # GPU ãƒãƒƒãƒ•ã‚¡ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°
    if actual_data_size < dbuf.size:
        print("GPU ãƒãƒƒãƒ•ã‚¡ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ä¸­...")
        trimmed_dbuf = rmm.DeviceBuffer(size=actual_data_size)
        # RMM 25.x ã§ã¯ copy_from_device ã‚‚å¼•æ•°ãŒå¤‰æ›´ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§æ³¨æ„
        try:
            trimmed_dbuf.copy_from_device(dbuf, size=actual_data_size)
        except TypeError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Numba CUDA Driverä½¿ç”¨
            cuda.cudadrv.driver.memcpy_dtod(
                int(trimmed_dbuf.ptr),
                int(dbuf.ptr),
                actual_data_size
            )
        dbuf = trimmed_dbuf
        print(f"GPU ãƒãƒƒãƒ•ã‚¡ãƒˆãƒªãƒŸãƒ³ã‚°å®Œäº†: {actual_data_size / (1024*1024):.2f} MB")

    # numba GPU ã‚¢ãƒ¬ã‚¤ã«å¤‰æ›
    print("GPU ãƒãƒƒãƒ•ã‚¡ã‚’ numba GPU ã‚¢ãƒ¬ã‚¤ã«å¤‰æ›ä¸­...")
    raw_dev = cuda.as_cuda_array(dbuf).view(dtype=np.uint8)
    print(f"GPU ã‚¢ãƒ¬ã‚¤å¤‰æ›å®Œäº†: {raw_dev.shape[0]:,} bytes")

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºæ¤œå‡º
    header_sample = raw_dev[:min(128, raw_dev.shape[0])].copy_to_host()
    header_size = detect_pg_header_size(header_sample)
    print(f"ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º: {header_size} ãƒã‚¤ãƒˆ")

    # GPUæœ€é©åŒ–å‡¦ç†
    print("GPUæœ€é©åŒ–å‡¦ç†ä¸­...")
    start_processing_time = time.time()
    
    try:
        cudf_df, detailed_timing = postgresql_to_cudf_parquet(
            raw_dev=raw_dev,
            columns=columns,
            ncols=ncols,
            header_size=header_size,
            output_path=OUTPUT_PARQUET_PATH,
            compression='snappy',
            use_rmm=True,
            optimize_gpu=True
        )
        
        processing_time = time.time() - start_processing_time
        rows = len(cudf_df)
        parse_time = detailed_timing.get('gpu_parsing', 0)
        decode_time = detailed_timing.get('cudf_creation', 0)
        write_time = detailed_timing.get('parquet_export', 0)
        
        print(f"GPUæœ€é©åŒ–å‡¦ç†å®Œäº† ({processing_time:.4f}ç§’), è¡Œæ•°: {rows}")
        
    except Exception as e:
        print(f"GPUæœ€é©åŒ–å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
        return

    total_time = time.time() - start_total_time
    decimal_cols = sum(1 for col in columns if col.arrow_id == 5)
    
    print(f"\n=== RMMäº’æ›ç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº† ===")
    print(f"ç·æ™‚é–“ = {total_time:.4f} ç§’")
    print(f"ä½¿ç”¨API: {copy_method}")
    print("--- æ™‚é–“å†…è¨³ ---")
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—       : {meta_time:.4f} ç§’")
    print(f"  COPYâ†’GPUç›´æ¥æ›¸ãè¾¼ã¿: {copy_time:.4f} ç§’")
    print(f"  GPUãƒ‘ãƒ¼ã‚¹           : {parse_time:.4f} ç§’")
    print(f"  GPUãƒ‡ã‚³ãƒ¼ãƒ‰         : {decode_time:.4f} ç§’")
    print(f"  Parquetæ›¸ãè¾¼ã¿     : {write_time:.4f} ç§’")
    print("--- çµ±è¨ˆæƒ…å ± ---")
    print(f"  å‡¦ç†è¡Œæ•°      : {rows:,} è¡Œ")
    print(f"  å‡¦ç†åˆ—æ•°      : {len(columns)} åˆ—")
    print(f"  Decimalåˆ—æ•°   : {decimal_cols} åˆ—")
    print(f"  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º  : {actual_data_size / (1024*1024):.2f} MB")
    print(f"  å‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {total_chunks:,}")
    
    total_cells = rows * len(columns)
    throughput = total_cells / decode_time if decode_time > 0 else 0
    network_throughput = actual_data_size / (1024*1024) / copy_time
    print(f"  ã‚»ãƒ«å‡¦ç†é€Ÿåº¦  : {throughput:,.0f} cells/sec")
    print(f"  ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦: {network_throughput:.2f} MB/sec")
    print("--- æœ€é©åŒ–åŠ¹æœ ---")
    print("  âœ… ãƒ•ã‚¡ã‚¤ãƒ« I/O: å®Œå…¨ã‚¼ãƒ­ (ç›´æ¥GPUæ›¸ãè¾¼ã¿)")
    print("  âœ… ãƒ›ã‚¹ãƒˆãƒ¡ãƒ¢ãƒª: æœ€å°åŒ– (ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®ã¿)")
    print("  âœ… GPUè»¢é€: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)")
    print(f"  âœ… RMM API: {copy_method} è‡ªå‹•é¸æŠ")
    print("=====================================")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='PostgreSQL â†’ GPUç›´æ¥ã‚³ãƒ”ãƒ¼ï¼ˆRMMäº’æ›ç‰ˆï¼‰')
    parser.add_argument('--rows', type=int, default=1000000, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    
    args = parser.parse_args()
    
    try:
        cuda.current_context()
        print("âœ… CUDA context OK")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        exit(1)
    
    run_rmm_compatible_benchmark(limit_rows=args.rows)

if __name__ == "__main__":
    main()