"""
PostgreSQL â†’ GPU Rayä¸¦åˆ— é †æ¬¡GPUå‡¦ç†ç‰ˆï¼ˆç›´æ¥GPUè»¢é€ï¼‰
memoryviewã‹ã‚‰ç›´æ¥GPUè»¢é€ã«ã‚ˆã‚Šã€ä¸­é–“ãƒãƒƒãƒ•ã‚¡ã‚’æ’é™¤

æœ€é©åŒ–:
- psycopg3ã®memoryviewãƒãƒ£ãƒ³ã‚¯ã‚’ç›´æ¥GPUè»¢é€
- ä¸­é–“ãƒãƒƒãƒ•ã‚¡ï¼ˆBytesIOã€bytearrayï¼‰ã‚’å®Œå…¨ã«æ’é™¤
- GPUä¸Šã§ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
- è©³ç´°ãªãƒ¡ãƒ¢ãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²

ç’°å¢ƒå¤‰æ•°:
GPUPASER_PG_DSN  : PostgreSQLæ¥ç¶šæ–‡å­—åˆ—
"""

import os
import time
import math
import psycopg
import ray
import gc
import numpy as np
from numba import cuda
import argparse
from typing import List, Dict, Tuple, Optional
import psutil
import json
import cupy as cp

from src.metadata import fetch_column_meta
from src.cuda_kernels.postgresql_binary_parser import detect_pg_header_size
from src.main_postgres_to_parquet import postgresql_to_cudf_parquet

TABLE_NAME = "lineorder"
OUTPUT_PARQUET_PATH = "benchmark/lineorder_parallel_ctid_ray_sequential_gpu_direct.output"

# ä¸¦åˆ—è¨­å®š
DEFAULT_PARALLEL = 16
CHUNK_COUNT = 4

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ç”¨
class DetailedMetrics:
    def __init__(self, is_worker=False):
        self.is_worker = is_worker  # Ray Workerå†…ã‹ã©ã†ã‹
        self.metrics = {
            'memory': {
                'initial_system_mb': 0,
                'peak_system_mb': 0,
                'initial_gpu_mb': 0,
                'peak_gpu_mb': 0,
                'chunk_count': 0,
                'avg_chunk_size': 0,
                'total_data_size_mb': 0,
                'memory_overhead_ratio': 0
            },
            'performance': {
                'copy_time_sec': 0,
                'gpu_transfer_time_sec': 0,
                'gpu_transfer_count': 0,
                'gpu_processing_time_sec': 0,
                'total_time_sec': 0,
                'throughput_mb_sec': 0
            },
            'details': []
        }
    
    def log_memory_snapshot(self, stage: str):
        import psutil
        
        process = psutil.Process()
        system_memory_mb = process.memory_info().rss / (1024**2)
        
        # Ray Workerå†…ã§ã¯GPUãƒ¡ãƒ¢ãƒªã‚’å–å¾—ã—ãªã„
        gpu_memory_mb = 0
        if not self.is_worker:
            try:
                mempool = cp.get_default_memory_pool()
                gpu_memory_mb = mempool.used_bytes() / (1024**2)
            except:
                gpu_memory_mb = 0
        
        self.metrics['details'].append({
            'timestamp': time.time(),
            'stage': stage,
            'system_memory_mb': system_memory_mb,
            'gpu_memory_mb': gpu_memory_mb
        })
        
        # ãƒ”ãƒ¼ã‚¯å€¤ã‚’æ›´æ–°
        if system_memory_mb > self.metrics['memory']['peak_system_mb']:
            self.metrics['memory']['peak_system_mb'] = system_memory_mb
        if gpu_memory_mb > self.metrics['memory']['peak_gpu_mb']:
            self.metrics['memory']['peak_gpu_mb'] = gpu_memory_mb
    
    def save_to_json(self, filename: str):
        with open(filename, 'w') as f:
            json.dump(self.metrics, f, indent=2)

@ray.remote  # CPUã®ã¿ã€GPUã¯ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã§ä½¿ç”¨
class PostgreSQLWorker:
    """Rayä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼: ç›´æ¥GPUè»¢é€ç‰ˆ"""
    
    def __init__(self, worker_id: int, dsn: str):
        self.worker_id = worker_id
        self.dsn = dsn
        
    def copy_data_to_memory_direct(
        self, 
        table_name: str,
        start_block: int, 
        end_block: int,
        chunk_idx: int,
        total_chunks: int,
        limit_rows: Optional[int] = None
    ) -> Dict[str, any]:
        """PostgreSQLã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’COPYã—ã¦CPUãƒ¡ãƒ¢ãƒªã«ä¿æŒï¼ˆGPUè»¢é€ã¯ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œï¼‰"""
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆæœŸåŒ–
        metrics = DetailedMetrics(is_worker=True)  # Ray Workerå†…ãªã®ã§True
        process = psutil.Process()
        initial_memory = process.memory_info().rss / (1024**2)  # MB
        metrics.metrics['memory']['initial_system_mb'] = initial_memory
        metrics.log_memory_snapshot("start")
        
        # ãƒãƒ£ãƒ³ã‚¯ã«å¿œã˜ã¦ctidç¯„å›²ã‚’åˆ†å‰²
        block_range = end_block - start_block
        chunk_block_size = block_range // total_chunks
        
        chunk_start_block = start_block + (chunk_idx * chunk_block_size)
        chunk_end_block = start_block + ((chunk_idx + 1) * chunk_block_size) if chunk_idx < total_chunks - 1 else end_block
        
        print(f"Worker {self.worker_id}-Chunk{chunk_idx}: COPYé–‹å§‹ ctidç¯„å›² ({chunk_start_block},{chunk_end_block})...")
        print(f"  åˆæœŸãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {initial_memory:.2f} MB")
        
        start_time = time.time()
        
        try:
            # PostgreSQLæ¥ç¶š
            conn = psycopg.connect(self.dsn)
            
            # CPUãƒ¡ãƒ¢ãƒªã¸ã®ãƒãƒ£ãƒ³ã‚¯ä¿å­˜ç”¨
            all_chunks = []  # memoryviewã®ã¾ã¾ä¿æŒ
            chunk_count = 0
            total_size = 0
            chunk_sizes = []
            
            try:
                # COPY SQLç”Ÿæˆ
                copy_sql = self._make_copy_sql(table_name, chunk_start_block, chunk_end_block, limit_rows)
                
                # ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨ç›´æ¥GPUè»¢é€
                with conn.cursor() as cur:
                    with cur.copy(copy_sql) as copy_obj:
                        print(f"  CPUãƒ¡ãƒ¢ãƒªã¸ã®ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")
                        
                        for chunk in copy_obj:
                            if chunk:
                                chunk_count += 1
                                chunk_size = len(chunk)
                                chunk_sizes.append(chunk_size)
                                total_size += chunk_size
                                
                                # memoryviewã‚’bytesã«å¤‰æ›ã—ã¦ä¿å­˜
                                if isinstance(chunk, memoryview):
                                    chunk_bytes = bytes(chunk)
                                else:
                                    chunk_bytes = chunk
                                
                                all_chunks.append(chunk_bytes)
                                
                                # æœ€åˆã®10ãƒãƒ£ãƒ³ã‚¯ã®ã‚µã‚¤ã‚ºã‚’è¡¨ç¤º
                                if chunk_count <= 10:
                                    print(f"    ãƒãƒ£ãƒ³ã‚¯{chunk_count}: {chunk_size} bytes")
                                
                                # å®šæœŸçš„ã«ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
                                if chunk_count % 10000 == 0:
                                    metrics.log_memory_snapshot(f"chunk_{chunk_count}")
                
                # CPUã§ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
                print(f"  CPUã§ãƒãƒ£ãƒ³ã‚¯çµåˆä¸­... ({len(all_chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯)")
                concat_start = time.time()
                
                if all_chunks:
                    # bytearrayã§åŠ¹ç‡çš„ã«çµåˆ
                    combined_data = bytearray()
                    for chunk in all_chunks:
                        combined_data.extend(chunk)
                    data_bytes = bytes(combined_data)
                    
                    # ä¸­é–“ãƒãƒƒãƒ•ã‚¡ã‚’å³åº§ã«è§£æ”¾
                    del combined_data
                    del all_chunks
                else:
                    data_bytes = b''
                
                concat_time = time.time() - concat_start
                
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                metrics.log_memory_snapshot("after_concat")
                copy_time = time.time() - start_time
                
                # ãƒãƒ£ãƒ³ã‚¯çµ±è¨ˆ
                if chunk_sizes:
                    avg_chunk_size = sum(chunk_sizes) / len(chunk_sizes)
                else:
                    avg_chunk_size = 0
                
                metrics.metrics['memory']['chunk_count'] = chunk_count
                metrics.metrics['memory']['avg_chunk_size'] = avg_chunk_size
                metrics.metrics['memory']['total_data_size_mb'] = total_size / (1024**2)
                metrics.metrics['performance']['copy_time_sec'] = copy_time
                
                # ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è¨ˆç®—
                current_memory = process.memory_info().rss / (1024**2)
                memory_used = current_memory - initial_memory
                if total_size > 0:
                    overhead_ratio = memory_used / (total_size / (1024**2))
                else:
                    overhead_ratio = 1.0
                metrics.metrics['memory']['memory_overhead_ratio'] = overhead_ratio
                
                print(f"Worker {self.worker_id}-Chunk{chunk_idx}: COPYå®Œäº†")
                print(f"  ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_count:,}")
                print(f"  å¹³å‡ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {avg_chunk_size:.0f} bytes")
                print(f"  ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size/(1024*1024):.1f} MB")
                print(f"  CPUçµåˆæ™‚é–“: {concat_time:.2f}ç§’")
                print(f"  ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {current_memory:.2f} MB (å¢—åŠ : +{memory_used:.2f} MB)")
                print(f"  ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ç‡: {overhead_ratio:.2f}x")
                
                return {
                    'worker_id': self.worker_id,
                    'chunk_idx': chunk_idx,
                    'data': data_bytes,  # CPUã§åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿
                    'data_size': len(data_bytes),
                    'copy_time': copy_time,
                    'metrics': metrics.metrics,
                    'status': 'success'
                }
                
            finally:
                conn.close()
                # ãƒ¡ãƒ¢ãƒªè§£æ”¾
                del all_chunks
                gc.collect()
                
        except Exception as e:
            print(f"Worker {self.worker_id}-Chunk{chunk_idx}: âŒCOPYå¤±æ•— - {e}")
            return {
                'worker_id': self.worker_id,
                'chunk_idx': chunk_idx,
                'status': 'error',
                'error': str(e),
                'copy_time': time.time() - start_time,
                'metrics': metrics.metrics
            }
    
    def _make_copy_sql(self, table_name: str, start_block: int, end_block: int, limit_rows: Optional[int]) -> str:
        """COPY SQLç”Ÿæˆ"""
        sql = f"""
        COPY (
            SELECT * FROM {table_name}
            WHERE ctid >= '({start_block},1)'::tid
              AND ctid < '({end_block+1},1)'::tid
        ) TO STDOUT (FORMAT binary)"""
        
        return sql


def process_batch_on_gpu(
    batch_tasks: List[Dict],
    columns: List,
    gds_supported: bool,
    output_base: str,
    true_batch_mode: bool = False
) -> List[Dict]:
    """è¤‡æ•°ã®ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã‚’çµåˆã—ã¦1å›ã®GPUå‡¦ç†ã§å®Ÿè¡Œ"""
    
    import cupy as cp
    
    num_tasks = len(batch_tasks)
    print(f"\nğŸ“Š ãƒãƒƒãƒGPUå‡¦ç†é–‹å§‹: {num_tasks}å€‹ã®ã‚¿ã‚¹ã‚¯ã‚’çµ±åˆå‡¦ç†")
    
    results = []
    start_total_time = time.time()
    
    try:
        # 1. å…¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        total_size = sum(task['data_size'] for task in batch_tasks)
        print(f"  çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size/(1024*1024):.2f} MB")
        
        # 2. GPUé…åˆ—ã‚’ç›´æ¥ä½œæˆï¼ˆãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªçµŒç”±ãªã—ï¼‰
        start_gpu_transfer_time = time.time()
        gpu_array = cp.empty(total_size, dtype=cp.uint8)
        
        # 3. å„ã‚¿ã‚¹ã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥GPUé…åˆ—ã«ã‚³ãƒ”ãƒ¼
        task_offsets = []
        current_offset = 0
        
        for task in batch_tasks:
            data_len = task['data_size']
            # ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥GPUé…åˆ—ã«ã‚³ãƒ”ãƒ¼
            gpu_array[current_offset:current_offset + data_len] = cp.frombuffer(task['data'], dtype=cp.uint8)
            
            task_offsets.append({
                'worker_id': task['worker_id'],
                'chunk_idx': task['chunk_idx'],
                'offset': current_offset,
                'size': task['data_size']
            })
            current_offset += task['data_size']
        
        gpu_transfer_time = time.time() - start_gpu_transfer_time
        print(f"  GPUè»¢é€å®Œäº† ({gpu_transfer_time:.2f}ç§’, {(total_size/(1024*1024))/gpu_transfer_time:.2f} MB/sec)")
        
        # ä»¥ä¸‹ã€æ—¢å­˜ã®GPUå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨
        start_gpu_processing_time = time.time()
        
        if true_batch_mode:
            # çœŸã®ãƒãƒƒãƒå‡¦ç†ãƒ¢ãƒ¼ãƒ‰
            print(f"\n  ğŸš€ çœŸã®ãƒãƒƒãƒå‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {num_tasks}å€‹ã®ã‚¿ã‚¹ã‚¯ã‚’1å›ã®GPUå‡¦ç†ã§å®Ÿè¡Œ")
            
            raw_dev = cuda.as_cuda_array(gpu_array)
            header_sample = gpu_array[:min(128, len(gpu_array))].get()
            header_size = detect_pg_header_size(header_sample)
            
            output_path = f"{output_base}_batch_integrated.parquet"
            
            try:
                cudf_df, detailed_timing = postgresql_to_cudf_parquet(
                    raw_dev=raw_dev,
                    columns=columns,
                    ncols=len(columns),
                    header_size=header_size,
                    output_path=output_path,
                    compression='snappy',
                    use_rmm=False,
                    optimize_gpu=True
                )
                
                print(f"  âœ… ãƒãƒƒãƒå‡¦ç†æˆåŠŸ: {len(cudf_df):,} è¡Œå‡¦ç†æ¸ˆã¿")
                
                results.append({
                    'worker_id': 'batch',
                    'chunk_idx': 0,
                    'gpu_transfer_time': gpu_transfer_time,
                    'gpu_processing_time': detailed_timing.get('overall_total', 0),
                    'rows_processed': len(cudf_df),
                    'status': 'success'
                })
                
            except Exception as e:
                print(f"  âŒ ãƒãƒƒãƒå‡¦ç†å¤±æ•—: {e}")
                true_batch_mode = False
        
        if not true_batch_mode:
            # å€‹åˆ¥å‡¦ç†ãƒ¢ãƒ¼ãƒ‰
            for i, (task, offset_info) in enumerate(zip(batch_tasks, task_offsets)):
                print(f"\n  å‡¦ç†ä¸­ [{i+1}/{num_tasks}]: Worker{offset_info['worker_id']}-Chunk{offset_info['chunk_idx']}")
                
                dataset_gpu = gpu_array[offset_info['offset']:offset_info['offset'] + offset_info['size']]
                raw_dev = cuda.as_cuda_array(dataset_gpu)
                header_sample = dataset_gpu[:min(128, len(dataset_gpu))].get()
                header_size = detect_pg_header_size(header_sample)
                
                output_path = f"{output_base}_worker{offset_info['worker_id']}_chunk{offset_info['chunk_idx']}.parquet"
                
                cudf_df, detailed_timing = postgresql_to_cudf_parquet(
                    raw_dev=raw_dev,
                    columns=columns,
                    ncols=len(columns),
                    header_size=header_size,
                    output_path=output_path,
                    compression='snappy',
                    use_rmm=False,
                    optimize_gpu=True
                )
                
                results.append({
                    'worker_id': offset_info['worker_id'],
                    'chunk_idx': offset_info['chunk_idx'],
                    'gpu_transfer_time': gpu_transfer_time / num_tasks,
                    'gpu_processing_time': detailed_timing.get('overall_total', 0),
                    'rows_processed': len(cudf_df),
                    'status': 'success'
                })
        
        gpu_processing_time = time.time() - start_gpu_processing_time
        total_time = time.time() - start_total_time
        
        print(f"\nâœ… ãƒãƒƒãƒGPUå‡¦ç†å®Œäº†:")
        print(f"  ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
        print(f"  GPUè»¢é€: {gpu_transfer_time:.2f}ç§’")
        print(f"  GPUå‡¦ç†: {gpu_processing_time:.2f}ç§’")
        print(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {(total_size/(1024*1024))/total_time:.2f} MB/sec")
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del gpu_array
        gc.collect()
        cp.get_default_memory_pool().free_all_blocks()
        cuda.synchronize()
        
        return results
        
    except Exception as e:
        print(f"  âŒãƒãƒƒãƒGPUå‡¦ç†å¤±æ•—: {e}")
        for task in batch_tasks:
            results.append({
                'worker_id': task['worker_id'],
                'chunk_idx': task['chunk_idx'],
                'status': 'error',
                'error': str(e)
            })
        
        try:
            gc.collect()
            cp.get_default_memory_pool().free_all_blocks()
            cuda.synchronize()
        except:
            pass
            
        return results


def get_table_blocks(dsn: str, table_name: str) -> int:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’å–å¾—"""
    conn = psycopg.connect(dsn)
    try:
        with conn.cursor() as cur:
            cur.execute(f"SELECT pg_relation_size('{table_name}') / 8192 AS blocks")
            blocks = cur.fetchone()[0]
            return int(blocks)
    finally:
        conn.close()


def make_ctid_ranges(total_blocks: int, parallel_count: int) -> List[Tuple[int, int]]:
    """ctidç¯„å›²ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    chunk_size = math.ceil(total_blocks / parallel_count)
    ranges = []
    
    for i in range(parallel_count):
        start_block = i * chunk_size
        end_block = min((i + 1) * chunk_size, total_blocks)
        if start_block < total_blocks:
            ranges.append((start_block, end_block))
    
    return ranges


def check_gpu_direct_support() -> bool:
    """GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª"""
    print("\n=== GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª ===")
    
    try:
        if os.path.exists("/proc/driver/nvidia-fs/stats"):
            print("âœ… nvidia-fs ãƒ‰ãƒ©ã‚¤ãƒæ¤œå‡º")
        else:
            print("âš ï¸  nvidia-fs ãƒ‰ãƒ©ã‚¤ãƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
    except Exception:
        print("âš ï¸  nvidia-fs ç¢ºèªã‚¨ãƒ©ãƒ¼")
        return False
    
    try:
        import kvikio
        print(f"âœ… kvikio ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {kvikio.__version__}")
        os.environ["KVIKIO_COMPAT_MODE"] = "OFF"
        print("âœ… KVIKIO_COMPAT_MODE=OFF è¨­å®šå®Œäº†")
        return True
    except ImportError:
        print("âš ï¸  kvikio ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False


def run_ray_parallel_sequential_gpu(
    limit_rows: int = 10000000,
    parallel_count: int = DEFAULT_PARALLEL,
    use_gpu_direct: bool = True,
    batch_size: int = 4,
    true_batch_mode: bool = False
):
    """Rayä¸¦åˆ—COPY + é †æ¬¡GPUå‡¦ç†ï¼ˆç›´æ¥GPUè»¢é€ç‰ˆï¼‰"""
    
    # å…¨ä½“ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    global_metrics = DetailedMetrics()
    global_metrics.log_memory_snapshot("start")
    
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    print(f"=== PostgreSQL â†’ GPU Rayä¸¦åˆ— é †æ¬¡GPUå‡¦ç†ç‰ˆï¼ˆç›´æ¥GPUè»¢é€ï¼‰ ===")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME}")
    print(f"è¡Œæ•°åˆ¶é™: {limit_rows:,}" if limit_rows else "è¡Œæ•°åˆ¶é™: ãªã—ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰")
    print(f"ä¸¦åˆ—æ•°: {parallel_count}")
    print(f"ãƒãƒ£ãƒ³ã‚¯æ•°: {CHUNK_COUNT}")
    print(f"ç·ã‚¿ã‚¹ã‚¯æ•°: {parallel_count * CHUNK_COUNT}")
    print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
    print(f"è»¢é€æ–¹å¼: ğŸš€ memoryview â†’ GPUç›´æ¥è»¢é€ï¼ˆä¸­é–“ãƒãƒƒãƒ•ã‚¡ãªã—ï¼‰")
    print(f"GPUå‡¦ç†æ–¹å¼: {'ğŸš€ çœŸã®ãƒãƒƒãƒå‡¦ç†ï¼ˆå®Ÿé¨“çš„ï¼‰' if true_batch_mode else 'å¾“æ¥ã®å€‹åˆ¥å‡¦ç†'}")
    
    # GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª
    gds_supported = check_gpu_direct_support() if use_gpu_direct else False
    
    # RayåˆæœŸåŒ–
    print("\n=== RayåˆæœŸåŒ– ===")
    if not ray.is_initialized():
        ray.init(num_cpus=parallel_count * 2)
        print(f"âœ… RayåˆæœŸåŒ–å®Œäº†")
    
    start_total_time = time.time()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    print("\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    start_meta_time = time.time()
    conn = psycopg.connect(dsn)
    try:
        columns = fetch_column_meta(conn, f"SELECT * FROM {TABLE_NAME}")
        meta_time = time.time() - start_meta_time
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({meta_time:.4f}ç§’)")
    finally:
        conn.close()
    
    global_metrics.log_memory_snapshot("after_metadata")
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°å–å¾—
    print("ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’å–å¾—ä¸­...")
    total_blocks = get_table_blocks(dsn, TABLE_NAME)
    print(f"ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°: {total_blocks:,}")
    
    # ctidç¯„å›²åˆ†å‰²
    ranges = make_ctid_ranges(total_blocks, parallel_count)
    print(f"ctidç¯„å›²åˆ†å‰²: {len(ranges)}å€‹ã®ç¯„å›²")
    
    # Rayä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ä½œæˆ
    workers = []
    for i in range(len(ranges)):
        worker = PostgreSQLWorker.remote(i, dsn)
        workers.append(worker)
    
    # å…¨ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹
    print(f"\n=== ãƒ•ã‚§ãƒ¼ã‚º1: PostgreSQL COPYä¸¦åˆ—å®Ÿè¡Œï¼ˆç›´æ¥GPUè»¢é€ï¼‰ ===")
    all_copy_futures = []
    
    for worker_idx, (start_block, end_block) in enumerate(ranges):
        for chunk_idx in range(CHUNK_COUNT):
            future = workers[worker_idx].copy_data_to_memory_direct.remote(
                TABLE_NAME, start_block, end_block, chunk_idx, CHUNK_COUNT, limit_rows
            )
            all_copy_futures.append(future)
    
    print(f"âœ… {len(all_copy_futures)}å€‹ã®COPYã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥")
    
    # ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†
    copy_results = []
    gpu_results = []
    pending_gpu_tasks = []
    
    total_copy_time = 0
    total_data_size = 0
    total_gpu_transfer_time = 0
    total_gpu_processing_time = 0
    total_rows_processed = 0
    all_worker_metrics = []
    
    output_base = OUTPUT_PARQUET_PATH
    
    print(f"\n=== ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†é–‹å§‹ ===")
    print(f"COPYãŒ{batch_size}å€‹å®Œäº†ã™ã‚‹ã”ã¨ã«GPUå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
    
    while all_copy_futures or pending_gpu_tasks:
        # COPYã‚¿ã‚¹ã‚¯ãŒã¾ã ã‚ã‚‹å ´åˆ
        if all_copy_futures:
            num_to_wait = min(batch_size, len(all_copy_futures))
            ready_futures, remaining_futures = ray.wait(all_copy_futures, num_returns=num_to_wait, timeout=0.1)
            all_copy_futures = remaining_futures
            
            for future in ready_futures:
                result = ray.get(future)
                
                if result['status'] == 'success':
                    total_copy_time += result['copy_time']
                    total_data_size += result['data_size']
                    pending_gpu_tasks.append(result)
                    all_worker_metrics.append(result['metrics'])
                    print(f"âœ… COPYå®Œäº†: Worker{result['worker_id']}-Chunk{result['chunk_idx']} "
                          f"({result['data_size']/(1024*1024):.1f}MB)")
                    
                    # çµ±è¨ˆæƒ…å ±ã®ã¿ã‚’ä¿æŒï¼ˆå¤§ããªãƒ‡ãƒ¼ã‚¿ã¯é™¤å¤–ï¼‰
                    copy_results.append({
                        'worker_id': result['worker_id'],
                        'chunk_idx': result['chunk_idx'],
                        'status': 'success',
                        'copy_time': result['copy_time'],
                        'data_size': result['data_size']
                    })
                else:
                    print(f"âŒ COPYå¤±æ•—: Worker{result['worker_id']}-Chunk{result['chunk_idx']} - "
                          f"{result.get('error', 'Unknown')}")
                    copy_results.append({
                        'worker_id': result['worker_id'],
                        'chunk_idx': result['chunk_idx'],
                        'status': 'error',
                        'error': result.get('error', 'Unknown')
                    })
        
        # GPUå‡¦ç†
        if (len(pending_gpu_tasks) >= batch_size) or (not all_copy_futures and pending_gpu_tasks):
            tasks_to_process = pending_gpu_tasks[:batch_size] if len(pending_gpu_tasks) >= batch_size else pending_gpu_tasks
            pending_gpu_tasks = pending_gpu_tasks[len(tasks_to_process):]
            
            global_metrics.log_memory_snapshot(f"before_gpu_batch_{len(gpu_results)}")
            
            batch_results = process_batch_on_gpu(
                tasks_to_process,
                columns,
                gds_supported,
                output_base,
                true_batch_mode=true_batch_mode
            )
            
            global_metrics.log_memory_snapshot(f"after_gpu_batch_{len(gpu_results)}")
            
            for gpu_result in batch_results:
                gpu_results.append(gpu_result)
                
                if gpu_result['status'] == 'success':
                    total_gpu_transfer_time += gpu_result['gpu_transfer_time']
                    total_gpu_processing_time += gpu_result['gpu_processing_time']
                    total_rows_processed += gpu_result['rows_processed']
            
            # GPUå‡¦ç†å¾Œã«CPUãƒ¡ãƒ¢ãƒªã‚’è§£æ”¾
            for task in tasks_to_process:
                if 'data' in task:
                    del task['data']  # å¤§ããªãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ•ã‚¡ã‚’è§£æ”¾
            gc.collect()
            
            print(f"å‡¦ç†æ¸ˆã¿ã‚¿ã‚¹ã‚¯ç´¯è¨ˆ: {len(gpu_results)}/{len(copy_results)}")
    
    # æˆåŠŸã—ãŸå‡¦ç†ã®æ•°ã‚’é›†è¨ˆ
    successful_copies = [r for r in copy_results if r['status'] == 'success']
    successful_gpu = [r for r in gpu_results if r['status'] == 'success']
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†è¨ˆ
    if all_worker_metrics:
        total_chunk_count = sum(m['memory']['chunk_count'] for m in all_worker_metrics)
        avg_chunk_size = sum(m['memory']['avg_chunk_size'] * m['memory']['chunk_count'] for m in all_worker_metrics) / total_chunk_count
        total_gpu_transfer_count = sum(m['performance']['gpu_transfer_count'] for m in all_worker_metrics)
        
        global_metrics.metrics['memory']['chunk_count'] = total_chunk_count
        global_metrics.metrics['memory']['avg_chunk_size'] = avg_chunk_size
        global_metrics.metrics['performance']['gpu_transfer_count'] = total_gpu_transfer_count
    
    global_metrics.log_memory_snapshot("end")
    
    print(f"\nâœ… å…¨å‡¦ç†å®Œäº†")
    print(f"COPY: {len(successful_copies)}/{len(copy_results)} ã‚¿ã‚¹ã‚¯æˆåŠŸ")
    print(f"GPU: {len(successful_gpu)}/{len(gpu_results)} ã‚¿ã‚¹ã‚¯æˆåŠŸ")
    print(f"ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_data_size / (1024*1024):.2f} MB")
    
    # ç·åˆçµæœ
    total_time = time.time() - start_total_time
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
    global_metrics.metrics['memory']['total_data_size_mb'] = total_data_size / (1024*1024)
    global_metrics.metrics['performance']['copy_time_sec'] = total_copy_time
    global_metrics.metrics['performance']['gpu_processing_time_sec'] = total_gpu_processing_time
    global_metrics.metrics['performance']['total_time_sec'] = total_time
    global_metrics.metrics['performance']['throughput_mb_sec'] = (total_data_size / (1024*1024)) / total_time if total_time > 0 else 0
    
    # ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰è¨ˆç®—
    peak_memory = global_metrics.metrics['memory']['peak_system_mb']
    initial_memory = global_metrics.metrics['memory']['initial_system_mb']
    memory_used = peak_memory - initial_memory
    if total_data_size > 0:
        global_metrics.metrics['memory']['memory_overhead_ratio'] = memory_used / (total_data_size / (1024*1024))
    
    print(f"\n{'='*60}")
    print(f"=== Rayä¸¦åˆ—ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³GPUå‡¦ç†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†ï¼ˆç›´æ¥GPUè»¢é€ï¼‰ ===")
    print(f"{'='*60}")
    print(f"ç·æ™‚é–“ = {total_time:.4f} ç§’")
    print("--- æ™‚é–“å†…è¨³ ---")
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—    : {meta_time:.4f} ç§’")
    print(f"  PostgreSQL COPY   : {total_copy_time:.4f} ç§’ (ç´¯ç©)")
    print(f"  GPUè»¢é€          : {total_gpu_transfer_time:.4f} ç§’ (ç´¯ç©)")
    print(f"  GPUå‡¦ç†          : {total_gpu_processing_time:.4f} ç§’ (ç´¯ç©)")
    print("--- çµ±è¨ˆæƒ…å ± ---")
    print(f"  å‡¦ç†è¡Œæ•°ï¼ˆåˆè¨ˆï¼‰  : {total_rows_processed:,} è¡Œ")
    print(f"  å‡¦ç†åˆ—æ•°         : {len(columns)} åˆ—")
    print(f"  ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º    : {total_data_size / (1024*1024):.2f} MB")
    print(f"  æˆåŠŸç‡           : COPY {len(successful_copies)}/{len(copy_results)}, "
          f"GPU {len(successful_gpu)}/{len(gpu_results)}")
    
    print("\n--- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ ---")
    print(f"  åˆæœŸã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª : {initial_memory:.2f} MB")
    print(f"  ãƒ”ãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª: {peak_memory:.2f} MB")
    print(f"  ãƒ¡ãƒ¢ãƒªå¢—åŠ é‡      : {memory_used:.2f} MB")
    print(f"  ãƒ¡ãƒ¢ãƒªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰: {global_metrics.metrics['memory']['memory_overhead_ratio']:.2f}x")
    print(f"  ç·ãƒãƒ£ãƒ³ã‚¯æ•°      : {global_metrics.metrics['memory']['chunk_count']:,}")
    print(f"  å¹³å‡ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º : {global_metrics.metrics['memory']['avg_chunk_size']:.0f} bytes")
    print(f"  GPUè»¢é€å›æ•°       : {global_metrics.metrics['performance']['gpu_transfer_count']:,}")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
    if total_data_size > 0:
        overall_throughput = (total_data_size / (1024*1024)) / total_time
        print("\n--- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ ---")
        print(f"  å…¨ä½“ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ  : {overall_throughput:.2f} MB/sec")
    
    print("\n--- å‡¦ç†æ–¹å¼ã®ç‰¹å¾´ ---")
    print("  âœ… ç›´æ¥GPUè»¢é€: memoryview â†’ GPUï¼ˆä¸­é–“ãƒãƒƒãƒ•ã‚¡ãªã—ï¼‰")
    print("  âœ… ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: BytesIO/bytearrayã‚’å®Œå…¨ã«æ’é™¤")
    print("  âœ… GPUè»¢é€æœ€é©åŒ–: ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«ç›´æ¥è»¢é€")
    print("=========================================")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    metrics_file = f"{OUTPUT_PARQUET_PATH}_metrics_direct.json"
    global_metrics.save_to_json(metrics_file)
    print(f"\nâœ… ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜: {metrics_file}")
    
    # Rayçµ‚äº†
    ray.shutdown()
    print("\nâœ… Rayçµ‚äº†")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='PostgreSQL â†’ GPU Rayä¸¦åˆ— ç›´æ¥GPUè»¢é€ç‰ˆ')
    parser.add_argument('--rows', type=int, default=10000000, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    parser.add_argument('--parallel', type=int, default=DEFAULT_PARALLEL, help='ä¸¦åˆ—æ•°')
    parser.add_argument('--chunks', type=int, default=4, help='ãƒãƒ£ãƒ³ã‚¯æ•°')
    parser.add_argument('--batch-size', type=int, default=4, help='ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒãƒƒãƒã‚µã‚¤ã‚º')
    parser.add_argument('--true-batch', action='store_true', help='çœŸã®ãƒãƒƒãƒGPUå‡¦ç†ã‚’æœ‰åŠ¹åŒ–ï¼ˆå®Ÿé¨“çš„ï¼‰')
    parser.add_argument('--no-limit', action='store_true', help='LIMITç„¡ã—ï¼ˆå…¨ä»¶é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼‰')
    parser.add_argument('--check-support', action='store_true', help='GPU Directã‚µãƒãƒ¼ãƒˆç¢ºèªã®ã¿')
    parser.add_argument('--no-gpu-direct', action='store_true', help='GPU Directç„¡åŠ¹åŒ–')
    
    args = parser.parse_args()
    
    # CUDAç¢ºèª
    try:
        cuda.current_context()
        print("âœ… CUDA context OK")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        exit(1)
    
    if args.check_support:
        check_gpu_direct_support()
        return
    
    # ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’è¨­å®š
    global CHUNK_COUNT
    CHUNK_COUNT = args.chunks
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    final_limit_rows = None if args.no_limit else args.rows
    run_ray_parallel_sequential_gpu(
        limit_rows=final_limit_rows,
        parallel_count=args.parallel,
        use_gpu_direct=not args.no_gpu_direct,
        batch_size=args.batch_size,
        true_batch_mode=args.true_batch
    )

if __name__ == "__main__":
    main()