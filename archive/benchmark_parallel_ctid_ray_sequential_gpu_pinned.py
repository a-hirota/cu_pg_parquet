"""
PostgreSQL â†’ GPU Rayä¸¦åˆ— é †æ¬¡GPUå‡¦ç†ç‰ˆ
CPUä¸¦åˆ—ã§COPYã€GPUå‡¦ç†ã¯é †æ¬¡å®Ÿè¡Œã—ã¦å®‰å®šæ€§ã‚’ç¢ºä¿

æœ€é©åŒ–:
- 16ä¸¦åˆ—ã§PostgreSQL COPYã‚’å®Ÿè¡Œ
- GPUå‡¦ç†ã¯1ã¤ãšã¤é †æ¬¡å®Ÿè¡Œï¼ˆãƒ¡ãƒ¢ãƒªç«¶åˆå›é¿ï¼‰
- CuPyé…åˆ—ã«ã‚ˆã‚‹å®‰å®šã—ãŸãƒ¡ãƒ¢ãƒªç®¡ç†
- 64å€‹ã®ç‹¬ç«‹ã—ãŸParquetãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›

ç’°å¢ƒå¤‰æ•°:
GPUPASER_PG_DSN  : PostgreSQLæ¥ç¶šæ–‡å­—åˆ—
"""

import os
import time
import math
import tempfile
import psycopg
import ray
import gc
import numpy as np
from numba import cuda
import argparse
from typing import List, Dict, Tuple, Optional

from src.metadata import fetch_column_meta
from src.cuda_kernels.postgresql_binary_parser import detect_pg_header_size
from src.main_postgres_to_parquet import postgresql_to_cudf_parquet

TABLE_NAME = "lineorder"
OUTPUT_PARQUET_PATH = "benchmark/lineorder_parallel_ctid_ray_sequential_gpu.output"

# ä¸¦åˆ—è¨­å®š
DEFAULT_PARALLEL = 16
CHUNK_COUNT = 4  # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ctidç¯„å›²ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²

@ray.remote
class PostgreSQLWorker:
    """Rayä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼: PostgreSQL COPYå°‚ç”¨"""
    
    def __init__(self, worker_id: int, dsn: str):
        self.worker_id = worker_id
        self.dsn = dsn
        
    def copy_data_to_memory(
        self, 
        table_name: str,
        start_block: int, 
        end_block: int,
        chunk_idx: int,
        total_chunks: int,
        limit_rows: Optional[int] = None,
        initial_buffer_size: int = 64 * 1024 * 1024  # 64MB
    ) -> Dict[str, any]:
        """PostgreSQLã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’COPYã—ã¦ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªã«ä¿å­˜"""
        
        # ãƒãƒ£ãƒ³ã‚¯ã«å¿œã˜ã¦ctidç¯„å›²ã‚’åˆ†å‰²
        block_range = end_block - start_block
        chunk_block_size = block_range // total_chunks
        
        chunk_start_block = start_block + (chunk_idx * chunk_block_size)
        chunk_end_block = start_block + ((chunk_idx + 1) * chunk_block_size) if chunk_idx < total_chunks - 1 else end_block
        
        print(f"Worker {self.worker_id}-Chunk{chunk_idx}: COPYé–‹å§‹ ctidç¯„å›² ({chunk_start_block},{chunk_end_block})...")
        
        start_time = time.time()
        
        try:
            # PostgreSQLæ¥ç¶š
            conn = psycopg.connect(self.dsn)
            
            # é€šå¸¸ã®bytearrayã‚’ä½¿ç”¨ï¼ˆRayãƒ¯ãƒ¼ã‚«ãƒ¼ã§ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªç¢ºä¿ã¯å›°é›£ï¼‰
            buffer = bytearray()
            offset = 0
            
            try:
                # COPY SQLç”Ÿæˆ
                copy_sql = self._make_copy_sql(table_name, chunk_start_block, chunk_end_block, limit_rows)
                
                # ãƒ‡ãƒ¼ã‚¿å–å¾—
                with conn.cursor() as cur:
                    with cur.copy(copy_sql) as copy_obj:
                        for chunk in copy_obj:
                            if chunk:
                                # memoryview â†’ byteså¤‰æ›
                                if isinstance(chunk, memoryview):
                                    chunk_bytes = chunk.tobytes()
                                else:
                                    chunk_bytes = bytes(chunk)
                                
                                # bytearrayã«è¿½åŠ 
                                buffer.extend(chunk_bytes)
                
                copy_time = time.time() - start_time
                data_size = len(buffer)  # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º
                print(f"Worker {self.worker_id}-Chunk{chunk_idx}: COPYå®Œäº† "
                      f"({copy_time:.2f}ç§’, {data_size/(1024*1024):.1f}MB)")
                
                # bytearrayã‚’bytesã«å¤‰æ›ã—ã¦è¿”ã™
                return {
                    'worker_id': self.worker_id,
                    'chunk_idx': chunk_idx,
                    'data': bytes(buffer),  # bytesã«å¤‰æ›ã—ã¦ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ã«
                    'data_size': data_size,
                    'copy_time': copy_time,
                    'status': 'success'
                }
                
            finally:
                conn.close()
                
        except Exception as e:
            print(f"Worker {self.worker_id}-Chunk{chunk_idx}: âŒCOPYå¤±æ•— - {e}")
            return {
                'worker_id': self.worker_id,
                'chunk_idx': chunk_idx,
                'status': 'error',
                'error': str(e),
                'copy_time': time.time() - start_time
            }
    
    def _make_copy_sql(self, table_name: str, start_block: int, end_block: int, limit_rows: Optional[int]) -> str:
        """COPY SQLç”Ÿæˆ"""
        sql = f"""
        COPY (
            SELECT * FROM {table_name}
            WHERE ctid >= '({start_block},1)'::tid
              AND ctid < '({end_block+1},1)'::tid
        """
        
        if limit_rows:
            # 64ã‚¿ã‚¹ã‚¯å…¨ä½“ã§ã®è¡Œæ•°åˆ¶é™
            sql += f" LIMIT {limit_rows // (DEFAULT_PARALLEL * CHUNK_COUNT)}"
        
        sql += ") TO STDOUT (FORMAT binary)"
        return sql


def process_batch_on_gpu(
    batch_tasks: List[Dict],
    columns: List,
    gds_supported: bool,
    output_base: str
) -> List[Dict]:
    """è¤‡æ•°ã®ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã‚’çµåˆã—ã¦1å›ã®GPUå‡¦ç†ã§å®Ÿè¡Œ"""
    
    import cupy as cp  # ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    
    num_tasks = len(batch_tasks)
    print(f"\nğŸ“Š ãƒãƒƒãƒGPUå‡¦ç†é–‹å§‹: {num_tasks}å€‹ã®ã‚¿ã‚¹ã‚¯ã‚’çµ±åˆå‡¦ç†")
    
    results = []
    start_total_time = time.time()
    
    try:
        # 1. å…¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        total_size = sum(task['data_size'] for task in batch_tasks)
        print(f"  çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size/(1024*1024):.2f} MB")
        
        # 2. cupyxã®é«˜ãƒ¬ãƒ™ãƒ«APIã‚’ä½¿ç”¨ã—ã¦ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªé…åˆ—ã‚’ä½œæˆ
        start_gpu_transfer_time = time.time()
        import cupyx
        pinned_array = cupyx.zeros_pinned(total_size, dtype=np.uint8)
        
        # 3. å„ã‚¿ã‚¹ã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªã«ã‚³ãƒ”ãƒ¼
        task_offsets = []
        current_offset = 0
        
        for task in batch_tasks:
            # ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªã«ã‚³ãƒ”ãƒ¼
            data_len = task['data_size']
            pinned_array[current_offset:current_offset + data_len] = np.frombuffer(task['data'], dtype=np.uint8)
            
            task_offsets.append({
                'worker_id': task['worker_id'],
                'chunk_idx': task['chunk_idx'],
                'offset': current_offset,
                'size': task['data_size']
            })
            current_offset += task['data_size']
        
        # 4. GPUé…åˆ—ã‚’ç¢ºä¿ã—ã€ãƒ”ãƒ³ãƒ¡ãƒ¢ãƒªã‹ã‚‰é«˜é€Ÿè»¢é€ï¼ˆset()ã‚’ä½¿ç”¨ï¼‰
        gpu_array = cp.empty(total_size, dtype=cp.uint8)
        gpu_array.set(pinned_array)  # åŠ¹ç‡çš„ãªã‚³ãƒ”ãƒ¼æ–¹æ³•
        
        gpu_transfer_time = time.time() - start_gpu_transfer_time
        print(f"  GPUè»¢é€å®Œäº† ({gpu_transfer_time:.2f}ç§’, {(total_size/(1024*1024))/gpu_transfer_time:.2f} MB/sec)")
        
        # 5. çµ±åˆãƒ‡ãƒ¼ã‚¿ã§1å›ã®GPUå‡¦ç†ã‚’å®Ÿè¡Œ
        start_gpu_processing_time = time.time()
        
        # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å€‹åˆ¥ã«å‡¦ç†ï¼ˆå°†æ¥çš„ã«ã¯çµ±åˆå‡¦ç†ã«æ‹¡å¼µå¯èƒ½ï¼‰
        for i, (task, offset_info) in enumerate(zip(batch_tasks, task_offsets)):
            print(f"\n  å‡¦ç†ä¸­ [{i+1}/{num_tasks}]: Worker{offset_info['worker_id']}-Chunk{offset_info['chunk_idx']}")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ‡ã‚Šå‡ºã—
            dataset_gpu = gpu_array[offset_info['offset']:offset_info['offset'] + offset_info['size']]
            
            # numbaç”¨ã®é…åˆ—ã«å¤‰æ›
            raw_dev = cuda.as_cuda_array(dataset_gpu)
            header_sample = dataset_gpu[:min(128, len(dataset_gpu))].get()
            header_size = detect_pg_header_size(header_sample)
            
            # å‡ºåŠ›ãƒ‘ã‚¹
            output_path = f"{output_base}_worker{offset_info['worker_id']}_chunk{offset_info['chunk_idx']}.parquet"
            
            # GPUæœ€é©åŒ–å‡¦ç†
            cudf_df, detailed_timing = postgresql_to_cudf_parquet(
                raw_dev=raw_dev,
                columns=columns,
                ncols=len(columns),
                header_size=header_size,
                output_path=output_path,
                compression='snappy',
                use_rmm=False,
                optimize_gpu=True
            )
            
            results.append({
                'worker_id': offset_info['worker_id'],
                'chunk_idx': offset_info['chunk_idx'],
                'gpu_transfer_time': gpu_transfer_time / num_tasks,  # è»¢é€æ™‚é–“ã‚’åˆ†é…
                'gpu_processing_time': detailed_timing.get('overall_total', 0),
                'rows_processed': len(cudf_df),
                'status': 'success'
            })
        
        gpu_processing_time = time.time() - start_gpu_processing_time
        total_time = time.time() - start_total_time
        
        print(f"\nâœ… ãƒãƒƒãƒGPUå‡¦ç†å®Œäº†:")
        print(f"  ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
        print(f"  GPUè»¢é€: {gpu_transfer_time:.2f}ç§’")
        print(f"  GPUå‡¦ç†: {gpu_processing_time:.2f}ç§’")
        print(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {(total_size/(1024*1024))/total_time:.2f} MB/sec")
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del gpu_array
        gc.collect()
        cp.get_default_memory_pool().free_all_blocks()
        cuda.synchronize()
        
        return results
        
    except Exception as e:
        print(f"  âŒãƒãƒƒãƒGPUå‡¦ç†å¤±æ•—: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å€‹åˆ¥ã«ã‚¨ãƒ©ãƒ¼çµæœã‚’è¿”ã™
        for task in batch_tasks:
            results.append({
                'worker_id': task['worker_id'],
                'chunk_idx': task['chunk_idx'],
                'status': 'error',
                'error': str(e)
            })
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾ã‚’è©¦ã¿ã‚‹
        try:
            gc.collect()
            cp.get_default_memory_pool().free_all_blocks()
            cuda.synchronize()
        except:
            pass
            
        return results


def get_table_blocks(dsn: str, table_name: str) -> int:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’å–å¾—"""
    conn = psycopg.connect(dsn)
    try:
        with conn.cursor() as cur:
            cur.execute(f"SELECT pg_relation_size('{table_name}') / 8192 AS blocks")
            blocks = cur.fetchone()[0]
            return int(blocks)
    finally:
        conn.close()


def make_ctid_ranges(total_blocks: int, parallel_count: int) -> List[Tuple[int, int]]:
    """ctidç¯„å›²ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ"""
    chunk_size = math.ceil(total_blocks / parallel_count)
    ranges = []
    
    for i in range(parallel_count):
        start_block = i * chunk_size
        end_block = min((i + 1) * chunk_size, total_blocks)
        if start_block < total_blocks:
            ranges.append((start_block, end_block))
    
    return ranges


def check_gpu_direct_support() -> bool:
    """GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª"""
    print("\n=== GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª ===")
    
    try:
        if os.path.exists("/proc/driver/nvidia-fs/stats"):
            print("âœ… nvidia-fs ãƒ‰ãƒ©ã‚¤ãƒæ¤œå‡º")
        else:
            print("âš ï¸  nvidia-fs ãƒ‰ãƒ©ã‚¤ãƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
    except Exception:
        print("âš ï¸  nvidia-fs ç¢ºèªã‚¨ãƒ©ãƒ¼")
        return False
    
    try:
        import kvikio
        print(f"âœ… kvikio ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {kvikio.__version__}")
        os.environ["KVIKIO_COMPAT_MODE"] = "OFF"
        print("âœ… KVIKIO_COMPAT_MODE=OFF è¨­å®šå®Œäº†")
        return True
    except ImportError:
        print("âš ï¸  kvikio ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False


def run_ray_parallel_sequential_gpu(
    limit_rows: int = 10000000,
    parallel_count: int = DEFAULT_PARALLEL,
    use_gpu_direct: bool = True,
    batch_size: int = 4
):
    """Rayä¸¦åˆ—COPY + é †æ¬¡GPUå‡¦ç†"""
    
    dsn = os.environ.get("GPUPASER_PG_DSN")
    if not dsn:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GPUPASER_PG_DSN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    print(f"=== PostgreSQL â†’ GPU Rayä¸¦åˆ— é †æ¬¡GPUå‡¦ç†ç‰ˆ ===")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {TABLE_NAME}")
    print(f"è¡Œæ•°åˆ¶é™: {limit_rows:,}" if limit_rows else "è¡Œæ•°åˆ¶é™: ãªã—ï¼ˆå…¨ä»¶å‡¦ç†ï¼‰")
    print(f"ä¸¦åˆ—æ•°: {parallel_count}")
    print(f"ãƒãƒ£ãƒ³ã‚¯æ•°: {CHUNK_COUNT}")
    print(f"ç·ã‚¿ã‚¹ã‚¯æ•°: {parallel_count * CHUNK_COUNT}")
    print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
    print(f"å‡¦ç†æ–¹å¼:")
    print(f"  â‘  CPU: {parallel_count}ä¸¦åˆ—ã§PostgreSQL COPYå®Ÿè¡Œ")
    print(f"  â‘¡ GPU: ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ï¼ˆ{batch_size}å€‹ã®COPYå®Œäº†ã”ã¨ã«GPUå‡¦ç†é–‹å§‹ï¼‰")
    
    # GPU Direct ã‚µãƒãƒ¼ãƒˆç¢ºèª
    gds_supported = check_gpu_direct_support() if use_gpu_direct else False
    
    # RayåˆæœŸåŒ–ï¼ˆGPUæŒ‡å®šãªã—ï¼‰
    print("\n=== RayåˆæœŸåŒ– ===")
    if not ray.is_initialized():
        ray.init(num_cpus=parallel_count * 2)
        print(f"âœ… RayåˆæœŸåŒ–å®Œäº†")
    
    start_total_time = time.time()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    print("\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    start_meta_time = time.time()
    conn = psycopg.connect(dsn)
    try:
        columns = fetch_column_meta(conn, f"SELECT * FROM {TABLE_NAME}")
        meta_time = time.time() - start_meta_time
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({meta_time:.4f}ç§’)")
    finally:
        conn.close()
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°å–å¾—
    print("ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ–ãƒ­ãƒƒã‚¯æ•°ã‚’å–å¾—ä¸­...")
    total_blocks = get_table_blocks(dsn, TABLE_NAME)
    print(f"ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°: {total_blocks:,}")
    
    # ctidç¯„å›²åˆ†å‰²
    ranges = make_ctid_ranges(total_blocks, parallel_count)
    print(f"ctidç¯„å›²åˆ†å‰²: {len(ranges)}å€‹ã®ç¯„å›²")
    
    # Rayä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ä½œæˆ
    workers = []
    for i in range(len(ranges)):
        worker = PostgreSQLWorker.remote(i, dsn)
        workers.append(worker)
    
    # å…¨ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹
    print(f"\n=== ãƒ•ã‚§ãƒ¼ã‚º1: PostgreSQL COPYä¸¦åˆ—å®Ÿè¡Œ ===")
    all_copy_futures = []
    
    for worker_idx, (start_block, end_block) in enumerate(ranges):
        for chunk_idx in range(CHUNK_COUNT):
            future = workers[worker_idx].copy_data_to_memory.remote(
                TABLE_NAME, start_block, end_block, chunk_idx, CHUNK_COUNT, limit_rows
            )
            all_copy_futures.append(future)
    
    print(f"âœ… {len(all_copy_futures)}å€‹ã®COPYã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥")
    
    # ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†: COPYã¨GPUã‚’ä¸¦è¡Œå®Ÿè¡Œ
    copy_results = []
    gpu_results = []
    pending_gpu_tasks = []  # GPUå‡¦ç†å¾…ã¡ã®ã‚¿ã‚¹ã‚¯
    
    total_copy_time = 0
    total_data_size = 0
    total_gpu_transfer_time = 0
    total_gpu_processing_time = 0
    total_rows_processed = 0
    
    output_base = OUTPUT_PARQUET_PATH
    
    print(f"\n=== ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†é–‹å§‹ ===")
    print(f"COPYãŒ{batch_size}å€‹å®Œäº†ã™ã‚‹ã”ã¨ã«GPUå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
    
    while all_copy_futures or pending_gpu_tasks:
        # COPYã‚¿ã‚¹ã‚¯ãŒã¾ã ã‚ã‚‹å ´åˆ
        if all_copy_futures:
            # å®Œäº†ã—ãŸCOPYã‚¿ã‚¹ã‚¯ã‚’ãƒãƒƒãƒã‚µã‚¤ã‚ºã¾ã§åé›†
            num_to_wait = min(batch_size, len(all_copy_futures))
            ready_futures, remaining_futures = ray.wait(all_copy_futures, num_returns=num_to_wait, timeout=0.1)
            all_copy_futures = remaining_futures
            
            # COPYçµæœã‚’å‡¦ç†
            for future in ready_futures:
                result = ray.get(future)
                copy_results.append(result)
                
                if result['status'] == 'success':
                    total_copy_time += result['copy_time']
                    total_data_size += result['data_size']
                    pending_gpu_tasks.append(result)
                    print(f"âœ… COPYå®Œäº†: Worker{result['worker_id']}-Chunk{result['chunk_idx']} "
                          f"({result['data_size']/(1024*1024):.1f}MB)")
                else:
                    print(f"âŒ COPYå¤±æ•—: Worker{result['worker_id']}-Chunk{result['chunk_idx']} - "
                          f"{result.get('error', 'Unknown')}")
        
        # GPUå‡¦ç†å¾…ã¡ã‚¿ã‚¹ã‚¯ãŒãƒãƒƒãƒã‚µã‚¤ã‚ºã«é”ã—ãŸå ´åˆã€ã¾ãŸã¯COPYãŒå…¨ã¦å®Œäº†ã—ãŸå ´åˆ
        if (len(pending_gpu_tasks) >= batch_size) or (not all_copy_futures and pending_gpu_tasks):
            # ãƒãƒƒãƒã‚µã‚¤ã‚ºåˆ†ã®ã‚¿ã‚¹ã‚¯ã‚’å–å¾—
            tasks_to_process = pending_gpu_tasks[:batch_size] if len(pending_gpu_tasks) >= batch_size else pending_gpu_tasks
            pending_gpu_tasks = pending_gpu_tasks[len(tasks_to_process):]
            
            # ãƒãƒƒãƒGPUå‡¦ç†ã‚’å®Ÿè¡Œ
            batch_results = process_batch_on_gpu(
                tasks_to_process,
                columns,
                gds_supported,
                output_base
            )
            
            # çµæœã‚’é›†è¨ˆ
            for gpu_result in batch_results:
                gpu_results.append(gpu_result)
                
                if gpu_result['status'] == 'success':
                    total_gpu_transfer_time += gpu_result['gpu_transfer_time']
                    total_gpu_processing_time += gpu_result['gpu_processing_time']
                    total_rows_processed += gpu_result['rows_processed']
            
            print(f"å‡¦ç†æ¸ˆã¿ã‚¿ã‚¹ã‚¯ç´¯è¨ˆ: {len(gpu_results)}/{len(copy_results)}")
    
    # æˆåŠŸã—ãŸå‡¦ç†ã®æ•°ã‚’é›†è¨ˆ
    successful_copies = [r for r in copy_results if r['status'] == 'success']
    successful_gpu = [r for r in gpu_results if r['status'] == 'success']
    
    print(f"\nâœ… å…¨å‡¦ç†å®Œäº†")
    print(f"COPY: {len(successful_copies)}/{len(copy_results)} ã‚¿ã‚¹ã‚¯æˆåŠŸ")
    print(f"GPU: {len(successful_gpu)}/{len(gpu_results)} ã‚¿ã‚¹ã‚¯æˆåŠŸ")
    print(f"ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_data_size / (1024*1024):.2f} MB")
    
    # ç·åˆçµæœ
    total_time = time.time() - start_total_time
    
    print(f"\n{'='*60}")
    print(f"=== Rayä¸¦åˆ—ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³GPUå‡¦ç†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº† ===")
    print(f"{'='*60}")
    print(f"ç·æ™‚é–“ = {total_time:.4f} ç§’")
    print("--- æ™‚é–“å†…è¨³ ---")
    print(f"  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—    : {meta_time:.4f} ç§’")
    print(f"  PostgreSQL COPY   : {total_copy_time:.4f} ç§’ (ç´¯ç©)")
    print(f"  GPUè»¢é€          : {total_gpu_transfer_time:.4f} ç§’ (ç´¯ç©)")
    print(f"  GPUå‡¦ç†          : {total_gpu_processing_time:.4f} ç§’ (ç´¯ç©)")
    print("--- çµ±è¨ˆæƒ…å ± ---")
    print(f"  å‡¦ç†è¡Œæ•°ï¼ˆåˆè¨ˆï¼‰  : {total_rows_processed:,} è¡Œ")
    print(f"  å‡¦ç†åˆ—æ•°         : {len(columns)} åˆ—")
    print(f"  ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º    : {total_data_size / (1024*1024):.2f} MB")
    print(f"  æˆåŠŸç‡           : COPY {len(successful_copies)}/{len(copy_results)}, "
          f"GPU {len(successful_gpu)}/{len(gpu_results)}")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
    if total_data_size > 0:
        overall_throughput = (total_data_size / (1024*1024)) / total_time
        print("\n--- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ ---")
        print(f"  å…¨ä½“ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ  : {overall_throughput:.2f} MB/sec")
    
    print("\n--- å‡¦ç†æ–¹å¼ã®ç‰¹å¾´ ---")
    print("  âœ… ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: COPYã¨GPUå‡¦ç†ã‚’ä¸¦è¡Œå®Ÿè¡Œ")
    print(f"  âœ… ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}å€‹ã®COPYå®Œäº†ã”ã¨ã«GPUå‡¦ç†é–‹å§‹")
    print("  âœ… ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: GPUãƒ¡ãƒ¢ãƒªç«¶åˆã‚’å›é¿")
    print("  âœ… ç¢ºå®Ÿãªå‡¦ç†: 64å€‹ã®Parquetãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ")
    print("=========================================")
    
    # Rayçµ‚äº†
    ray.shutdown()
    print("\nâœ… Rayçµ‚äº†")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description='PostgreSQL â†’ GPU Rayä¸¦åˆ— ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ç‰ˆ')
    parser.add_argument('--rows', type=int, default=10000000, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    parser.add_argument('--parallel', type=int, default=DEFAULT_PARALLEL, help='ä¸¦åˆ—æ•°')
    parser.add_argument('--chunks', type=int, default=4, help='ãƒãƒ£ãƒ³ã‚¯æ•°')
    parser.add_argument('--batch-size', type=int, default=4, help='ã‚»ãƒŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒãƒƒãƒã‚µã‚¤ã‚º')
    parser.add_argument('--no-limit', action='store_true', help='LIMITç„¡ã—ï¼ˆå…¨ä»¶é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼‰')
    parser.add_argument('--check-support', action='store_true', help='GPU Directã‚µãƒãƒ¼ãƒˆç¢ºèªã®ã¿')
    parser.add_argument('--no-gpu-direct', action='store_true', help='GPU Directç„¡åŠ¹åŒ–')
    
    args = parser.parse_args()
    
    # CUDAç¢ºèª
    try:
        cuda.current_context()
        print("âœ… CUDA context OK")
    except Exception as e:
        print(f"âŒ CUDAåˆæœŸåŒ–å¤±æ•—: {e}")
        exit(1)
    
    if args.check_support:
        check_gpu_direct_support()
        return
    
    # ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’è¨­å®š
    global CHUNK_COUNT
    CHUNK_COUNT = args.chunks
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    final_limit_rows = None if args.no_limit else args.rows
    run_ray_parallel_sequential_gpu(
        limit_rows=final_limit_rows,
        parallel_count=args.parallel,
        use_gpu_direct=not args.no_gpu_direct,
        batch_size=args.batch_size
    )

if __name__ == "__main__":
    main()