#!/usr/bin/env python3
"""
ä¸€æ‹¬COPYã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’GPUã§å‡¦ç†ã—ã¦è¡Œæ•°ã‚’ç¢ºèª
"""
import os
import sys
import time
import rmm
import cupy as cp
import kvikio
from numba import cuda

# ç’°å¢ƒè¨­å®š
os.environ["GPUPASER_PG_DSN"] = "host=localhost dbname=postgres user=postgres"
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.cuda_kernels.postgres_binary_parser import parse_rows_and_fields_lite, detect_pg_header_size
from docs.benchmark.benchmark_rust_gpu_direct import setup_rmm_pool, get_postgresql_metadata

def main():
    # RMMãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–
    setup_rmm_pool()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    columns = get_postgresql_metadata("customer")
    print(f"âœ… ã‚«ãƒ©ãƒ æ•°: {len(columns)}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    file_path = "/dev/shm/customer_single_copy.bin"
    print(f"\nğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {file_path}")
    
    start = time.time()
    file_size = os.path.getsize(file_path)
    print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes ({file_size/1024/1024/1024:.2f} GB)")
    
    # kvikioã§èª­ã¿è¾¼ã¿
    data_gpu = rmm.DeviceBuffer(size=file_size)
    with kvikio.CuFile(file_path, "r") as f:
        f.read(data_gpu)
    read_time = time.time() - start
    print(f"kvikioèª­ã¿è¾¼ã¿æ™‚é–“: {read_time:.2f}ç§’")
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºæ¤œå‡º
    header_info = cp.zeros(3, dtype=cp.int32)
    detect_pg_header_size_kernel = detect_pg_header_size.specialize(data_gpu, header_info)
    detect_pg_header_size_kernel[1, 1]()
    cuda.synchronize()
    header_size = int(header_info[0])
    num_fields = int(header_info[1])
    
    print(f"\nğŸ” PostgreSQLãƒ˜ãƒƒãƒ€ãƒ¼:")
    print(f"  - ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º: {header_size} ãƒã‚¤ãƒˆ")
    print(f"  - ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°: {num_fields}")
    
    # GPUè§£æ
    print(f"\nğŸš€ GPUè§£æé–‹å§‹...")
    start = time.time()
    
    # è¡Œæ•°æ¨å®š
    estimated_row_size = 141  # customerãƒ†ãƒ¼ãƒ–ãƒ«ã®å¹³å‡è¡Œã‚µã‚¤ã‚º
    estimated_rows = (file_size - header_size) // estimated_row_size
    max_rows = int(estimated_rows * 1.5)  # 50%ãƒãƒ¼ã‚¸ãƒ³
    
    print(f"æ¨å®šè¡Œæ•°: {estimated_rows:,}")
    print(f"ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {max_rows:,} è¡Œ")
    
    # GPUé…åˆ—ç¢ºä¿
    row_info_size = 8 + 4 * num_fields + 4 * num_fields  # row_pos + offsets + lengths
    row_info_gpu = rmm.DeviceBuffer(size=max_rows * row_info_size)
    detected_rows_gpu = cp.zeros(1, dtype=cp.int32)
    
    # ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
    threads_per_block = 256
    blocks = (estimated_rows + threads_per_block - 1) // threads_per_block
    
    parse_kernel = parse_rows_and_fields_lite.specialize(
        data_gpu,
        row_info_gpu,
        detected_rows_gpu,
        max_rows,
        header_size,
        file_size,
        estimated_row_size,
        num_fields
    )
    parse_kernel[blocks, threads_per_block]()
    cuda.synchronize()
    
    detected_rows = int(detected_rows_gpu[0])
    parse_time = time.time() - start
    
    print(f"\nâœ… GPUè§£æå®Œäº†:")
    print(f"  - æ¤œå‡ºè¡Œæ•°: {detected_rows:,} è¡Œ")
    print(f"  - å‡¦ç†æ™‚é–“: {parse_time:.2f}ç§’")
    print(f"  - PostgreSQLæœŸå¾…å€¤: 12,030,000 è¡Œ")
    print(f"  - å·®åˆ†: {12030000 - detected_rows:,} è¡Œ ({(12030000 - detected_rows) / 12030000 * 100:.4f}%)")
    
    if detected_rows == 12030000:
        print("\nğŸ‰ 100%ã®ç²¾åº¦ã‚’é”æˆï¼")
    else:
        print(f"\nâš ï¸  {12030000 - detected_rows}è¡ŒãŒæ¬ è½ã—ã¦ã„ã¾ã™")

if __name__ == "__main__":
    main()