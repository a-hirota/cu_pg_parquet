/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
[3386020][05:07:44:834089][error ] Parquet writer encountered exception during processing. No data has been written to the sink.
/home/ubuntu/gpupgparser/src/write_parquet_from_cudf.py:118: UserWarning: 拡張書き込み失敗, 標準方式にフォールバック: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 2574648720 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
  warnings.warn(f"拡張書き込み失敗, 標準方式にフォールバック: {e}")
[3386020][05:07:45:044036][error ] Parquet writer encountered exception during processing. No data has been written to the sink.
/home/ubuntu/gpupgparser/src/write_parquet_from_cudf.py:49: UserWarning: cuDF直接書き出し失敗, PyArrowにフォールバック: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 2574648720 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
  warnings.warn(f"cuDF直接書き出し失敗, PyArrowにフォールバック: {e}")
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/dispatcher.py:605: NumbaPerformanceWarning: [1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
[3386020][05:08:07:806632][error ] Parquet writer encountered exception during processing. No data has been written to the sink.
/home/ubuntu/gpupgparser/src/write_parquet_from_cudf.py:118: UserWarning: 拡張書き込み失敗, 標準方式にフォールバック: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 2496954608 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
  warnings.warn(f"拡張書き込み失敗, 標準方式にフォールバック: {e}")
[3386020][05:08:08:012166][error ] Parquet writer encountered exception during processing. No data has been written to the sink.
/home/ubuntu/gpupgparser/src/write_parquet_from_cudf.py:49: UserWarning: cuDF直接書き出し失敗, PyArrowにフォールバック: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 2496954608 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
  warnings.warn(f"cuDF直接書き出し失敗, PyArrowにフォールバック: {e}")
Traceback (most recent call last):
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 135, in process_chunk_unified
    raw_dev = cuda.to_device(raw_host)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devices.py", line 232, in _require_cuda_context
    return fn(*args, **kws)
           ^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/api.py", line 128, in to_device
    to, new = devicearray.auto_device(obj, stream=stream, copy=copy,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 880, in auto_device
    devobj = from_array_like(obj, stream=stream)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 801, in from_array_like
    return DeviceNDArray(ary.shape, ary.strides, ary.dtype, stream=stream,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 103, in __init__
    gpu_data = devices.get_context().memalloc(self.alloc_size)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/driver.py", line 1372, in memalloc
    return self.memory_manager.memalloc(bytesize)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/rmm/allocators/numba.py", line 73, in memalloc
    buf = pylibrmm.DeviceBuffer(size=size)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "device_buffer.pyx", line 102, in rmm.pylibrmm.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 6973053472 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 257, in main
    gpu_time, _, rows, timing = process_chunk_unified(chunk_info, columns)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 135, in process_chunk_unified
    raw_dev = cuda.to_device(raw_host)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devices.py", line 232, in _require_cuda_context
    return fn(*args, **kws)
           ^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/api.py", line 128, in to_device
    to, new = devicearray.auto_device(obj, stream=stream, copy=copy,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 880, in auto_device
    devobj = from_array_like(obj, stream=stream)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 801, in from_array_like
    return DeviceNDArray(ary.shape, ary.strides, ary.dtype, stream=stream,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 103, in __init__
    gpu_data = devices.get_context().memalloc(self.alloc_size)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/driver.py", line 1372, in memalloc
    return self.memory_manager.memalloc(bytesize)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/rmm/allocators/numba.py", line 73, in memalloc
    buf = pylibrmm.DeviceBuffer(size=size)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "device_buffer.pyx", line 102, in rmm.pylibrmm.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 6973053472 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
=== PostgreSQL → Rust → GPU 統一処理版 ===
チャンク数: 8
各チャンクサイズ: 約6.6 GB
出力ディレクトリ: /dev/shm

改善内容:
  - cuda.to_device()で直接GPU転送
  - postgresql_to_cudf_parquet()で一括処理
  - cuDF DataFrame作成のCPUシングルスレッド問題を解決
RMM既に初期化済み

✅ CUDA context OK

[Rust] チャンク 1/8 転送開始
[Rust] チャンク 1 転送完了: 6.59 GB, 4.89秒 (1.35 GB/秒)
カラム数: 17

[GPU] チャンク 1 統一処理開始
  ファイル読み込み: 3.47秒 (1.90 GB/秒)
  GPU転送: 0.54秒 (12.25 GB/秒)
=== GPU並列パース開始 ===
✅ Ultra Fast GPU並列パーサー使用（8.94倍高速化達成）
GPUパース完了: 14814344 行 (2.9877秒)
=== 文字列最適化デコード開始 ===
文字列列 lo_orderpriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_orderpriority: 最適化バッファ作成完了 (222215160 bytes)
文字列列 lo_shippriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shippriority: 最適化バッファ作成完了 (14814344 bytes)
文字列列 lo_commit_date: 直接コピー最適化カーネル実行
✅ 文字列列 lo_commit_date: 最適化バッファ作成完了 (118514752 bytes)
文字列列 lo_shipmode: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shipmode: 最適化バッファ作成完了 (148143440 bytes)
統合カーネル実行（固定長データのみ）: 57869 blocks × 256 threads

=== パフォーマンス統計（文字列最適化版） ===
処理データ: 14,814,344 行 × 17 列
データサイズ: 6745.30 MB

--- 詳細タイミング ---
  gpu_parsing         : 2.9877 秒
  decode_and_export   : 11.4332 秒
    ├─ preparation   : 0.4747 秒
    │  └─ string_opt  : 0.4747 秒
    ├─ gpu_decode      : 1.3719 秒
    └─ cudf_creation : 1.1219 秒
  parquet_export      : 8.4559 秒
    └─ cudf_direct   : 8.1478 秒
  total               : 11.4242 秒
  overall_total       : 14.4209 秒

--- スループット ---
  セル処理速度: 17,463,825 cells/sec
  データ処理速度: 467.74 MB/sec
  文字列最適化効率: 3.3%
  GPU使用効率: 9.5%
==============================
[GPU] チャンク 1 処理完了:
  - 処理行数: 14,814,344 行
  - GPU全体時間: 18.43秒
  - 内訳:
    - ファイル読込: 3.47秒
    - GPU転送: 0.54秒
    - GPUパース: 2.99秒
    - デコード+cuDF: 11.43秒 (cuDF作成: 1.12秒)
    - Parquet書込: 8.46秒
  - スループット: 0.36 GB/秒

[Rust] チャンク 2/8 転送開始
[Rust] チャンク 2 転送完了: 6.49 GB, 4.60秒 (1.41 GB/秒)

[GPU] チャンク 2 統一処理開始
  ファイル読み込み: 3.48秒 (1.87 GB/秒)
  GPU転送: 0.58秒 (11.13 GB/秒)
=== GPU並列パース開始 ===
✅ Ultra Fast GPU並列パーサー使用（8.94倍高速化達成）
GPUパース完了: 14496479 行 (2.4739秒)
=== 文字列最適化デコード開始 ===
文字列列 lo_orderpriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_orderpriority: 最適化バッファ作成完了 (217447185 bytes)
文字列列 lo_shippriority: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shippriority: 最適化バッファ作成完了 (14496479 bytes)
文字列列 lo_commit_date: 直接コピー最適化カーネル実行
✅ 文字列列 lo_commit_date: 最適化バッファ作成完了 (115971832 bytes)
文字列列 lo_shipmode: 直接コピー最適化カーネル実行
✅ 文字列列 lo_shipmode: 最適化バッファ作成完了 (144964790 bytes)
統合カーネル実行（固定長データのみ）: 56627 blocks × 256 threads

=== パフォーマンス統計（文字列最適化版） ===
処理データ: 14,496,479 行 × 17 列
データサイズ: 6650.02 MB

--- 詳細タイミング ---
  gpu_parsing         : 2.4739 秒
  decode_and_export   : 9.7417 秒
    ├─ preparation   : 0.5192 秒
    │  └─ string_opt  : 0.5192 秒
    ├─ gpu_decode      : 0.0989 秒
    └─ cudf_creation : 1.0613 秒
  parquet_export      : 8.0622 秒
    └─ cudf_direct   : 7.8379 秒
  total               : 9.7417 秒
  overall_total       : 12.2156 秒

--- スループット ---
  セル処理速度: 20,174,212 cells/sec
  データ処理速度: 544.39 MB/sec
  文字列最適化効率: 4.3%
  GPU使用効率: 0.8%
==============================
[GPU] チャンク 2 処理完了:
  - 処理行数: 14,496,479 行
  - GPU全体時間: 16.28秒
  - 内訳:
    - ファイル読込: 3.48秒
    - GPU転送: 0.58秒
    - GPUパース: 2.47秒
    - デコード+cuDF: 9.74秒 (cuDF作成: 1.06秒)
    - Parquet書込: 8.06秒
  - スループット: 0.40 GB/秒

[Rust] チャンク 3/8 転送開始
[Rust] チャンク 3 転送完了: 6.49 GB, 4.93秒 (1.32 GB/秒)

[GPU] チャンク 3 統一処理開始
  ファイル読み込み: 3.60秒 (1.80 GB/秒)
❌ GPU処理エラー: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 6973053472 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp

❌ エラー: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 6973053472 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
Traceback (most recent call last):
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 292, in <module>
    main()
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 257, in main
    gpu_time, _, rows, timing = process_chunk_unified(chunk_info, columns)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/gpupgparser/benchmark/benchmark_rust_gpu_unified.py", line 135, in process_chunk_unified
    raw_dev = cuda.to_device(raw_host)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devices.py", line 232, in _require_cuda_context
    return fn(*args, **kws)
           ^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/api.py", line 128, in to_device
    to, new = devicearray.auto_device(obj, stream=stream, copy=copy,
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 880, in auto_device
    devobj = from_array_like(obj, stream=stream)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 801, in from_array_like
    return DeviceNDArray(ary.shape, ary.strides, ary.dtype, stream=stream,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/devicearray.py", line 103, in __init__
    gpu_data = devices.get_context().memalloc(self.alloc_size)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/numba_cuda/numba/cuda/cudadrv/driver.py", line 1372, in memalloc
    return self.memory_manager.memalloc(bytesize)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cudf_dev/lib/python3.12/site-packages/rmm/allocators/numba.py", line 73, in memalloc
    buf = pylibrmm.DeviceBuffer(size=size)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "device_buffer.pyx", line 102, in rmm.pylibrmm.device_buffer.DeviceBuffer.__cinit__
MemoryError: std::bad_alloc: out_of_memory: CUDA error (failed to allocate 6973053472 bytes) at: /home/ubuntu/miniconda3/envs/cudf_dev/include/rmm/mr/device/cuda_memory_resource.hpp
