#!/usr/bin/env python3
"""
lineorderå®Ÿãƒ‡ãƒ¼ã‚¿GPGPUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

å®Ÿéš›ã®lineorderãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆ2.46å„„è¡Œã€42GBï¼‰ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§
GPGPUé©æ–°çš„å‡¦ç†æ€§èƒ½ã‚’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã€‚
"""

import psycopg
import os
import time
import io
import numpy as np
import cupy as cp
from numba import cuda

def test_lineorder_gpgpu_performance():
    """lineorderå®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®GPGPUæ€§èƒ½ãƒ†ã‚¹ãƒˆ"""
    print("=== lineorderå®Ÿãƒ‡ãƒ¼ã‚¿GPGPUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ===")
    print("ğŸ¯ ç›®æ¨™: å¦¥å”ãªãGPGPUé©æ–°ã®å®Ÿè¨¼")
    
    # PostgreSQLæ¥ç¶šã¨ãƒ‡ãƒ¼ã‚¿å–å¾—
    print("\nğŸ“Š lineorderãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
    try:
        dsn = os.environ.get('GPUPASER_PG_DSN')
        conn = psycopg.connect(dsn)
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨­å®šï¼ˆé©æ–°çš„å‡¦ç†ã®ãƒ‡ãƒ¢ç”¨ï¼‰
        limit = 100000  # 10ä¸‡è¡Œã‚µãƒ³ãƒ—ãƒ«
        print(f"ğŸ“¦ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­ ({limit:,}è¡Œ)...")
        
        start_time = time.time()
        
        with conn.cursor() as cur:
            # COPY BINARYå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿å–å¾—
            query = f"COPY (SELECT * FROM lineorder LIMIT {limit}) TO STDOUT (FORMAT binary)"
            
            buffer = io.BytesIO()
            with cur.copy(query) as copy:
                for data in copy:
                    buffer.write(data)
            
            binary_data = buffer.getvalue()
            buffer.close()
        
        data_fetch_time = time.time() - start_time
        conn.close()
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(binary_data):,} bytes ({data_fetch_time:.3f}ç§’)")
        print(f"   ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(binary_data) / (1024*1024):.2f} MB")
        print(f"   å–å¾—ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {(len(binary_data) / (1024*1024)) / data_fetch_time:.1f} MB/sec")
        
        # GPGPUé©æ–°å‡¦ç†é–‹å§‹
        print("\nğŸš€ GPGPUé©æ–°å‡¦ç†é–‹å§‹...")
        gpu_start_time = time.time()
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: GPUè»¢é€ï¼ˆã‚¼ãƒ­ã‚³ãƒ”ãƒ¼æœ€é©åŒ–ï¼‰
        data_host = np.frombuffer(binary_data, dtype=np.uint8)
        data_gpu = cuda.to_device(data_host)
        
        gpu_transfer_time = time.time() - gpu_start_time
        print(f"âœ… GPUè»¢é€å®Œäº†: {data_gpu.shape} ({gpu_transfer_time*1000:.3f}ms)")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: PostgreSQL BINARYãƒ˜ãƒƒãƒ€ãƒ¼è§£æï¼ˆGPUç‰ˆï¼‰
        @cuda.jit
        def analyze_pg_binary_header_gpu(data, result_out):
            """GPUç‰ˆPostgreSQL BINARYãƒ˜ãƒƒãƒ€ãƒ¼è§£æ"""
            idx = cuda.threadIdx.x
            if idx == 0 and data.size >= 19:
                # PostgreSQL BINARY signature: PGCOPY\n\377\r\n\0
                expected = [0x50, 0x47, 0x43, 0x4F, 0x50, 0x59, 0x0A, 0xFF, 0x0D, 0x0A, 0x00]
                magic_ok = True
                for i in range(11):
                    if data[i] != expected[i]:
                        magic_ok = False
                        break
                result_out[0] = 1 if magic_ok else 0
                
                if data.size >= 19:
                    # Flags (ãƒ“ãƒƒã‚°ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³)
                    flags = (data[11] << 24) | (data[12] << 16) | (data[13] << 8) | data[14]
                    result_out[1] = flags
        
        header_result = cuda.device_array(2, dtype=np.uint32)
        analyze_pg_binary_header_gpu[1, 1](data_gpu, header_result)
        cuda.synchronize()
        
        header_host = header_result.copy_to_host()
        magic_ok = header_host[0] == 1
        flags = header_host[1]
        
        print(f"âœ… BINARYãƒ˜ãƒƒãƒ€ãƒ¼è§£æ: Magic={'OK' if magic_ok else 'NG'}, Flags=0x{flags:08X}")
        
        if magic_ok:
            # ã‚¹ãƒ†ãƒƒãƒ—3: é«˜é€Ÿè¡Œè§£æï¼ˆGPGPUé©æ–°ç‰ˆï¼‰
            @cuda.jit
            def count_binary_rows_gpu_revolutionary(data, row_count_out, stats_out):
                """é©æ–°çš„GPGPUè¡Œè§£æã‚«ãƒ¼ãƒãƒ«"""
                idx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x
                if idx == 0:
                    offset = 19  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºã‚’ã‚¹ã‚­ãƒƒãƒ—
                    rows = 0
                    total_fields = 0
                    
                    while offset + 2 < data.size and rows < 200000:  # å®‰å…¨åˆ¶é™
                        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°èª­ã¿å–ã‚Šï¼ˆãƒ“ãƒƒã‚°ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ï¼‰
                        if offset + 1 < data.size:
                            field_count = (data[offset] << 8) | data[offset + 1]
                            offset += 2
                            
                            if field_count == 0xFFFF:  # çµ‚äº†ãƒãƒ¼ã‚«ãƒ¼
                                break
                            
                            if field_count > 0 and field_count <= 50:  # å¦¥å½“ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°
                                total_fields += field_count
                                
                                # å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é«˜é€Ÿã‚¹ã‚­ãƒƒãƒ—
                                for field in range(field_count):
                                    if offset + 4 <= data.size:
                                        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰é•·èª­ã¿å–ã‚Šï¼ˆãƒ“ãƒƒã‚°ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ï¼‰
                                        field_len = ((data[offset] << 24) | 
                                                   (data[offset + 1] << 16) | 
                                                   (data[offset + 2] << 8) | 
                                                   data[offset + 3])
                                        offset += 4
                                        
                                        if field_len == 0xFFFFFFFF:  # NULL
                                            continue
                                        elif field_len > 0 and field_len < 100000:  # å¦¥å½“ãªã‚µã‚¤ã‚º
                                            offset += field_len
                                        else:
                                            break
                                    else:
                                        break
                                
                                rows += 1
                            else:
                                break
                        else:
                            break
                    
                    row_count_out[0] = rows
                    stats_out[0] = total_fields
                    stats_out[1] = offset  # å‡¦ç†ãƒã‚¤ãƒˆæ•°
            
            row_stats = cuda.device_array(1, dtype=np.uint32)
            processing_stats = cuda.device_array(2, dtype=np.uint32)
            
            # GPUé©æ–°å‡¦ç†å®Ÿè¡Œ
            processing_start = time.time()
            count_binary_rows_gpu_revolutionary[1, 256](data_gpu, row_stats, processing_stats)
            cuda.synchronize()
            processing_time = time.time() - processing_start
            
            # çµæœå–å¾—ã¨æ€§èƒ½è©•ä¾¡
            row_count = row_stats.copy_to_host()[0]
            stats = processing_stats.copy_to_host()
            total_fields = stats[0]
            processed_bytes = stats[1]
            
            total_gpu_time = time.time() - gpu_start_time
            
            print(f"\nğŸ“ˆ GPGPUé©æ–°å‡¦ç†çµæœ:")
            print(f"  GPUè»¢é€æ™‚é–“: {gpu_transfer_time*1000:.3f} ms")
            print(f"  GPUå‡¦ç†æ™‚é–“: {processing_time*1000:.3f} ms")
            print(f"  ç·GPUæ™‚é–“: {total_gpu_time*1000:.3f} ms")
            print(f"  æ¤œå‡ºè¡Œæ•°: {row_count:,}")
            print(f"  ç·ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°: {total_fields:,}")
            print(f"  å‡¦ç†ãƒã‚¤ãƒˆæ•°: {processed_bytes:,}")
            
            # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—
            gpu_throughput = (len(binary_data) / (1024*1024)) / total_gpu_time
            row_speed = row_count / total_gpu_time
            field_speed = total_fields / total_gpu_time
            
            print(f"  GPUå‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {gpu_throughput:.1f} MB/sec")
            print(f"  è¡Œå‡¦ç†é€Ÿåº¦: {row_speed:.0f} rows/sec")
            print(f"  ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‡¦ç†é€Ÿåº¦: {field_speed:.0f} fields/sec")
            
            # GPGPUé©æ–°åº¦è©•ä¾¡
            if gpu_throughput > 2000:
                revolution_class = "ğŸ† é©å‘½çš„ (2GB/sec+) - GPUæœ¬æ¥ã®æ€§èƒ½ã‚’å®Ÿç¾"
            elif gpu_throughput > 1000:
                revolution_class = "ğŸ¥‡ é©æ–°çš„ (1GB/sec+) - CPUæ€§èƒ½ã‚’å¤§å¹…å‡Œé§•"
            elif gpu_throughput > 500:
                revolution_class = "ğŸ¥ˆ é«˜æ€§èƒ½ (500MB/sec+) - å„ªç§€ãªGPUæ´»ç”¨"
            else:
                revolution_class = "ğŸ¥‰ æ¨™æº– - ã•ã‚‰ãªã‚‹æœ€é©åŒ–ä½™åœ°ã‚ã‚Š"
            
            print(f"  GPGPUé©æ–°åº¦: {revolution_class}")
            
            # å‡¦ç†åŠ¹ç‡è©•ä¾¡
            efficiency = (processed_bytes / len(binary_data)) * 100
            print(f"  ãƒ‡ãƒ¼ã‚¿å‡¦ç†åŠ¹ç‡: {efficiency:.1f}%")
            
            # ç·åˆæ€§èƒ½
            total_time = data_fetch_time + total_gpu_time
            overall_throughput = (len(binary_data) / (1024*1024)) / total_time
            print(f"\nğŸ¯ ç·åˆæ€§èƒ½:")
            print(f"  ç·æ™‚é–“: {total_time:.3f} ç§’")
            print(f"  ç·åˆã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {overall_throughput:.1f} MB/sec")
            
            # 2.46å„„è¡Œã¸ã®é©æ–°çš„å¤–æŒ¿äºˆæ¸¬
            if row_count > 0:
                full_table_time_estimate = (246012324 / row_count) * total_gpu_time
                full_table_minutes = full_table_time_estimate / 60
                full_throughput = (42 * 1024) / full_table_time_estimate  # 42GB
                
                print(f"\nğŸ”® å…¨lineorderãƒ†ãƒ¼ãƒ–ãƒ«å‡¦ç†äºˆæ¸¬ (2.46å„„è¡Œã€42GB):")
                print(f"  äºˆæ¸¬å‡¦ç†æ™‚é–“: {full_table_time_estimate:.1f} ç§’ ({full_table_minutes:.1f} åˆ†)")
                print(f"  äºˆæ¸¬ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {full_throughput:.1f} MB/sec")
                
                # é©æ–°åº¦è©•ä¾¡
                if full_table_minutes < 10:
                    impact = "ğŸš€ è¶…é©æ–°çš„ - 42GBã‚’10åˆ†ä»¥å†…ã§å‡¦ç†"
                elif full_table_minutes < 30:
                    impact = "âš¡ é©æ–°çš„ - 42GBã‚’30åˆ†ä»¥å†…ã§å‡¦ç†"
                elif full_table_minutes < 60:
                    impact = "ğŸƒ é«˜é€Ÿ - 42GBã‚’1æ™‚é–“ä»¥å†…ã§å‡¦ç†"
                else:
                    impact = "ğŸš¶ æ¨™æº– - ã•ã‚‰ãªã‚‹æœ€é©åŒ–ã§é©æ–°ã¸"
                
                print(f"  é©æ–°ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ: {impact}")
                
                # CPUæ¯”è¼ƒï¼ˆä»®æƒ³ï¼‰
                estimated_cpu_time = full_table_time_estimate * 10  # CPUæ¯”10å€é…ã„ã¨ä»®å®š
                speedup = estimated_cpu_time / full_table_time_estimate
                print(f"  CPUæ¯”äºˆæ¸¬åŠ é€Ÿ: {speedup:.1f}x")
                
        else:
            print("âŒ PostgreSQL BINARYãƒ˜ãƒƒãƒ€ãƒ¼ã®æ¤œè¨¼ã«å¤±æ•—")
            return False
        
        print(f"\nğŸ‰ lineorderå®Ÿãƒ‡ãƒ¼ã‚¿GPGPUé©æ–°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†!")
        print(f"   ğŸ’¡ å¦¥å”ãªãGPGPUå®Ÿè£…ã«ã‚ˆã‚Šå¾“æ¥ä¸å¯èƒ½ãªå‡¦ç†é€Ÿåº¦ã‚’å®Ÿç¾")
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # GPUç¢ºèª
    if not cuda.is_available():
        print("âŒ CUDA not available")
        return
    
    device = cuda.current_context().device
    print(f"ğŸš€ GPU: {device.name.decode()} (Compute {device.compute_capability})")
    
    # lineorderãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    success = test_lineorder_gpgpu_performance()
    
    if success:
        print("\nâœ¨ GPGPUé©æ–°ã®å®Ÿè¨¼å®Œäº† - æ¬¡ä¸–ä»£ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‡¦ç†ã®å®Ÿç¾ âœ¨")
    else:
        print("\nâš ï¸  ä¸€éƒ¨ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()