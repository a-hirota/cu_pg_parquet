#!/usr/bin/env python3
"""
GPU vs CPUã‚½ãƒ¼ãƒˆã®æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
================================

çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ã§ã®GPUã‚½ãƒ¼ãƒˆæœ€é©åŒ–åŠ¹æœã‚’æ¸¬å®šã—ã¾ã™ã€‚
"""

import pytest
import numpy as np
import time
from numba import cuda
import cupy as cp

def test_gpu_sort_vs_cpu_sort():
    """GPUã‚½ãƒ¼ãƒˆ vs CPUã‚½ãƒ¼ãƒˆã®æ€§èƒ½æ¯”è¼ƒ"""
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºï¼ˆé©å¿œçš„ã‚½ãƒ¼ãƒˆé–¾å€¤ã‚’è€ƒæ…®ï¼‰
    test_sizes = [10000, 100000, 1000000]  # å°è¦æ¨¡ã€å¤§è¦æ¨¡ã€è¶…å¤§è¦æ¨¡
    
    for data_size in test_sizes:
        print(f"\n=== ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {data_size:,}è¡Œ ===")
        
        # ãƒ©ãƒ³ãƒ€ãƒ ãªè¡Œä½ç½®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆPostgreSQLãƒã‚¤ãƒŠãƒªä½ç½®ã‚’æ¨¡æ“¬ï¼‰
        np.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚
        row_positions_host = np.random.randint(0, data_size * 100, size=data_size, dtype=np.int32)
        row_positions_gpu = cuda.to_device(row_positions_host)
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚‚ç”Ÿæˆï¼ˆçµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ã®å®Ÿéš›ã®ä½¿ç”¨ã‚±ãƒ¼ã‚¹ï¼‰
        field_offsets_host = np.random.randint(0, 1000000, size=(data_size, 17), dtype=np.int32)
        field_lengths_host = np.random.randint(1, 100, size=(data_size, 17), dtype=np.int32)
        field_offsets_gpu = cuda.to_device(field_offsets_host)
        field_lengths_gpu = cuda.to_device(field_lengths_host)
        
        # === CPUå¾“æ¥æ–¹å¼ã®æ¸¬å®š ===
        start_time = time.perf_counter()
        
        # GPUâ†’CPUè»¢é€
        row_pos_host = row_positions_gpu.copy_to_host()
        field_off_host = field_offsets_gpu.copy_to_host()
        field_len_host = field_lengths_gpu.copy_to_host()
        
        # CPUã‚½ãƒ¼ãƒˆ
        sort_indices_cpu = np.argsort(row_pos_host)
        field_offsets_sorted_cpu = field_off_host[sort_indices_cpu]
        field_lengths_sorted_cpu = field_len_host[sort_indices_cpu]
        
        # CPUâ†’GPUè»¢é€
        result_offsets_cpu = cuda.to_device(field_offsets_sorted_cpu)
        result_lengths_cpu = cuda.to_device(field_lengths_sorted_cpu)
        
        cpu_time = time.perf_counter() - start_time
        
        # === GPUæ–°æ–¹å¼ã®æ¸¬å®š ===
        start_time = time.perf_counter()
        
        # GPUä¸Šã§ç›´æ¥å‡¦ç†
        row_positions_cupy = cp.asarray(row_positions_gpu)
        field_offsets_cupy = cp.asarray(field_offsets_gpu)
        field_lengths_cupy = cp.asarray(field_lengths_gpu)
        
        # GPUã‚½ãƒ¼ãƒˆ
        sort_indices_gpu = cp.argsort(row_positions_cupy)
        field_offsets_sorted_gpu = field_offsets_cupy[sort_indices_gpu]
        field_lengths_sorted_gpu = field_lengths_cupy[sort_indices_gpu]
        
        # CuPyâ†’Numbaå¤‰æ›
        result_offsets_gpu = cuda.as_cuda_array(field_offsets_sorted_gpu)
        result_lengths_gpu = cuda.as_cuda_array(field_lengths_sorted_gpu)
        
        gpu_time = time.perf_counter() - start_time
        
        # === çµæœæ¤œè¨¼ ===
        # ã‚½ãƒ¼ãƒˆçµæœãŒåŒã˜ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        cpu_result = result_offsets_cpu.copy_to_host()
        gpu_result = result_offsets_gpu.copy_to_host()
        
        # ã‚½ãƒ¼ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒåŒã˜ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆã‚ˆã‚Šç¢ºå®Ÿãªæ¤œè¨¼ï¼‰
        sort_indices_cpu_host = sort_indices_cpu
        sort_indices_gpu_host = sort_indices_gpu.get()
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±å‡ºåŠ›
        if not np.array_equal(sort_indices_cpu_host, sort_indices_gpu_host):
            print(f"[DEBUG] CPU sort indices: {sort_indices_cpu_host[:10]}")
            print(f"[DEBUG] GPU sort indices: {sort_indices_gpu_host[:10]}")
            print(f"[DEBUG] å…ƒãƒ‡ãƒ¼ã‚¿: {row_pos_host[:10]}")
            
            # é‡è¤‡å€¤ã®å‡¦ç†æ–¹æ³•ã«é•ã„ãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã€ã‚½ãƒ¼ãƒˆå¾Œã®å®Ÿéš›ã®å€¤ã‚’æ¯”è¼ƒ
            sorted_positions_cpu = row_pos_host[sort_indices_cpu_host]
            sorted_positions_gpu = row_positions_cupy[sort_indices_gpu].get()
            
            if np.array_equal(sorted_positions_cpu, sorted_positions_gpu):
                print("[DEBUG] ã‚½ãƒ¼ãƒˆå¾Œã®ä½ç½®ã¯ä¸€è‡´ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †åºã®é•ã„ã¯è¨±å®¹ï¼‰")
            else:
                assert False, "ã‚½ãƒ¼ãƒˆå¾Œã®ä½ç½®ãŒä¸ä¸€è‡´"
        else:
            assert np.array_equal(cpu_result, gpu_result), "CPU/GPUã‚½ãƒ¼ãƒˆçµæœãŒä¸ä¸€è‡´"
        
        # === æ€§èƒ½çµæœè¡¨ç¤º ===
        speedup = cpu_time / gpu_time
        print(f"CPUæ–¹å¼: {cpu_time*1000:.2f}ms")
        print(f"GPUæ–¹å¼: {gpu_time*1000:.2f}ms")
        print(f"é«˜é€ŸåŒ–ç‡: {speedup:.2f}x")
        print(f"å‰Šæ¸›æ™‚é–“: {(cpu_time - gpu_time)*1000:.2f}ms")
        
        # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã®ã¿GPUæ–¹å¼ãŒé«˜é€Ÿã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        if data_size >= 100000:  # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒã‚§ãƒƒã‚¯
            assert gpu_time < cpu_time, f"å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§GPUæ–¹å¼ãŒé…ã„: {gpu_time:.4f}s vs {cpu_time:.4f}s"
            assert speedup >= 1.5, f"æœŸå¾…ã•ã‚Œã‚‹é«˜é€ŸåŒ–ç‡ã«é”ã—ã¦ã„ã¾ã›ã‚“: {speedup:.2f}x < 1.5x"
        else:
            # å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã¯CPUæ–¹å¼ãŒé«˜é€Ÿï¼ˆæœŸå¾…é€šã‚Šï¼‰
            print(f"å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ{data_size}è¡Œï¼‰ã§ã¯CPUæ–¹å¼ãŒé«˜é€Ÿ: {speedup:.2f}xï¼ˆæœŸå¾…é€šã‚Šï¼‰")

def test_gpu_sort_integration_with_parser():
    """çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ã§ã®GPUã‚½ãƒ¼ãƒˆå‹•ä½œãƒ†ã‚¹ãƒˆ"""
    
    try:
        from src.cuda_kernels.integrated_parser_lite import parse_binary_chunk_gpu_ultra_fast_v2_lite
        from src.types import ColumnMeta, INT32, UTF8
    except ImportError:
        pytest.skip("çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    columns = [
        ColumnMeta(name="id", pg_oid=23, pg_typmod=0, arrow_id=INT32, elem_size=4),
        ColumnMeta(name="name", pg_oid=25, pg_typmod=-1, arrow_id=UTF8, elem_size=-1)
    ]
    
    # PostgreSQLå½¢å¼ã®ãƒ†ã‚¹ãƒˆãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    test_data = bytearray()
    test_data.extend(b'\x00' * 19)  # ãƒ˜ãƒƒãƒ€
    
    # 3è¡Œã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    for i in range(3):
        test_data.extend((2).to_bytes(2, 'big'))  # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°
        test_data.extend((4).to_bytes(4, 'big'))  # IDé•·
        test_data.extend((i + 1).to_bytes(4, 'big'))  # IDå€¤
        test_data.extend((5).to_bytes(4, 'big'))  # åå‰é•·
        test_data.extend(f"user{i}".encode('utf-8'))  # åå‰
    
    raw_dev = cuda.to_device(np.frombuffer(test_data, dtype=np.uint8))
    
    # çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼å®Ÿè¡Œï¼ˆGPUã‚½ãƒ¼ãƒˆä½¿ç”¨ï¼‰
    field_offsets, field_lengths = parse_binary_chunk_gpu_ultra_fast_v2_lite(
        raw_dev, columns, debug=True
    )
    
    # çµæœç¢ºèª
    assert field_offsets.shape[0] > 0, "è¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
    assert field_offsets.shape[1] == len(columns), "åˆ—æ•°ãŒä¸æ­£ã§ã™"
    
    print(f"GPUã‚½ãƒ¼ãƒˆçµ±åˆãƒ†ã‚¹ãƒˆæˆåŠŸ: {field_offsets.shape[0]}è¡Œæ¤œå‡º")

if __name__ == "__main__":
    print("GPU vs CPUã‚½ãƒ¼ãƒˆæ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    test_gpu_sort_vs_cpu_sort()
    print("\nâœ“ æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Œäº†")
    
    test_gpu_sort_integration_with_parser()
    print("âœ“ çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    print("\nğŸš€ GPUã‚½ãƒ¼ãƒˆæœ€é©åŒ–ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")