#!/usr/bin/env python3
"""
å¤§è¦æ¨¡Parquetãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨è¡¨ç¤ºã‚µãƒ³ãƒ—ãƒ«
cuDFã‚’ä½¿ç”¨ã—ãŸGPUé«˜é€Ÿå‡¦ç†ç‰ˆ
"""

import cudf
import dask_cudf
import time
import sys
from pathlib import Path
import gc

def check_gpu_environment():
    """GPUç’°å¢ƒã®ç¢ºèª"""
    try:
        import pynvml
        pynvml.nvmlInit()
        device_count = pynvml.nvmlDeviceGetCount()
        print(f"âœ“ GPUæ•°: {device_count}")
        
        for i in range(device_count):
            handle = pynvml.nvmlDeviceGetHandleByIndex(i)
            name = pynvml.nvmlDeviceGetName(handle).decode('utf-8')
            mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
            print(f"  GPU {i}: {name}")
            print(f"    ãƒ¡ãƒ¢ãƒª: {mem_info.total / 1024**3:.1f} GB (ä½¿ç”¨ä¸­: {mem_info.used / 1024**3:.1f} GB)")
    except Exception as e:
        print(f"âš  GPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        print("  cuDFã¯å‹•ä½œã—ã¾ã™ãŒã€ãƒ¡ãƒ¢ãƒªæƒ…å ±ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“")

def read_parquet_files(file_paths, use_dask=False):
    """
    Parquetãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    
    Args:
        file_paths: èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        use_dask: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ç”¨ã«Dask-cuDFã‚’ä½¿ç”¨ã™ã‚‹ã‹
    
    Returns:
        èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒªã‚¹ãƒˆ
    """
    dfs = []
    
    for file_path in file_paths:
        if not Path(file_path).exists():
            print(f"âš  ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            continue
            
        print(f"\nğŸ“ èª­ã¿è¾¼ã¿ä¸­: {file_path}")
        start_time = time.time()
        
        try:
            if use_dask:
                # Dask-cuDFã‚’ä½¿ç”¨ï¼ˆè¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰
                df = dask_cudf.read_parquet(file_path)
                # å¿…è¦ã«å¿œã˜ã¦è¨ˆç®—ã‚’å®Ÿè¡Œ
                df = df.persist()
            else:
                # é€šå¸¸ã®cuDFèª­ã¿è¾¼ã¿
                df = cudf.read_parquet(file_path)
            
            elapsed = time.time() - start_time
            print(f"  âœ“ èª­ã¿è¾¼ã¿å®Œäº† ({elapsed:.2f}ç§’)")
            
            # åŸºæœ¬æƒ…å ±ã®è¡¨ç¤º
            if use_dask:
                print(f"  ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³æ•°: {df.npartitions}")
                # Daskã®å ´åˆã¯.compute()ã§å®Ÿéš›ã®å€¤ã‚’å–å¾—
                shape = (len(df), len(df.columns))
            else:
                shape = df.shape
            
            print(f"  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {shape[0]:,} è¡Œ Ã— {shape[1]} åˆ—")
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ¨å®š
            if not use_dask:
                memory_usage = df.memory_usage(deep=True).sum() / 1024**3
                print(f"  GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_usage:.2f} GB")
            
            dfs.append(df)
            
        except Exception as e:
            print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    return dfs

def display_sample_data(df, n_rows=10, name=""):
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿{' - ' + name if name else ''}")
    print(f"{'='*60}")
    
    # ãƒ‡ãƒ¼ã‚¿å‹æƒ…å ±
    print("\nã€ã‚«ãƒ©ãƒ æƒ…å ±ã€‘")
    for col, dtype in df.dtypes.items():
        print(f"  {col}: {dtype}")
    
    # å…ˆé ­nè¡Œã®è¡¨ç¤º
    print(f"\nã€å…ˆé ­{n_rows}è¡Œã€‘")
    if isinstance(df, dask_cudf.DataFrame):
        # Daskã®å ´åˆ
        print(df.head(n_rows))
    else:
        # é€šå¸¸ã®cuDFã®å ´åˆ
        print(df.head(n_rows))
    
    # åŸºæœ¬çµ±è¨ˆé‡ï¼ˆæ•°å€¤åˆ—ã®ã¿ï¼‰
    print("\nã€åŸºæœ¬çµ±è¨ˆé‡ã€‘")
    try:
        numeric_cols = df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            if isinstance(df, dask_cudf.DataFrame):
                stats = df[numeric_cols].describe().compute()
            else:
                stats = df[numeric_cols].describe()
            print(stats)
        else:
            print("  æ•°å€¤åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
    except Exception as e:
        print(f"  çµ±è¨ˆé‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")

def process_large_parquet_files():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼"""
    print("ğŸš€ cuDF Parquetãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹")
    print("="*60)
    
    # 1. GPUç’°å¢ƒç¢ºèª
    print("\nã€GPUç’°å¢ƒç¢ºèªã€‘")
    check_gpu_environment()
    
    # 2. ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
    file_paths = [
        "output/customer_chunk_0_queue.parquet",
        "output/customer_chunk_1_queue.parquet"
    ]
    
    # 3. ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ç¢ºèªï¼ˆå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿åˆ¤å®šï¼‰
    total_size = 0
    for file_path in file_paths:
        if Path(file_path).exists():
            size = Path(file_path).stat().st_size / 1024**3
            print(f"\nğŸ“ {file_path}: {size:.2f} GB")
            total_size += size
    
    # 4. èª­ã¿è¾¼ã¿æ–¹æ³•ã®é¸æŠï¼ˆ10GBä»¥ä¸Šãªã‚‰Daskä½¿ç”¨ã‚’æ¨å¥¨ï¼‰
    use_dask = total_size > 10
    if use_dask:
        print(f"\nâš¡ å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿æ¤œå‡º (åˆè¨ˆ {total_size:.2f} GB)")
        print("  â†’ Dask-cuDFã‚’ä½¿ç”¨ã—ã¦åˆ†æ•£å‡¦ç†ã—ã¾ã™")
    
    # 5. ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    print("\nã€ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã€‘")
    dfs = read_parquet_files(file_paths, use_dask=use_dask)
    
    if not dfs:
        print("\nâœ— èª­ã¿è¾¼ã¿å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # 6. å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    for i, (df, file_path) in enumerate(zip(dfs, file_paths)):
        display_sample_data(df, n_rows=5, name=f"ãƒ•ã‚¡ã‚¤ãƒ«{i} ({Path(file_path).name})")
    
    # 7. ä¸¦åˆ—å‡¦ç†ã§ã®çµåˆä¾‹ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    if len(dfs) == 2:
        print("\nã€ãƒ‡ãƒ¼ã‚¿çµåˆä¾‹ã€‘")
        try:
            # å…±é€šã‚«ãƒ©ãƒ ã®ç¢ºèª
            common_cols = set(dfs[0].columns) & set(dfs[1].columns)
            print(f"å…±é€šã‚«ãƒ©ãƒ : {common_cols}")
            
            # å‚ç›´çµåˆï¼ˆè¡Œæ–¹å‘ï¼‰ã®ä¾‹
            if use_dask:
                combined_df = dask_cudf.concat(dfs, axis=0)
                print(f"\nçµåˆå¾Œã®ã‚µã‚¤ã‚º: ç´„{len(dfs[0]) + len(dfs[1]):,} è¡Œ")
            else:
                combined_df = cudf.concat(dfs, axis=0)
                print(f"\nçµåˆå¾Œã®ã‚µã‚¤ã‚º: {combined_df.shape[0]:,} è¡Œ Ã— {combined_df.shape[1]} åˆ—")
                
        except Exception as e:
            print(f"çµåˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # 8. ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    print("\nã€ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã€‘")
    del dfs
    gc.collect()
    cudf._lib.nvtx.nvtx_range_pop()  # GPUãƒ¡ãƒ¢ãƒªè§£æ”¾
    print("âœ“ å‡¦ç†å®Œäº†")

def advanced_operations_example():
    """é«˜åº¦ãªæ“ä½œã®ä¾‹"""
    print("\n" + "="*60)
    print("ğŸ“ˆ é«˜åº¦ãªæ“ä½œä¾‹ï¼ˆå‚è€ƒï¼‰")
    print("="*60)
    
    example_code = """
# 1. æ¡ä»¶ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆGPUé«˜é€Ÿå‡¦ç†ï¼‰
filtered_df = df[df['column_name'] > threshold]

# 2. ã‚°ãƒ«ãƒ¼ãƒ—é›†è¨ˆ
grouped = df.groupby('category').agg({
    'value': ['sum', 'mean', 'count'],
    'amount': 'sum'
})

# 3. ä¸¦åˆ—ã‚½ãƒ¼ãƒˆ
sorted_df = df.sort_values(['col1', 'col2'], ascending=[True, False])

# 4. ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°ã®é©ç”¨ï¼ˆGPUæœ€é©åŒ–ï¼‰
df['new_col'] = df.apply_rows(custom_gpu_function, 
                              incols=['col1', 'col2'],
                              outcols={'new_col': 'float32'})

# 5. å¤§è¦æ¨¡JOINï¼ˆãƒãƒƒã‚·ãƒ¥JOIN on GPUï¼‰
merged = df1.merge(df2, on='key', how='inner')

# 6. CPU/GPUé–“ã®ãƒ‡ãƒ¼ã‚¿è»¢é€
pandas_df = cudf_df.to_pandas()  # GPU â†’ CPU
cudf_df = cudf.from_pandas(pandas_df)  # CPU â†’ GPU
"""
    print(example_code)

if __name__ == "__main__":
    try:
        # ãƒ¡ã‚¤ãƒ³å‡¦ç†å®Ÿè¡Œ
        process_large_parquet_files()
        
        # é«˜åº¦ãªæ“ä½œä¾‹ã®è¡¨ç¤º
        advanced_operations_example()
        
    except ImportError as e:
        print(f"\nâœ— ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("\nã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•ã€‘")
        print("conda install -c rapidsai -c conda-forge -c nvidia cudf")
        print("ã¾ãŸã¯")
        print("pip install cudf-cu11  # CUDA 11.xå‘ã‘")
        print("pip install cudf-cu12  # CUDA 12.xå‘ã‘")
        
    except Exception as e:
        print(f"\nâœ— ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
