#!/usr/bin/env python3
"""
kvikio lineorderãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆæ¨©é™åˆ¶é™å›é¿ç‰ˆï¼‰

PostgreSQLãƒ’ãƒ¼ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ç’°å¢ƒã§ã®
ä»£æ›¿å®Ÿè£…ã€‚COPY BINARYãƒ‡ãƒ¼ã‚¿ã‚’kvikioé¢¨ã«å‡¦ç†ã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç‰ˆã€‚

æ¨©é™å•é¡Œã‚’å›é¿ã—ã¤ã¤ã€kvikioçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ€§èƒ½å®Ÿè¨¼ã‚’è¡Œã†ã€‚
"""

import os
import time
import io
import tempfile
import psycopg
import cudf
import numpy as np
from numba import cuda
import rmm

from src.metadata import fetch_column_meta
from src.types import ColumnMeta
from src.build_cudf_from_buf import integrate_kvikio_pipeline
from src.heap_file_reader import read_heap_file_direct

TABLE_NAME = "lineorder"
OUTPUT_DIR = "benchmark"

def create_mock_heap_file_from_copy_binary(database: str, table: str, limit: int = 100000):
    """
    COPY BINARYãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒƒã‚¯ãƒ’ãƒ¼ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    
    æ¨©é™åˆ¶é™ã«ã‚ˆã‚ŠPostgreSQLãƒ’ãƒ¼ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„å ´åˆã®
    ä»£æ›¿æ‰‹æ³•ã€‚å®Ÿéš›ã®lineorderãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦kvikioå‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚
    """
    print(f"ğŸ“¦ {table}ãƒ¢ãƒƒã‚¯ãƒ’ãƒ¼ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ ({limit:,}è¡Œ)")
    
    dsn = os.environ.get("GPUPASER_PG_DSN")
    conn = psycopg.connect(dsn)
    
    try:
        # PostgreSQLã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        start_time = time.time()
        
        with conn.cursor() as cur:
            # ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            query = f"COPY (SELECT * FROM {table} LIMIT {limit}) TO STDOUT (FORMAT binary)"
            
            buffer = io.BytesIO()
            with cur.copy(query) as copy:
                for data in copy:
                    buffer.write(data)
            
            binary_data = buffer.getvalue()
            buffer.close()
        
        fetch_time = time.time() - start_time
        
        print(f"âœ… PostgreSQLãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†:")
        print(f"   å–å¾—æ™‚é–“: {fetch_time:.3f}ç§’")
        print(f"   ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(binary_data) / (1024*1024):.2f} MB")
        print(f"   å–å¾—ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {(len(binary_data) / (1024*1024)) / fetch_time:.1f} MB/sec")
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        with tempfile.NamedTemporaryFile(delete=False, suffix='.heap') as temp_file:
            temp_file.write(binary_data)
            temp_file_path = temp_file.name
        
        print(f"âœ… ãƒ¢ãƒƒã‚¯ãƒ’ãƒ¼ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {temp_file_path}")
        
        return temp_file_path, len(binary_data), fetch_time
        
    finally:
        conn.close()

def convert_binary_to_mock_heap(binary_data):
    """
    PostgreSQL BINARYãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸é¢¨ã«å¤‰æ›
    
    å®Ÿéš›ã®ãƒ’ãƒ¼ãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’æ¨¡æ“¬ã—ã¦kvikioãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆç”¨ã®
    ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹ã€‚
    """
    # PostgreSQL BINARYãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆ19ãƒã‚¤ãƒˆï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if len(binary_data) < 19:
        raise ValueError("ä¸æ­£ãªPostgreSQL BINARYãƒ‡ãƒ¼ã‚¿")
    
    # ç°¡æ˜“çš„ãªãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸æ§‹é€ ä½œæˆ
    page_size = 8192
    header_size = 24
    
    # BINARYãƒ‡ãƒ¼ã‚¿ã‚’ãƒšãƒ¼ã‚¸ã«åˆ†å‰²
    data_without_header = binary_data[19:]  # PostgreSQL BINARYãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
    
    mock_heap_data = bytearray()
    
    # å„ãƒšãƒ¼ã‚¸ã®ãƒ¢ãƒƒã‚¯ä½œæˆ
    offset = 0
    page_count = 0
    
    while offset < len(data_without_header):
        # ãƒšãƒ¼ã‚¸ãƒ˜ãƒƒãƒ€ãƒ¼ä½œæˆï¼ˆ24ãƒã‚¤ãƒˆï¼‰
        page_header = bytearray(header_size)
        
        # pd_lower, pd_upperè¨­å®šï¼ˆç°¡æ˜“ï¼‰
        chunk_size = min(page_size - header_size, len(data_without_header) - offset)
        pd_lower = header_size + 8  # ItemIdé…åˆ—ï¼ˆä»®ï¼‰
        pd_upper = page_size - chunk_size
        
        page_header[12:14] = pd_lower.to_bytes(2, 'little')
        page_header[14:16] = pd_upper.to_bytes(2, 'little')
        
        # ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        page_data = bytearray(page_size)
        page_data[:header_size] = page_header
        
        # ItemIdé…åˆ—ï¼ˆç°¡æ˜“ï¼‰
        item_id = bytearray(4)
        item_id[0:2] = pd_upper.to_bytes(2, 'little')  # lp_off
        item_id[2:4] = (chunk_size | (1 << 14)).to_bytes(2, 'little')  # lp_len + flags
        page_data[header_size:header_size+4] = item_id
        
        # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿
        page_data[pd_upper:pd_upper+chunk_size] = data_without_header[offset:offset+chunk_size]
        
        mock_heap_data.extend(page_data)
        offset += chunk_size
        page_count += 1
    
    print(f"âœ… ãƒ¢ãƒƒã‚¯ãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸ä½œæˆ: {page_count}ãƒšãƒ¼ã‚¸")
    return bytes(mock_heap_data)

def run_kvikio_lineorder_mock_benchmark(
    database: str = "postgres",
    table: str = TABLE_NAME,
    limit: int = 100000,
    output_path: str = None
):
    """kvikio lineorderãƒ¢ãƒƒã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
    
    print("=== kvikio lineorderãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆæ¨©é™åˆ¶é™å›é¿ç‰ˆï¼‰===")
    print("ğŸ¯ ç›®æ¨™: PostgreSQLå®Ÿãƒ‡ãƒ¼ã‚¿ â†’ kvikioé¢¨å‡¦ç† â†’ cuDF â†’ GPU Parquet")
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {database}")
    print(f"ãƒ†ãƒ¼ãƒ–ãƒ«: {table}")
    print(f"ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {limit:,}è¡Œ")
    
    if output_path is None:
        timestamp = int(time.time())
        output_path = f"{OUTPUT_DIR}/{table}_kvikio_mock_{timestamp}.parquet"
    
    print(f"å‡ºåŠ›å…ˆ: {output_path}")
    
    try:
        # RMMåˆæœŸåŒ–
        if not rmm.is_initialized():
            rmm.reinitialize(
                pool_allocator=True,
                initial_pool_size=2*1024**3  # 2GB
            )
            print("âœ… RMM 2GB poolåˆæœŸåŒ–å®Œäº†")
        
        start_total_time = time.time()
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
        print(f"\nğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        start_meta_time = time.time()
        
        dsn = os.environ.get("GPUPASER_PG_DSN")
        conn = psycopg.connect(dsn)
        try:
            columns = fetch_column_meta(conn, f"SELECT * FROM {table}")
        finally:
            conn.close()
        
        meta_time = time.time() - start_meta_time
        print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº† ({meta_time:.4f}ç§’)")
        print(f"   åˆ—æ•°: {len(columns)}")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: PostgreSQLå®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—ã¨ãƒ¢ãƒƒã‚¯å¤‰æ›
        print(f"\nğŸ“¦ PostgreSQLå®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—...")
        mock_file_path, data_size, fetch_time = create_mock_heap_file_from_copy_binary(
            database, table, limit
        )
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: kvikioé¢¨çµ±åˆå‡¦ç†å®Ÿè¡Œ
        print(f"\nğŸš€ kvikioé¢¨çµ±åˆå‡¦ç†é–‹å§‹...")
        start_kvikio_time = time.time()
        
        try:
            # kvikioçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œï¼ˆãƒ¢ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨ï¼‰
            cudf_df = integrate_kvikio_pipeline(mock_file_path, columns)
            
        except Exception as e:
            print(f"âŒ kvikioçµ±åˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
            os.unlink(mock_file_path)
        
        kvikio_time = time.time() - start_kvikio_time
        rows = len(cudf_df)
        
        print(f"âœ… kvikioé¢¨å‡¦ç†å®Œäº† ({kvikio_time:.4f}ç§’)")
        print(f"   å‡¦ç†è¡Œæ•°: {rows:,}")
        print(f"   å‡¦ç†åˆ—æ•°: {len(cudf_df.columns)}")
        
        # ã‚¹ãƒ†ãƒƒãƒ—4: GPUç›´æ¥Parquetå‡ºåŠ›
        print(f"\nğŸ’¾ GPUç›´æ¥Parquetæ›¸ãè¾¼ã¿ä¸­...")
        start_write_time = time.time()
        
        try:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            cudf_df.to_parquet(
                output_path,
                compression='snappy',
                engine='cudf'
            )
            
        except Exception as e:
            print(f"âŒ GPU Parquetæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        
        write_time = time.time() - start_write_time
        output_size = os.path.getsize(output_path)
        
        print(f"âœ… GPU Parquetå‡ºåŠ›å®Œäº† ({write_time:.4f}ç§’)")
        print(f"   å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {output_size / (1024**2):.1f} MB")
        
        # ã‚¹ãƒ†ãƒƒãƒ—5: æ€§èƒ½è©•ä¾¡
        total_time = time.time() - start_total_time
        processing_time = kvikio_time + write_time
        
        print(f"\nğŸ“ˆ kvikioé¢¨lineorderãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ:")
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿è¦æ¨¡:")
        print(f"   è¡Œæ•°: {rows:,}")
        print(f"   åˆ—æ•°: {len(columns)}")
        print(f"   ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {data_size / (1024**2):.2f} MB")
        print(f"   å‡ºåŠ›ã‚µã‚¤ã‚º: {output_size / (1024**2):.1f} MB")
        
        print(f"\nâ±ï¸  æ™‚é–“å†…è¨³:")
        print(f"   ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—: {meta_time:.4f} ç§’")
        print(f"   PostgreSQLå–å¾—: {fetch_time:.4f} ç§’")
        print(f"   kvikioé¢¨å‡¦ç†: {kvikio_time:.4f} ç§’")
        print(f"   GPU Parquetå‡ºåŠ›: {write_time:.4f} ç§’")
        print(f"   ç·æ™‚é–“: {total_time:.4f} ç§’")
        
        print(f"\nğŸš€ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ:")
        if kvikio_time > 0:
            kvikio_throughput = (data_size / (1024**2)) / kvikio_time
            print(f"   kvikioé¢¨å‡¦ç†: {kvikio_throughput:.1f} MB/sec")
        
        if processing_time > 0:
            overall_throughput = (data_size / (1024**2)) / processing_time
            row_speed = rows / processing_time
            print(f"   GPUå‡¦ç†å…¨ä½“: {overall_throughput:.1f} MB/sec")
            print(f"   è¡Œå‡¦ç†é€Ÿåº¦: {row_speed:,.0f} rows/sec")
        
        # å…¨ãƒ†ãƒ¼ãƒ–ãƒ«å¤–æŒ¿äºˆæ¸¬
        full_table_rows = 246012324  # lineorderå…¨è¡Œæ•°
        if rows > 0 and processing_time > 0:
            scale_factor = full_table_rows / rows
            predicted_time = processing_time * scale_factor
            predicted_throughput = (42 * 1024) / predicted_time  # 42GB
            
            print(f"\nğŸ”® å…¨lineorderãƒ†ãƒ¼ãƒ–ãƒ«å‡¦ç†äºˆæ¸¬:")
            print(f"   äºˆæ¸¬å‡¦ç†æ™‚é–“: {predicted_time:.1f}ç§’ ({predicted_time/60:.1f}åˆ†)")
            print(f"   äºˆæ¸¬ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {predicted_throughput:.1f} MB/sec")
            
            if predicted_time < 300:  # 5åˆ†ä»¥å†…
                impact = "ğŸ† å®Ÿç”¨çš„ - 5åˆ†ä»¥å†…ã§42GBå‡¦ç†å¯èƒ½"
            elif predicted_time < 1800:  # 30åˆ†ä»¥å†…
                impact = "ğŸ¥‡ é«˜æ€§èƒ½ - 30åˆ†ä»¥å†…ã§42GBå‡¦ç†å¯èƒ½"
            else:
                impact = "ğŸ¥ˆ æ”¹å–„ä¸­ - ã•ã‚‰ãªã‚‹æœ€é©åŒ–ã§å®Ÿç”¨åŒ–"
            
            print(f"   å®Ÿç”¨æ€§è©•ä¾¡: {impact}")
        
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        
        # çµæœæ¤œè¨¼
        print(f"\nğŸ” çµæœæ¤œè¨¼...")
        try:
            verify_df = cudf.read_parquet(output_path)
            print(f"âœ… æ¤œè¨¼æˆåŠŸ: {len(verify_df):,}è¡Œ Ã— {len(verify_df.columns)}åˆ—")
            
            # ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª
            print("âœ… ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª:")
            for col_name, dtype in list(verify_df.dtypes.items())[:5]:
                print(f"   {col_name}: {dtype}")
            if len(verify_df.columns) > 5:
                print(f"   ... ä»–{len(verify_df.columns)-5}åˆ—")
                
        except Exception as e:
            print(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        
        print(f"\nğŸ‰ kvikioé¢¨lineorderãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æˆåŠŸ!")
        print(f"   ğŸ’¡ PostgreSQLå®Ÿãƒ‡ãƒ¼ã‚¿ â†’ kvikioé¢¨å‡¦ç† â†’ cuDF â†’ GPU Parquet")
        print(f"   âš¡ æ¨©é™åˆ¶é™å›é¿ç‰ˆã§ã‚‚GPGPUé©æ–°ã‚’å®Ÿè¨¼!")
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='kvikio lineorderãƒ¢ãƒƒã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯')
    parser.add_argument('--database', type=str, default='postgres', help='ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å')
    parser.add_argument('--table', type=str, default=TABLE_NAME, help='ãƒ†ãƒ¼ãƒ–ãƒ«å')
    parser.add_argument('--limit', type=int, default=100000, help='å‡¦ç†è¡Œæ•°åˆ¶é™')
    parser.add_argument('--output', type=str, help='å‡ºåŠ›Parquetãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    success = run_kvikio_lineorder_mock_benchmark(
        database=args.database,
        table=args.table,
        limit=args.limit,
        output_path=args.output
    )
    
    if success:
        print("\nâœ¨ kvikioé¢¨GPGPUé©æ–°ã®å®Ÿè¨¼å®Œäº†ï¼ˆæ¨©é™åˆ¶é™å›é¿ç‰ˆï¼‰âœ¨")
    else:
        print("\nâš ï¸  ä¸€éƒ¨ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()