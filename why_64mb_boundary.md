# なぜ8KB単位なのに64MB境界で行がまたがるのか

## PostgreSQLの8KBページとCOPY BINARYの関係

### 1. PostgreSQLの8KBページ管理
- PostgreSQLは**論理的に**8KBページでデータを管理
- 各ページ内に複数の行（タプル）を格納
- ctid = (ページ番号, 行番号)で行を識別

### 2. COPY BINARYの出力形式
```
[COPYヘッダー 19バイト]
[行1: フィールド数(2) + 各フィールド長(4) + データ]
[行2: フィールド数(2) + 各フィールド長(4) + データ]
...
[終端マーカー 2バイト]
```

**重要**: COPY BINARYは**連続したバイトストリーム**として出力され、ページ境界の情報は含まれない

### 3. なぜ64MB境界で行がまたがるのか

```
PostgreSQL内部:
ページ0 [行1, 行2, 行3]    8KB
ページ1 [行4, 行5, 行6]    8KB
ページ2 [行7, 行8, 行9]    8KB
...

COPY BINARY出力:
[ヘッダー][行1][行2][行3][行4][行5][行6][行7][行8][行9]...
          ↑
          連続ストリーム（ページ境界なし）

Rust並列書き込み:
ワーカー1: [0-64MB)     ← 64MB境界で行が分断される可能性
ワーカー2: [64MB-128MB) ← 
```

### 4. TOASTの影響は？

customerテーブルの構造:
- c_custkey: numeric(38,0) → 最大16バイト
- c_name: character(25) → 固定25バイト
- c_address: character(40) → 固定40バイト
- その他: すべて固定長

**結論**: customerテーブルにTOAST対象のカラムはない（すべて2KB未満）

### 5. ctid単位でフラッシュする案について

```rust
// 理論的には可能だが...
for page in start_page..end_page {
    // 1ページずつCOPY
    let query = format!("COPY ... WHERE ctid >= '({},1)'::tid AND ctid < '({},1)'::tid");
    // 問題: パフォーマンスが大幅に低下
}
```

**問題点**:
- 1ページ8KBずつのCOPYは非効率
- ネットワークオーバーヘッドが増大
- 並列性のメリットが失われる

## 結論

8KBページ管理は**PostgreSQL内部**の論理構造であり、COPY BINARYの**出力**は連続ストリームです。そのため、64MB境界で行がまたがるのは自然な現象です。

最も効率的な100点の解決策は：
1. **GPU側でオーバーラップ読み取り**（推奨）
2. バッファサイズを256MBに増やす（簡易対策）
3. スマートバッファリング（完全だが複雑）