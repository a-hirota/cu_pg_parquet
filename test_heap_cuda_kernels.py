#!/usr/bin/env python3
"""
PostgreSQLãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸è§£æCUDAã‚«ãƒ¼ãƒãƒ«åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆ

GPGPUã§ã®ãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸è§£ææ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã€ãƒ¡ãƒ¢ãƒªã‚³ã‚¢ãƒ¬ãƒƒã‚·ãƒ³ã‚°ã‚’ç¢ºèªã™ã‚‹ã€‚
"""

import numpy as np
import cupy as cp
from numba import cuda

# PostgreSQLå®šæ•°
POSTGRES_PAGE_SIZE = 8192
PAGE_HEADER_SIZE = 24
ITEM_ID_SIZE = 4
LP_NORMAL = 1
LP_UNUSED = 0
T_XMAX_OFFSET = 8

print("=== PostgreSQLãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸è§£æCUDAã‚«ãƒ¼ãƒãƒ«ãƒ†ã‚¹ãƒˆ ===")

# ãƒ‡ãƒã‚¤ã‚¹é–¢æ•°ã®å®šç¾©
@cuda.jit(device=True, inline=True)
def read_uint16_le(data, offset):
    """ãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ã§uint16ã‚’èª­ã¿å–ã‚Š"""
    if offset + 1 >= data.size:
        return np.uint16(0)
    return np.uint16(data[offset] | (data[offset + 1] << 8))

@cuda.jit(device=True, inline=True)
def read_uint32_le(data, offset):
    """ãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ã§uint32ã‚’èª­ã¿å–ã‚Š"""
    if offset + 3 >= data.size:
        return np.uint32(0)
    return np.uint32(data[offset] | 
                     (data[offset + 1] << 8) | 
                     (data[offset + 2] << 16) | 
                     (data[offset + 3] << 24))

@cuda.jit(device=True, inline=True)
def validate_page_header(data, page_offset):
    """ãƒšãƒ¼ã‚¸ãƒ˜ãƒƒãƒ€ãƒ¼ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼"""
    if page_offset + PAGE_HEADER_SIZE >= len(data):
        return False
    
    # pd_lowerï¼ˆ2ãƒã‚¤ãƒˆã€ã‚ªãƒ•ã‚»ãƒƒãƒˆ12ï¼‰
    pd_lower = read_uint16_le(data, page_offset + 12)
    # pd_upperï¼ˆ2ãƒã‚¤ãƒˆã€ã‚ªãƒ•ã‚»ãƒƒãƒˆ14ï¼‰
    pd_upper = read_uint16_le(data, page_offset + 14)
    
    if pd_lower < PAGE_HEADER_SIZE or pd_lower > POSTGRES_PAGE_SIZE:
        return False
    if pd_upper > POSTGRES_PAGE_SIZE or pd_upper < pd_lower:
        return False
    
    return True

# ãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸è§£æã‚«ãƒ¼ãƒãƒ«ï¼ˆãƒ¡ãƒ¢ãƒªã‚³ã‚¢ãƒ¬ãƒƒã‚·ãƒ³ã‚°æœ€é©åŒ–ç‰ˆï¼‰
@cuda.jit
def test_heap_page_parser_coalesced(
    heap_data,
    page_offsets, 
    tuple_count_out
):
    """
    ãƒ¡ãƒ¢ãƒªã‚³ã‚¢ãƒ¬ãƒƒã‚·ãƒ³ã‚°ã‚’æ„è­˜ã—ãŸãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸è§£æã‚«ãƒ¼ãƒãƒ«
    
    å„ã‚¹ãƒ¬ãƒƒãƒ‰ãŒé€£ç¶šã—ãŸãƒ¡ãƒ¢ãƒªã‚¢ãƒ‰ãƒ¬ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚ˆã†ã«æœ€é©åŒ–
    """
    page_idx = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x
    
    if page_idx >= page_offsets.size:
        return
    
    page_offset = page_offsets[page_idx]
    
    # ãƒšãƒ¼ã‚¸ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œè¨¼ï¼ˆã‚³ã‚¢ãƒ¬ãƒƒã‚·ãƒ³ã‚°ã‚¢ã‚¯ã‚»ã‚¹ï¼‰
    if not validate_page_header(heap_data, page_offset):
        tuple_count_out[page_idx] = 0
        return
    
    # pd_lowerã‹ã‚‰ItemIdæ•°ã‚’è¨ˆç®—
    pd_lower = read_uint16_le(heap_data, page_offset + 12)
    item_array_size = pd_lower - PAGE_HEADER_SIZE
    item_count = item_array_size // ITEM_ID_SIZE
    
    # æœ‰åŠ¹ãªã‚¿ãƒ—ãƒ«æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆé€£ç¶šãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹æœ€é©åŒ–ï¼‰
    valid_count = 0
    for item_idx in range(min(item_count, 100)):  # æœ€å¤§100å€‹ã¾ã§
        item_offset = page_offset + PAGE_HEADER_SIZE + (item_idx * ITEM_ID_SIZE)
        if item_offset + ITEM_ID_SIZE <= heap_data.size:
            # 4ãƒã‚¤ãƒˆå¢ƒç•Œã§ã®ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ï¼ˆGPUæœ€é©åŒ–ï¼‰
            item_data = read_uint32_le(heap_data, item_offset)
            lp_flags = (item_data >> 30) & np.uint32(0x3)
            if lp_flags == LP_NORMAL:
                valid_count += 1
    
    # ã‚³ã‚¢ãƒ¬ãƒƒã‚·ãƒ³ã‚°æ›¸ãè¾¼ã¿
    tuple_count_out[page_idx] = valid_count

def create_mock_heap_page():
    """
    ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¢ãƒƒã‚¯ãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    
    Returns:
        numpy.ndarray: æ¨¡æ“¬ãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ï¼ˆ8KBï¼‰
    """
    page_data = np.zeros(POSTGRES_PAGE_SIZE, dtype=np.uint8)
    
    # PageHeaderDataè¨­å®š
    # pd_lower = PAGE_HEADER_SIZE + (3 * ITEM_ID_SIZE) = 24 + 12 = 36
    pd_lower = PAGE_HEADER_SIZE + (3 * ITEM_ID_SIZE)
    page_data[12:14] = [pd_lower & 0xFF, (pd_lower >> 8) & 0xFF]
    
    # pd_upper = POSTGRES_PAGE_SIZE - 100 = 8092ï¼ˆã‚¿ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿é–‹å§‹ä½ç½®ï¼‰
    pd_upper = POSTGRES_PAGE_SIZE - 100
    page_data[14:16] = [pd_upper & 0xFF, (pd_upper >> 8) & 0xFF]
    
    # ItemIdé…åˆ—è¨­å®šï¼ˆ3å€‹ã®NORMALã‚¿ãƒ—ãƒ«ï¼‰
    for i in range(3):
        item_offset = PAGE_HEADER_SIZE + (i * ITEM_ID_SIZE)
        lp_off = pd_upper + (i * 32)  # å„ã‚¿ãƒ—ãƒ«32ãƒã‚¤ãƒˆé–“éš”
        lp_len = 28
        lp_flags = LP_NORMAL
        
        # ItemIdDataæ§‹é€ ä½“ï¼ˆãƒ¡ãƒ¢ãƒªé…ç½®æœ€é©åŒ–ï¼‰
        item_data = lp_off | (lp_len << 16) | (lp_flags << 30)
        page_data[item_offset:item_offset+4] = [
            item_data & 0xFF,
            (item_data >> 8) & 0xFF,
            (item_data >> 16) & 0xFF,
            (item_data >> 24) & 0xFF
        ]
    
    return page_data

def test_memory_coalescing_performance():
    """ãƒ¡ãƒ¢ãƒªã‚³ã‚¢ãƒ¬ãƒƒã‚·ãƒ³ã‚°æ€§èƒ½ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ãƒ¡ãƒ¢ãƒªã‚³ã‚¢ãƒ¬ãƒƒã‚·ãƒ³ã‚°æ€§èƒ½ãƒ†ã‚¹ãƒˆ ===")
    
    # å¤§é‡ã®ãƒšãƒ¼ã‚¸ã‚’ä½œæˆï¼ˆGPUãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆç”¨ï¼‰
    num_pages = 1024  # 1024ãƒšãƒ¼ã‚¸ = 8MB
    mock_page = create_mock_heap_page()
    
    # é€£ç¶šãƒ’ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ¡ãƒ¢ãƒªã‚³ã‚¢ãƒ¬ãƒƒã‚·ãƒ³ã‚°æœ€é©åŒ–ï¼‰
    heap_data_host = np.tile(mock_page, num_pages)
    heap_data_gpu = cuda.to_device(heap_data_host)
    
    # ãƒšãƒ¼ã‚¸ã‚ªãƒ•ã‚»ãƒƒãƒˆé…åˆ—
    page_offsets_host = np.arange(0, num_pages * POSTGRES_PAGE_SIZE, POSTGRES_PAGE_SIZE, dtype=np.uint32)
    page_offsets_gpu = cuda.to_device(page_offsets_host)
    
    # å‡ºåŠ›é…åˆ—
    tuple_counts_gpu = cuda.device_array(num_pages, dtype=np.uint32)
    
    print(f"âœ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")
    print(f"  ãƒ’ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(heap_data_host) / (1024*1024):.2f} MB")
    print(f"  ãƒšãƒ¼ã‚¸æ•°: {num_pages:,}")
    
    # ã‚°ãƒªãƒƒãƒ‰è¨­å®šï¼ˆGPUå æœ‰ç‡æœ€é©åŒ–ï¼‰
    threads_per_block = 256  # RTX 3090ã«æœ€é©åŒ–
    blocks = (num_pages + threads_per_block - 1) // threads_per_block
    
    print(f"âœ“ ã‚°ãƒªãƒƒãƒ‰è¨­å®š: {blocks} blocks Ã— {threads_per_block} threads")
    print(f"  ç·ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {blocks * threads_per_block:,}")
    print(f"  GPUå æœ‰ç‡: {min(100, (blocks * threads_per_block) / (2560 * 32) * 100):.1f}%")  # RTX 3090: 10752 CUDA cores
    
    # ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œï¼ˆæ€§èƒ½æ¸¬å®šï¼‰
    cuda.synchronize()
    import time
    start_time = time.time()
    
    test_heap_page_parser_coalesced[blocks, threads_per_block](
        heap_data_gpu, page_offsets_gpu, tuple_counts_gpu
    )
    cuda.synchronize()
    
    end_time = time.time()
    execution_time = end_time - start_time
    
    # çµæœç¢ºèª
    tuple_counts_host = tuple_counts_gpu.copy_to_host()
    total_tuples = np.sum(tuple_counts_host)
    
    print(f"âœ“ ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œå®Œäº†")
    print(f"  å®Ÿè¡Œæ™‚é–“: {execution_time*1000:.3f} ms")
    print(f"  ç·ã‚¿ãƒ—ãƒ«æ•°: {total_tuples:,}")
    print(f"  å‡¦ç†ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {num_pages / execution_time:.0f} pages/sec")
    print(f"  ãƒ¡ãƒ¢ãƒªã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {(len(heap_data_host) / (1024*1024)) / execution_time:.1f} MB/sec")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    if execution_time < 0.001:  # 1msæœªæº€
        performance_class = "ğŸ† æ¥µé«˜é€Ÿ (ãƒ¡ãƒ¢ãƒªã‚³ã‚¢ãƒ¬ãƒƒã‚·ãƒ³ã‚°æœ€é©åŒ–æˆåŠŸ)"
    elif execution_time < 0.01:  # 10msæœªæº€
        performance_class = "ğŸ¥‡ é«˜é€Ÿ (è‰¯å¥½ãªGPUåˆ©ç”¨)"
    else:
        performance_class = "ğŸ¥ˆ æ”¹å–„ä½™åœ°ã‚ã‚Š"
    
    print(f"  æ€§èƒ½ã‚¯ãƒ©ã‚¹: {performance_class}")
    
    # æœŸå¾…å€¤æ¤œè¨¼
    expected_tuples_per_page = 3
    expected_total = num_pages * expected_tuples_per_page
    
    if total_tuples == expected_total:
        print("âœ“ çµæœæ¤œè¨¼: å…¨ãƒšãƒ¼ã‚¸ã§æœŸå¾…é€šã‚Šã®ã‚¿ãƒ—ãƒ«æ•°ã‚’æ¤œå‡º")
    else:
        print(f"âš ï¸  çµæœç•°å¸¸: æœŸå¾…å€¤ {expected_total}, å®Ÿéš› {total_tuples}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        print("âœ“ CUDAã‚«ãƒ¼ãƒãƒ«å®šç¾©å®Œäº†")
        
        # åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆ
        print("\n=== åŸºæœ¬å‹•ä½œãƒ†ã‚¹ãƒˆ ===")
        
        # ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        mock_page1 = create_mock_heap_page()
        mock_page2 = create_mock_heap_page() 
        
        # 2ãƒšãƒ¼ã‚¸åˆ†ã®ãƒ’ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿
        heap_data_host = np.concatenate([mock_page1, mock_page2])
        heap_data_gpu = cuda.to_device(heap_data_host)
        
        # ãƒšãƒ¼ã‚¸ã‚ªãƒ•ã‚»ãƒƒãƒˆ
        page_offsets_host = np.array([0, POSTGRES_PAGE_SIZE], dtype=np.uint32)
        page_offsets_gpu = cuda.to_device(page_offsets_host)
        
        # å‡ºåŠ›é…åˆ—
        tuple_counts_gpu = cuda.device_array(2, dtype=np.uint32)
        
        print(f"âœ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")
        print(f"  ãƒ’ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(heap_data_host)} bytes")
        print(f"  ãƒšãƒ¼ã‚¸æ•°: {len(page_offsets_host)}")
        
        # ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
        threads_per_block = 256
        blocks = (len(page_offsets_host) + threads_per_block - 1) // threads_per_block
        
        test_heap_page_parser_coalesced[blocks, threads_per_block](
            heap_data_gpu, page_offsets_gpu, tuple_counts_gpu
        )
        cuda.synchronize()
        
        # çµæœç¢ºèª
        tuple_counts_host = tuple_counts_gpu.copy_to_host()
        print(f"âœ“ ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œå®Œäº†")
        print(f"  ãƒšãƒ¼ã‚¸0ã®ã‚¿ãƒ—ãƒ«æ•°: {tuple_counts_host[0]}")
        print(f"  ãƒšãƒ¼ã‚¸1ã®ã‚¿ãƒ—ãƒ«æ•°: {tuple_counts_host[1]}")
        print(f"  ç·ã‚¿ãƒ—ãƒ«æ•°: {np.sum(tuple_counts_host)}")
        
        # æœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ
        if tuple_counts_host[0] == 3 and tuple_counts_host[1] == 3:
            print("âœ“ æœŸå¾…å€¤ä¸€è‡´: ãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸è§£æGPGPUå‡¦ç†æ­£å¸¸å‹•ä½œ")
        else:
            print(f"âš ï¸  æœŸå¾…å€¤(3,3)ã¨ç•°ãªã‚‹çµæœ: {tuple_counts_host}")
        
        # æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        test_memory_coalescing_performance()
        
        print("\n=== ãƒ†ã‚¹ãƒˆå®Œäº† ===")
        print("ğŸ‰ PostgreSQLãƒ’ãƒ¼ãƒ—ãƒšãƒ¼ã‚¸è§£æCUDAã‚«ãƒ¼ãƒãƒ«ã®å‹•ä½œç¢ºèªæˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()