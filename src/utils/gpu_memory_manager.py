"""
GPUãƒ¡ãƒ¢ãƒªç®¡ç†ã®æ”¹å–„ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æœ€å°åŒ–ã—ã€å¤§è¦æ¨¡ãƒ†ãƒ¼ãƒ–ãƒ«å‡¦ç†æ™‚ã®OOMã‚’é˜²ã
"""
import rmm
import cupy as cp
import gc
import warnings
from typing import Optional, Dict, Any


class GPUMemoryManager:
    """æ”¹å–„ã•ã‚ŒãŸGPUãƒ¡ãƒ¢ãƒªç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, strategy: str = 'arena'):
        """
        Args:
            strategy: 'arena', 'async', 'pool', 'binning'ã®ã„ãšã‚Œã‹
        """
        self.strategy = strategy
        self.original_mr = None
        self.memory_resource = None
        
    def setup_memory_resource(self) -> None:
        """ãƒ¡ãƒ¢ãƒªãƒªã‚½ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
        try:
            # ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªãƒªã‚½ãƒ¼ã‚¹ã‚’ä¿å­˜
            self.original_mr = rmm.mr.get_current_device_resource()
            
            # GPUãƒ¡ãƒ¢ãƒªæƒ…å ±ã‚’å–å¾—
            gpu_memory = cp.cuda.runtime.getDeviceProperties(0)['totalGlobalMem']
            
            if self.strategy == 'arena':
                # Arena Memory Resourceï¼ˆãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å›é¿ã«æœ€é©ï¼‰
                upstream = rmm.mr.CudaMemoryResource()
                self.memory_resource = rmm.mr.ArenaMemoryResource(
                    upstream_mr=upstream,
                    arena_size=None,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªã®åŠåˆ†
                    dump_log_on_failure=True  # ãƒ‡ãƒãƒƒã‚°ç”¨
                )
                print(f"âœ… Arena Memory Resource ã‚’è¨­å®šï¼ˆãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼‰")
                
            elif self.strategy == 'async':
                # CUDA Async Memory Resourceï¼ˆãƒ¡ãƒ¢ãƒªã‚’ã‚·ã‚¹ãƒ†ãƒ ã«è¿”å´å¯èƒ½ï¼‰
                # CUDA 11.2ä»¥ä¸ŠãŒå¿…è¦
                self.memory_resource = rmm.mr.CudaAsyncMemoryResource()
                print(f"âœ… CUDA Async Memory Resource ã‚’è¨­å®šï¼ˆå‹•çš„ãƒ¡ãƒ¢ãƒªç®¡ç†ï¼‰")
                
            elif self.strategy == 'pool':
                # Pool Memory Resourceï¼ˆå¾“æ¥æ–¹å¼ã®æ”¹å–„ç‰ˆï¼‰
                # ã‚ˆã‚Šä¿å®ˆçš„ãªè¨­å®šï¼ˆ70%åˆæœŸã€85%æœ€å¤§ï¼‰
                self.memory_resource = rmm.mr.PoolMemoryResource(
                    upstream_mr=rmm.mr.CudaMemoryResource(),
                    initial_pool_size=int(gpu_memory * 0.7),
                    maximum_pool_size=int(gpu_memory * 0.85)
                )
                print(f"âœ… Pool Memory Resource ã‚’è¨­å®šï¼ˆåˆæœŸ70%, æœ€å¤§85%ï¼‰")
                
            elif self.strategy == 'binning':
                # Binning Memory Resourceï¼ˆæ§˜ã€…ãªã‚µã‚¤ã‚ºã®ã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«å¯¾å¿œï¼‰
                pool_mr = rmm.mr.PoolMemoryResource(
                    upstream_mr=rmm.mr.CudaMemoryResource(),
                    initial_pool_size=int(gpu_memory * 0.6),
                    maximum_pool_size=int(gpu_memory * 0.8)
                )
                self.memory_resource = rmm.mr.BinningMemoryResource(
                    upstream_mr=pool_mr,
                    min_size_exponent=10,  # 1KB
                    max_size_exponent=26   # 64MB
                )
                print(f"âœ… Binning Memory Resource ã‚’è¨­å®šï¼ˆã‚µã‚¤ã‚ºåˆ¥æœ€é©åŒ–ï¼‰")
                
            # ãƒ¡ãƒ¢ãƒªãƒªã‚½ãƒ¼ã‚¹ã‚’è¨­å®š
            rmm.mr.set_current_device_resource(self.memory_resource)
            
        except Exception as e:
            warnings.warn(f"ãƒ¡ãƒ¢ãƒªãƒªã‚½ãƒ¼ã‚¹è¨­å®šã‚¨ãƒ©ãƒ¼: {e}, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«æˆ»ã—ã¾ã™")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å¾“æ¥ã®æ–¹å¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self._setup_fallback_pool()
    
    def _setup_fallback_pool(self) -> None:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®æ¨™æº–ãƒ—ãƒ¼ãƒ«è¨­å®š"""
        try:
            gpu_memory = cp.cuda.runtime.getDeviceProperties(0)['totalGlobalMem']
            rmm.reinitialize(
                pool_allocator=True,
                initial_pool_size=int(gpu_memory * 0.5),
                maximum_pool_size=int(gpu_memory * 0.7)
            )
            print("âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ¨™æº–ãƒ—ãƒ¼ãƒ«ï¼ˆ50%-70%ï¼‰ã‚’ä½¿ç”¨")
        except Exception as e:
            print(f"âŒ RMMåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_memory_info(self) -> Dict[str, float]:
        """ç¾åœ¨ã®GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã‚’å–å¾—"""
        try:
            # CuPyãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«æƒ…å ±
            mempool = cp.get_default_memory_pool()
            used_bytes = mempool.used_bytes()
            total_bytes = mempool.total_bytes()
            
            # CUDA Runtimeæƒ…å ±
            free_mem, total_mem = cp.cuda.runtime.memGetInfo()
            
            # RMMæƒ…å ±ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            rmm_info = {}
            if rmm.is_initialized():
                try:
                    info = rmm.get_info()
                    rmm_info = {
                        'rmm_total_bytes': info.total_bytes / 1024**3,
                        'rmm_free_bytes': info.free_bytes / 1024**3 if hasattr(info, 'free_bytes') else 0
                    }
                except:
                    pass
            
            return {
                'cupy_used_gb': used_bytes / 1024**3,
                'cupy_total_gb': total_bytes / 1024**3,
                'cuda_free_gb': free_mem / 1024**3,
                'cuda_total_gb': total_mem / 1024**3,
                'cuda_used_gb': (total_mem - free_mem) / 1024**3,
                'utilization': (total_mem - free_mem) / total_mem * 100,
                **rmm_info
            }
        except Exception as e:
            return {'error': str(e)}
    
    def aggressive_cleanup(self) -> None:
        """ç©æ¥µçš„ãªãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # CuPyãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒªã‚¢
            mempool = cp.get_default_memory_pool()
            pinned_mempool = cp.get_default_pinned_memory_pool()
            
            # ä½¿ç”¨ä¸­ã®ãƒ¡ãƒ¢ãƒªã‚’è¨˜éŒ²
            before_used = mempool.used_bytes()
            
            # ãƒ¡ãƒ¢ãƒªãƒ–ãƒ­ãƒƒã‚¯ã‚’è§£æ”¾
            mempool.free_all_blocks()
            pinned_mempool.free_all_blocks()
            
            # Python GCã‚’å¼·åˆ¶å®Ÿè¡Œ
            gc.collect()
            
            # CUDAãƒ‡ãƒã‚¤ã‚¹ã‚’åŒæœŸ
            cp.cuda.Stream.null.synchronize()
            
            # è§£æ”¾ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªé‡ã‚’è¨ˆç®—
            after_used = mempool.used_bytes()
            freed_gb = (before_used - after_used) / 1024**3
            
            if freed_gb > 0:
                print(f"ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {freed_gb:.2f} GB è§£æ”¾")
                
        except Exception as e:
            warnings.warn(f"ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def log_memory_status(self, label: str = "") -> None:
        """ãƒ¡ãƒ¢ãƒªçŠ¶æ³ã‚’ãƒ­ã‚°å‡ºåŠ›"""
        info = self.get_memory_info()
        if 'error' not in info:
            print(f"\n{'='*60}")
            print(f"ğŸ“Š GPUãƒ¡ãƒ¢ãƒªçŠ¶æ³ {label}")
            print(f"{'='*60}")
            print(f"CUDAä½¿ç”¨é‡: {info['cuda_used_gb']:.2f}/{info['cuda_total_gb']:.2f} GB ({info['utilization']:.1f}%)")
            print(f"CuPy Pool: {info['cupy_used_gb']:.2f}/{info['cupy_total_gb']:.2f} GB")
            if 'rmm_total_bytes' in info:
                print(f"RMMä½¿ç”¨é‡: {info['rmm_total_bytes']:.2f} GB")
            print(f"{'='*60}\n")
    
    def reset(self) -> None:
        """ãƒ¡ãƒ¢ãƒªãƒªã‚½ãƒ¼ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        if self.original_mr is not None:
            try:
                rmm.mr.set_current_device_resource(self.original_mr)
                print("ãƒ¡ãƒ¢ãƒªãƒªã‚½ãƒ¼ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
            except:
                pass


# ä½¿ã„ã‚„ã™ã„ã‚°ãƒ­ãƒ¼ãƒãƒ«é–¢æ•°
def setup_gpu_memory(strategy: str = 'arena') -> GPUMemoryManager:
    """GPUãƒ¡ãƒ¢ãƒªç®¡ç†ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    manager = GPUMemoryManager(strategy)
    manager.setup_memory_resource()
    return manager


def cleanup_gpu_memory() -> None:
    """GPUãƒ¡ãƒ¢ãƒªã®ç©æ¥µçš„ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    manager = GPUMemoryManager()
    manager.aggressive_cleanup()