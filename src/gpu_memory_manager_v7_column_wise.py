"""
GPU Memory Manager V7: åˆ—é †åºãƒ™ãƒ¼ã‚¹çµ±åˆç‰ˆï¼ˆGrid sizeæœ€é©åŒ–ï¼‰
========================================

V7ã‚«ãƒ¼ãƒãƒ«å°‚ç”¨ã®æœ€é©åŒ–ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ :
1. åˆ—é †åºå‡¦ç†å¯¾å¿œ
2. æ®µéšçš„ãƒ¡ãƒ¢ãƒªç¢ºä¿
3. å¯å¤‰é•·ãƒ‡ãƒ¼ã‚¿ã®å‹•çš„ã‚µã‚¤ã‚ºèª¿æ•´
4. ãƒ–ãƒ­ãƒƒã‚¯å†…Prefix-sumå¯¾å¿œ
5. Grid sizeå®Œå…¨æœ€é©åŒ–ï¼ˆGPUä¸¦åˆ—æ€§ç¢ºä¿ï¼‰
"""

from typing import List, Dict, Any, Tuple, NamedTuple
import numpy as np
import cupy as cp
from numba import cuda

from .type_map import *

class ColumnLayoutV7(NamedTuple):
    """V7ç”¨ã®åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±"""
    name: str
    column_index: int        # å…ƒã®ãƒ†ãƒ¼ãƒ–ãƒ«åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    arrow_type_id: int       # Arrowå‹ID
    is_variable: bool        # å¯å¤‰é•·ãƒ•ãƒ©ã‚°
    
    # å›ºå®šé•·åˆ—ç”¨
    buffer_offset: int       # çµ±åˆãƒãƒƒãƒ•ã‚¡å†…ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆå›ºå®šé•·ã®ã¿ï¼‰
    element_size: int        # è¦ç´ ã‚µã‚¤ã‚ºï¼ˆå›ºå®šé•·ã®ã¿ï¼‰
    decimal_scale: int       # Decimalåˆ—ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆå›ºå®šé•·ã®ã¿ï¼‰
    
    # å¯å¤‰é•·åˆ—ç”¨
    var_index: int          # å¯å¤‰é•·åˆ—å†…ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆå¯å¤‰é•·ã®ã¿ï¼‰

class V7BufferInfo(NamedTuple):
    """V7çµ±åˆãƒãƒƒãƒ•ã‚¡ã®æƒ…å ±"""
    # å›ºå®šé•·ãƒãƒƒãƒ•ã‚¡
    fixed_buffer: cuda.cudadrv.devicearray.DeviceNDArray
    row_stride: int
    fixed_layouts: List[ColumnLayoutV7]
    
    # å¯å¤‰é•·ãƒãƒƒãƒ•ã‚¡
    var_data_buffer: cuda.cudadrv.devicearray.DeviceNDArray
    var_offset_arrays: cuda.cudadrv.devicearray.DeviceNDArray  # 2Dé…åˆ—
    var_layouts: List[ColumnLayoutV7]
    
    # åˆ—ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é…åˆ—ï¼ˆã‚«ãƒ¼ãƒãƒ«ç”¨ï¼‰
    column_types: cuda.cudadrv.devicearray.DeviceNDArray
    column_is_variable: cuda.cudadrv.devicearray.DeviceNDArray
    column_indices: cuda.cudadrv.devicearray.DeviceNDArray
    
    # å›ºå®šé•·åˆ—æƒ…å ±é…åˆ—
    fixed_column_offsets: cuda.cudadrv.devicearray.DeviceNDArray
    fixed_column_sizes: cuda.cudadrv.devicearray.DeviceNDArray
    fixed_decimal_scales: cuda.cudadrv.devicearray.DeviceNDArray
    
    # å¯å¤‰é•·åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°
    var_column_mapping: cuda.cudadrv.devicearray.DeviceNDArray

class GPUMemoryManagerV7ColumnWise:
    """V7åˆ—é †åºãƒ™ãƒ¼ã‚¹çµ±åˆãƒãƒƒãƒ•ã‚¡å¯¾å¿œã®GPUãƒ¡ãƒ¢ãƒªãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆGrid sizeæœ€é©åŒ–ç‰ˆï¼‰"""
    
    def __init__(self):
        self.device_buffers = {}
        self.v7_buffer_info = None
        
    def get_element_size(self, arrow_id: int) -> int:
        """Arrowå‹IDã‹ã‚‰è¦ç´ ã‚µã‚¤ã‚ºã‚’å–å¾—"""
        size_map = {
            INT16: 2,
            INT32: 4, 
            INT64: 8,
            FLOAT32: 4,
            FLOAT64: 8,
            DECIMAL128: 16,
            BOOL: 1,
            DATE32: 4,
            TS64_US: 8
        }
        return size_map.get(arrow_id, 4)
    
    def analyze_columns_v7(self, columns, rows: int) -> Tuple[List[ColumnLayoutV7], List[ColumnLayoutV7]]:
        """V7ç”¨ã®åˆ—åˆ†æï¼šé †åºã‚’ä¿æŒã—ãªãŒã‚‰å›ºå®šé•·ãƒ»å¯å¤‰é•·ã‚’åˆ†é¡"""
        fixed_layouts = []
        var_layouts = []
        
        current_fixed_offset = 0
        var_index = 0
        fixed_index = 0
        
        for col_idx, col in enumerate(columns):
            if col.is_variable and (col.arrow_id == UTF8 or col.arrow_id == BINARY):
                # å¯å¤‰é•·æ–‡å­—åˆ—åˆ—
                layout = ColumnLayoutV7(
                    name=col.name,
                    column_index=col_idx,
                    arrow_type_id=col.arrow_id,
                    is_variable=True,
                    buffer_offset=-1,  # å¯å¤‰é•·ã§ã¯æœªä½¿ç”¨
                    element_size=0,    # å¯å¤‰é•·ã§ã¯æœªä½¿ç”¨
                    decimal_scale=0,   # å¯å¤‰é•·ã§ã¯æœªä½¿ç”¨
                    var_index=var_index
                )
                var_layouts.append(layout)
                var_index += 1
            else:
                # å›ºå®šé•·åˆ—
                element_size = self.get_element_size(col.arrow_id)
                
                # Decimalåˆ—ã®ã‚¹ã‚±ãƒ¼ãƒ«å–å¾—
                decimal_scale = 0
                if col.arrow_id == DECIMAL128:
                    precision, scale = col.arrow_param or (38, 0)
                    if precision == 0:
                        precision, scale = 38, 0
                    decimal_scale = scale
                
                layout = ColumnLayoutV7(
                    name=col.name,
                    column_index=col_idx,
                    arrow_type_id=col.arrow_id,
                    is_variable=False,
                    buffer_offset=current_fixed_offset,
                    element_size=element_size,
                    decimal_scale=decimal_scale,
                    var_index=-1  # å›ºå®šé•·ã§ã¯æœªä½¿ç”¨
                )
                fixed_layouts.append(layout)
                current_fixed_offset += element_size
                fixed_index += 1
        
        return fixed_layouts, var_layouts
    
    def create_column_metadata_arrays(self, columns) -> Tuple[
        cuda.cudadrv.devicearray.DeviceNDArray,  # column_types
        cuda.cudadrv.devicearray.DeviceNDArray,  # column_is_variable  
        cuda.cudadrv.devicearray.DeviceNDArray   # column_indices
    ]:
        """ã‚«ãƒ¼ãƒãƒ«ç”¨ã®åˆ—ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é…åˆ—ã‚’ä½œæˆ"""
        total_cols = len(columns)
        
        column_types = np.array([col.arrow_id for col in columns], dtype=np.int32)
        column_is_variable = np.array([1 if col.is_variable else 0 for col in columns], dtype=np.uint8)
        column_indices = np.array(list(range(total_cols)), dtype=np.int32)
        
        d_column_types = cuda.to_device(column_types)
        d_column_is_variable = cuda.to_device(column_is_variable)
        d_column_indices = cuda.to_device(column_indices)
        
        return d_column_types, d_column_is_variable, d_column_indices
    
    def create_fixed_metadata_arrays(self, fixed_layouts: List[ColumnLayoutV7]) -> Tuple[
        cuda.cudadrv.devicearray.DeviceNDArray,  # fixed_column_offsets
        cuda.cudadrv.devicearray.DeviceNDArray,  # fixed_column_sizes
        cuda.cudadrv.devicearray.DeviceNDArray   # fixed_decimal_scales
    ]:
        """å›ºå®šé•·åˆ—ç”¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é…åˆ—ã‚’ä½œæˆ"""
        if not fixed_layouts:
            empty_array = np.array([], dtype=np.int32)
            return (cuda.to_device(empty_array), 
                   cuda.to_device(empty_array), 
                   cuda.to_device(empty_array))
        
        fixed_offsets = np.array([layout.buffer_offset for layout in fixed_layouts], dtype=np.int32)
        fixed_sizes = np.array([layout.element_size for layout in fixed_layouts], dtype=np.int32)
        fixed_scales = np.array([layout.decimal_scale for layout in fixed_layouts], dtype=np.int32)
        
        return (cuda.to_device(fixed_offsets),
               cuda.to_device(fixed_sizes),
               cuda.to_device(fixed_scales))
    
    def create_var_column_mapping(self, columns, var_layouts: List[ColumnLayoutV7]) -> cuda.cudadrv.devicearray.DeviceNDArray:
        """å¯å¤‰é•·åˆ—ã®ãƒãƒƒãƒ”ãƒ³ã‚°é…åˆ—ã‚’ä½œæˆï¼ˆåˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹â†’å¯å¤‰é•·ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰"""
        total_cols = len(columns)
        mapping = np.full(total_cols, -1, dtype=np.int32)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ-1ï¼ˆéå¯å¤‰é•·ï¼‰
        
        for var_layout in var_layouts:
            mapping[var_layout.column_index] = var_layout.var_index
        
        return cuda.to_device(mapping)
    
    def estimate_variable_total_size_v7(self, var_layouts: List[ColumnLayoutV7], rows: int) -> int:
        """V7ç”¨å¯å¤‰é•·ãƒ‡ãƒ¼ã‚¿ç·ã‚µã‚¤ã‚ºæ¨å®šï¼ˆãƒ–ãƒ­ãƒƒã‚¯å†…Prefix-sumã‚’è€ƒæ…®ï¼‰"""
        if not var_layouts:
            return 1
        
        # ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºã‚’è€ƒæ…®ã—ãŸæ¨å®š
        avg_string_length = 50
        safety_factor = 2.0  # ãƒ–ãƒ­ãƒƒã‚¯å†…å‡¦ç†ã®ãŸã‚å°‘ã—å¤§ãã‚
        
        total_estimated = len(var_layouts) * rows * avg_string_length * safety_factor
        return int(total_estimated)
    
    def create_fixed_buffer_v7(self, fixed_layouts: List[ColumnLayoutV7], rows: int) -> Tuple[cuda.cudadrv.devicearray.DeviceNDArray, int]:
        """V7ç”¨å›ºå®šé•·çµ±åˆãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ"""
        if not fixed_layouts:
            return cuda.device_array(1, dtype=np.uint8), 0
        
        # 1è¡Œåˆ†ã®ãƒã‚¤ãƒˆæ•°è¨ˆç®—
        row_stride = sum(layout.element_size for layout in fixed_layouts)
        
        # çµ±åˆãƒãƒƒãƒ•ã‚¡ç¢ºä¿
        total_bytes = rows * row_stride
        fixed_buffer = cuda.device_array(total_bytes, dtype=np.uint8)
        
        print(f"V7å›ºå®šé•·çµ±åˆãƒãƒƒãƒ•ã‚¡ä½œæˆ: {len(fixed_layouts)}åˆ—, è¡Œã‚¹ãƒˆãƒ©ã‚¤ãƒ‰={row_stride}ãƒã‚¤ãƒˆ, ç·ã‚µã‚¤ã‚º={total_bytes}ãƒã‚¤ãƒˆ")
        
        return fixed_buffer, row_stride
    
    def create_variable_buffers_v7(self, var_layouts: List[ColumnLayoutV7], rows: int) -> Tuple[
        cuda.cudadrv.devicearray.DeviceNDArray,  # çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ•ã‚¡
        cuda.cudadrv.devicearray.DeviceNDArray   # ã‚ªãƒ•ã‚»ãƒƒãƒˆé…åˆ—ï¼ˆ2Dï¼‰
    ]:
        """V7ç”¨å¯å¤‰é•·çµ±åˆãƒãƒƒãƒ•ã‚¡ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆï¼ˆGrid sizeæœ€é©åŒ–ç‰ˆï¼‰"""
        
        if not var_layouts:
            dummy_buffer = cuda.device_array(1, dtype=np.uint8)
            dummy_offsets = cuda.device_array((1, rows + 1), dtype=np.int32)
            return dummy_buffer, dummy_offsets
        
        # çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ•ã‚¡
        total_size = self.estimate_variable_total_size_v7(var_layouts, rows)
        var_data_buffer = cuda.device_array(total_size, dtype=np.uint8)
        
        # 2Dã‚ªãƒ•ã‚»ãƒƒãƒˆé…åˆ—ï¼ˆvar_count Ã— (rows + 1)ï¼‰
        var_count = len(var_layouts)
        var_offset_arrays = cuda.device_array((var_count, rows + 1), dtype=np.int32)
        
        # ã€é‡è¦ä¿®æ­£ã€‘åˆæœŸåŒ–ã‚«ãƒ¼ãƒãƒ«ã®Grid sizeæœ€é©åŒ–
        @cuda.jit
        def init_var_offsets_optimized(offset_arrays, var_count, rows_plus_one):
            var_idx = cuda.grid(1)
            if var_idx < var_count:
                offset_arrays[var_idx, 0] = 0
        
        # Grid sizeæœ€é©åŒ–ï¼ˆæœ€å°64ãƒ–ãƒ­ãƒƒã‚¯ä¿è¨¼ï¼‰
        init_threads = min(256, var_count)
        init_blocks = max(64, (var_count + init_threads - 1) // init_threads)
        print(f"   ğŸ”§ å¯å¤‰é•·åˆæœŸåŒ–Gridæœ€é©åŒ–: var_count={var_count} â†’ blocks={init_blocks}, threads={init_threads}")
        
        if var_count > 0:
            init_var_offsets_optimized[init_blocks, init_threads](var_offset_arrays, var_count, rows + 1)
            cuda.synchronize()
            print(f"   âœ… å¯å¤‰é•·åˆæœŸåŒ–å®Œäº†: {init_blocks}ãƒ–ãƒ­ãƒƒã‚¯ä¸¦åˆ—å®Ÿè¡Œ")
        
        print(f"V7å¯å¤‰é•·çµ±åˆãƒãƒƒãƒ•ã‚¡ä½œæˆ: {var_count}åˆ—, çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º={total_size}ãƒã‚¤ãƒˆ")
        
        return var_data_buffer, var_offset_arrays
    
    def initialize_v7_buffers(self, columns, rows: int) -> V7BufferInfo:
        """V7çµ±åˆãƒãƒƒãƒ•ã‚¡ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆGrid sizeæœ€é©åŒ–ç‰ˆï¼‰"""
        
        print(f"\n=== V7åˆ—é †åºãƒ™ãƒ¼ã‚¹çµ±åˆãƒãƒƒãƒ•ã‚¡åˆæœŸåŒ–ï¼ˆGrid sizeæœ€é©åŒ–ï¼‰ ===")
        print(f"ç·åˆ—æ•°: {len(columns)}, ç·è¡Œæ•°: {rows:,}")
        
        # åˆ—åˆ†æ
        fixed_layouts, var_layouts = self.analyze_columns_v7(columns, rows)
        
        print(f"å›ºå®šé•·åˆ—: {len(fixed_layouts)}åˆ—")
        print(f"å¯å¤‰é•·åˆ—: {len(var_layouts)}åˆ—")
        
        # åˆ—ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é…åˆ—ä½œæˆ
        d_column_types, d_column_is_variable, d_column_indices = \
            self.create_column_metadata_arrays(columns)
        
        # å›ºå®šé•·åˆ—æƒ…å ±é…åˆ—ä½œæˆ
        d_fixed_offsets, d_fixed_sizes, d_fixed_scales = \
            self.create_fixed_metadata_arrays(fixed_layouts)
        
        # å¯å¤‰é•·åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
        d_var_mapping = self.create_var_column_mapping(columns, var_layouts)
        
        # ãƒãƒƒãƒ•ã‚¡ä½œæˆï¼ˆGrid sizeæœ€é©åŒ–ç‰ˆï¼‰
        fixed_buffer, row_stride = self.create_fixed_buffer_v7(fixed_layouts, rows)
        var_data_buffer, var_offset_arrays = self.create_variable_buffers_v7(var_layouts, rows)
        
        # V7çµ±åˆãƒãƒƒãƒ•ã‚¡æƒ…å ±
        self.v7_buffer_info = V7BufferInfo(
            fixed_buffer=fixed_buffer,
            row_stride=row_stride,
            fixed_layouts=fixed_layouts,
            var_data_buffer=var_data_buffer,
            var_offset_arrays=var_offset_arrays,
            var_layouts=var_layouts,
            column_types=d_column_types,
            column_is_variable=d_column_is_variable,
            column_indices=d_column_indices,
            fixed_column_offsets=d_fixed_offsets,
            fixed_column_sizes=d_fixed_sizes,
            fixed_decimal_scales=d_fixed_scales,
            var_column_mapping=d_var_mapping
        )
        
        print("V7çµ±åˆãƒãƒƒãƒ•ã‚¡åˆæœŸåŒ–å®Œäº†ï¼ˆGrid sizeæœ€é©åŒ–ï¼‰")
        return self.v7_buffer_info
    
    def extract_fixed_column_arrays_v7(self, v7_info: V7BufferInfo, rows: int) -> Dict[str, cuda.cudadrv.devicearray.DeviceNDArray]:
        """V7å›ºå®šé•·çµ±åˆãƒãƒƒãƒ•ã‚¡ã‹ã‚‰å€‹åˆ¥åˆ—ãƒãƒƒãƒ•ã‚¡ã‚’æŠ½å‡ºï¼ˆGrid sizeæœ€é©åŒ–ç‰ˆï¼‰"""
        extracted_buffers = {}
        
        for layout in v7_info.fixed_layouts:
            # GPUä¸Šã§ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            column_buffer = cuda.device_array(rows * layout.element_size, dtype=np.uint8)
            
            @cuda.jit
            def extract_v7_column_optimized(unified_buf, row_stride, col_offset, col_size, output_buf, num_rows):
                row = cuda.grid(1)
                if row >= num_rows:
                    return
                
                src_base = row * row_stride + col_offset
                dest_base = row * col_size
                
                for i in range(col_size):
                    if src_base + i < unified_buf.size and dest_base + i < output_buf.size:
                        output_buf[dest_base + i] = unified_buf[src_base + i]
            
            # ã€é‡è¦ä¿®æ­£ã€‘Grid sizeæœ€é©åŒ–ï¼ˆæœ€å°64ãƒ–ãƒ­ãƒƒã‚¯ä¿è¨¼ï¼‰
            threads = 256
            blocks = max(64, (rows + threads - 1) // threads)
            print(f"   ğŸ”§ åˆ—æŠ½å‡ºGridæœ€é©åŒ– {layout.name}: rows={rows} â†’ blocks={blocks}, threads={threads}")
            
            extract_v7_column_optimized[blocks, threads](
                v7_info.fixed_buffer, v7_info.row_stride,
                layout.buffer_offset, layout.element_size,
                column_buffer, rows
            )
            cuda.synchronize()
            print(f"   âœ… åˆ—æŠ½å‡ºå®Œäº† {layout.name}: {blocks}ãƒ–ãƒ­ãƒƒã‚¯ä¸¦åˆ—å®Ÿè¡Œ")
            
            extracted_buffers[layout.name] = column_buffer
        
        return extracted_buffers

__all__ = ["GPUMemoryManagerV7ColumnWise", "V7BufferInfo"]