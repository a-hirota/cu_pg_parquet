"""
CUDAカーネル定義とGPUデコード処理モジュール
"""

import numpy as np
from numba import cuda, njit
from typing import List, Dict, Any, Optional, Tuple
import math

# PostgreSQLバイナリデータ解析用のGPUカーネル
@cuda.jit
def parse_binary_format_kernel(chunk_array, field_offsets, field_lengths, rows_per_thread, num_cols, header_size_shared):
    """
    PostgreSQLバイナリデータを直接GPU上で解析するカーネル
    
    Args:
        chunk_array: バイナリデータ配列
        field_offsets: フィールド位置の出力配列
        field_lengths: フィールド長の出力配列
        rows_per_thread: 各スレッドが処理する行数
        num_cols: 1行あたりのカラム数
        header_size_shared: 共有メモリに保存されたヘッダーサイズ
    """
    # スレッドインデックスの計算
    thread_id = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x
    
    # ヘッダー処理（最初のスレッドのみ）
    if thread_id == 0:
        # "PGCOPY\n\377\r\n\0" (バイナリフォーマット識別子)
        if len(chunk_array) >= 11:
            if (chunk_array[0] == 80 and chunk_array[1] == 71):  # 'P', 'G'
                header_size = 11  # 基本ヘッダー長
                
                # フラグフィールドとヘッダー拡張をスキップ
                if len(chunk_array) >= header_size + 8:
                    header_size += 8  # フラグ(4バイト) + 拡張長(4バイト)
                    
                    # ヘッダー拡張長を取得
                    ext_len = ((int(chunk_array[header_size-4]) & 0xFF) << 24) | \
                              ((int(chunk_array[header_size-3]) & 0xFF) << 16) | \
                              ((int(chunk_array[header_size-2]) & 0xFF) << 8) | \
                              (int(chunk_array[header_size-1]) & 0xFF)
                    
                    if ext_len > 0 and len(chunk_array) >= header_size + ext_len:
                        header_size += ext_len
                
                # 共有メモリにヘッダーサイズを保存
                header_size_shared[0] = header_size
    
    # すべてのスレッドがヘッダーサイズを共有するために同期
    cuda.syncthreads()
    
    # ヘッダーサイズを取得
    header_size = header_size_shared[0]

    # まず全体の行数を計算（マスタースレッドのみ）
    # このアプローチは単純化のため - 実際の実装では並列化が必要
    if thread_id == 0:
        row_positions = cuda.local.array(shape=1024, dtype=np.int32)
        pos = header_size
        total_rows = 0
        
        # バイナリデータをスキャンして行位置を記録
        # より多くの行を処理できるように制限を緩和
        max_rows = 100000  # 10万行まで処理可能に拡張
        while pos < len(chunk_array) - 2 and total_rows < max_rows:
            # データの終端に達したかチェック
            if pos + 2 > len(chunk_array):
                break
                
            # タプルのフィールド数を取得
            num_fields = (chunk_array[pos] << 8) | chunk_array[pos + 1]
            
            # 終端マーカーをチェック
            if num_fields == 0xFFFF:  # 終端マーカー (-1)
                break
                
            # 有効なフィールド数をチェック
            if num_fields <= 0 or num_fields > 100:  # 妥当性チェック
                break
            
            # 行の位置を記録
            if total_rows < 1000:  # 配列サイズ制限
                row_positions[total_rows] = pos
                total_rows += 1
            
            # 次の行へ
            pos += 2  # フィールド数フィールドをスキップ
            
            # 各フィールドをスキップ
            for field_idx in range(num_fields):
                if pos + 4 > len(chunk_array):
                    break
                    
                # フィールド長を取得（ビッグエンディアン）
                field_len = ((chunk_array[pos] & 0xFF) << 24) | \
                            ((chunk_array[pos+1] & 0xFF) << 16) | \
                            ((chunk_array[pos+2] & 0xFF) << 8) | \
                            (chunk_array[pos+3] & 0xFF)
                pos += 4
                
                # -1 (NULL)なら続行、それ以外はフィールド長分スキップ
                if field_len != -1 and field_len >= 0:
                    pos += field_len
    
        # 共有メモリに総行数を保存
        header_size_shared[1] = total_rows
        
        # 行位置を共有メモリに保存（最大100行まで）
        for i in range(min(total_rows, 100)):
            header_size_shared[2 + i] = row_positions[i]
    
    # すべてのスレッドが行位置データを共有するために同期
    cuda.syncthreads()
    
    # 総行数を取得
    total_rows = header_size_shared[1]
    
    # スレッドあたりの処理行数を計算
    if total_rows > 0:
        # スレッド間で行を分配
        rows_per_thread_actual = max(1, (total_rows + cuda.blockDim.x * cuda.gridDim.x - 1) // (cuda.blockDim.x * cuda.gridDim.x))
        start_row = thread_id * rows_per_thread_actual
        end_row = min(start_row + rows_per_thread_actual, total_rows)
        
        # 担当する行を処理
        for row_idx in range(start_row, end_row):
            if row_idx >= total_rows:
                break
                
            # 行位置を取得（最初の100行のみ共有メモリから取得可能）
            if row_idx < 100:
                pos = header_size_shared[2 + row_idx]
            else:
                # 100行以降は処理しない（簡略化のため）
                continue
            
            # タプルのフィールド数を取得
            num_fields = (chunk_array[pos] << 8) | chunk_array[pos + 1]
            pos += 2
            
            # 終端マーカーをチェック
            if num_fields == 0xFFFF:
                continue
                
            # フィールド数が期待と異なる場合は処理しない
            if num_fields != num_cols:
                continue
            
            # 各フィールドの位置と長さを記録
            for field_idx in range(num_fields):
                if pos + 4 > len(chunk_array):
                    break
                    
                # フィールド長を取得（ビッグエンディアン）
                b0 = chunk_array[pos]
                b1 = chunk_array[pos+1]
                b2 = chunk_array[pos+2]
                b3 = chunk_array[pos+3]
                field_len = ((b0 & 0xFF) << 24) | ((b1 & 0xFF) << 16) | \
                             ((b2 & 0xFF) << 8) | (b3 & 0xFF)
                
                # インデックス計算
                out_idx = row_idx * num_cols + field_idx
                
                # 配列範囲チェック
                if out_idx < len(field_offsets):
                    # オフセットと長さを記録
                    field_offsets[out_idx] = pos + 4 if field_len != -1 else 0
                    field_lengths[out_idx] = field_len
                
                pos += 4  # 長さフィールドをスキップ
                
                # NULLでない場合はデータ部分もスキップ
                if field_len != -1 and field_len >= 0:
                    pos += field_len

@cuda.jit(device=True)
def check_bounds(data, pos, size):
    """境界チェック"""
    return pos >= 0 and pos + size <= len(data)

@cuda.jit(device=True)
def decode_int16(data, pos):
    """2バイト整数のデコード（ビッグエンディアン）"""
    if not check_bounds(data, pos, 2):
        return 0
    
    # バイトを取得
    b0 = data[pos]
    b1 = data[pos + 1]
    
    # ビッグエンディアンからリトルエンディアンに変換
    val = ((b0 & 0xFF) << 8) | (b1 & 0xFF)
    
    # 符号付き16ビット整数に変換
    if val & 0x8000:  # 最上位ビットが1なら負の数
        val = -(((~val) + 1) & 0xFFFF)
    
    return val

@cuda.jit(device=True)
def decode_int32(data, pos):
    """4バイト整数のデコード（ビッグエンディアン）"""
    if not check_bounds(data, pos, 4):
        return 0
    
    # バイトを取得
    b0 = data[pos]
    b1 = data[pos + 1]
    b2 = data[pos + 2]
    b3 = data[pos + 3]
    
    # ビッグエンディアンからリトルエンディアンに変換
    val = ((b0 & 0xFF) << 24) | ((b1 & 0xFF) << 16) | ((b2 & 0xFF) << 8) | (b3 & 0xFF)
    
    # 符号付き32ビット整数に変換
    if val & 0x80000000:  # 最上位ビットが1なら負の数
        val = -(((~val) + 1) & 0xFFFFFFFF)
    
    return val

@cuda.jit(device=True)
def decode_numeric_postgres(data, pos, hi_out, lo_out, scale_out, row_idx):
    """PostgreSQLのnumeric型を128ビット固定小数点数に変換"""
    if not check_bounds(data, pos, 8):  # 少なくともヘッダー部分があるか
        hi_out[row_idx] = 0
        lo_out[row_idx] = 0
        scale_out[0] = 0
        return
    
    # ヘッダー情報の取得
    ndigits = decode_int16(data, pos)
    weight = decode_int16(data, pos + 2)
    sign = decode_int16(data, pos + 4)
    dscale = decode_int16(data, pos + 6)
    
    # データの妥当性チェック
    if ndigits < 0 or ndigits > 100 or dscale < 0 or dscale > 100:
        hi_out[row_idx] = 0
        lo_out[row_idx] = 0
        scale_out[0] = 0
        return
    
    # 必要なバイト数をチェック
    if not check_bounds(data, pos + 8, ndigits * 2):
        hi_out[row_idx] = 0
        lo_out[row_idx] = 0
        scale_out[0] = 0
        return
    
    # 128ビット整数に変換
    hi = 0
    lo = 0
    
    # 各桁を処理
    digit_pos = pos + 8
    scale = 0
    
    for i in range(ndigits):
        digit = decode_int16(data, digit_pos + i * 2)
        if digit < 0 or digit > 9999:  # 不正な桁
            continue
            
        # 既存の値を10000倍して新しい桁を加算
        hi_old = hi
        lo_old = lo
        
        # 10000倍
        lo = lo_old * 10000
        hi = hi_old * 10000 + (lo_old >> 32) * 10000
        
        # 桁を加算
        lo += digit
        if lo < lo_old:  # 桁上がり
            hi += 1
        
        # スケールの更新
        scale = max(scale, dscale)
    
    # 符号の適用
    if sign == 0x4000:  # 負の数
        if lo == 0:
            hi = -hi
        else:
            lo = ~lo + 1
            hi = ~hi
            if lo == 0:
                hi += 1
    
    # 結果の格納
    scale_out[0] = scale
    hi_out[row_idx] = hi
    lo_out[row_idx] = lo

@cuda.jit(device=True)
def bulk_copy_64bytes(src, src_pos, dst, dst_pos, size):
    """64バイト単位でのバルクコピー"""
    if size > 64:
        size = 64
    
    # 8バイトずつコピー
    for i in range(0, size, 8):
        if i + 8 <= size:
            # 8バイトを一度に読み書き
            val = 0
            for j in range(8):
                val = (val << 8) | src[src_pos + i + j]
            
            # 8バイトを一度に書き込み
            for j in range(8):
                dst[dst_pos + i + j] = (val >> ((7-j) * 8)) & 0xFF
        else:
            # 残りのバイトを1バイトずつコピー
            for j in range(size - i):
                dst[dst_pos + i + j] = src[src_pos + i + j]

@cuda.jit
def decode_all_columns_kernel(raw_data, field_offsets, field_lengths,
                            int_outputs, num_hi_output, num_lo_output, num_scale_output,
                            str_outputs, str_null_pos, str_offsets,
                            col_types, col_lengths, chunk_size, num_cols):
    """全カラムを一度に処理する統合カーネル（累積オフセット方式）"""
    # スレッドインデックスの計算を改善
    thread_id = cuda.threadIdx.x
    block_id = cuda.blockIdx.x
    block_size = cuda.blockDim.x
    grid_size = cuda.gridDim.x
    
    # グリッド内の絶対位置を計算
    row = block_id * block_size + thread_id
    
    # ストライド処理を追加
    stride = block_size * grid_size
    while row < chunk_size:
        for col in range(num_cols):
            # フィールドオフセットとデータ長を取得
            field_idx = row * num_cols + col
            if field_idx >= len(field_offsets):
                return
                
            pos = field_offsets[field_idx]
            length = field_lengths[field_idx]
            
            if col_types[col] <= 1:  # 数値型
                if length == -1:  # NULL値
                    int_outputs[col * chunk_size + row] = 0
                else:
                    if col_types[col] == 0:  # integer
                        val = decode_int32(raw_data, pos)
                        int_outputs[col * chunk_size + row] = val
                    else:  # numeric/decimal
                        # PostgreSQLのnumeric型を128ビット固定小数点数として処理
                        decode_numeric_postgres(raw_data, pos,
                                             num_hi_output[col * chunk_size:],
                                             num_lo_output[col * chunk_size:],
                                             num_scale_output[col:col + 1],
                                             row)
            else:  # 文字列型
                max_length = col_lengths[col]
                
                # 文字列カラムのインデックスを計算
                str_col_idx = 0
                for i in range(col):
                    if col_types[i] == 2:  # 文字列型
                        str_col_idx += 1
                
                # 文字列バッファの位置を計算（累積オフセット方式）
                buffer_offset = str_offsets[str_col_idx]
                dst_pos = buffer_offset + row * max_length
                
                if length == -1:  # NULL値
                    str_null_pos[str_col_idx * chunk_size + row] = 0
                    continue
                    
                # 文字列データのコピー
                valid_length = min(length, max_length)
                
                # バルクコピーを使用
                for i in range(0, valid_length, 64):
                    copy_size = min(64, valid_length - i)
                    bulk_copy_64bytes(raw_data, pos + i, str_outputs, dst_pos + i, copy_size)
                
                # 残りのバイトをゼロクリア
                for i in range(valid_length, max_length):
                    str_outputs[dst_pos + i] = 0
                
                # 文字列の有効範囲を設定（カラムごとに独立した位置）
                str_null_pos[str_col_idx * chunk_size + row] = valid_length
        
        # 次の行へ
        row += stride

class GPUDecoder:
    """GPU上でのデコード処理を管理するクラス"""
    
    def __init__(self):
        """初期化"""
        pass
    
    def parse_binary_data(self, chunk_array, rows_in_chunk, num_cols):
        """
        PostgreSQLバイナリデータをGPUで解析する
        
        Args:
            chunk_array: バイナリデータ配列 (numpyバイト配列)
            rows_in_chunk: 予想される行数 (エラー検出用)
            num_cols: 1行あたりのカラム数
            
        Returns:
            field_offsets: フィールド位置の配列
            field_lengths: フィールド長の配列
            actual_rows: 実際に解析できた行数
        """
        try:
            print(f"GPUでバイナリデータ解析を開始: {len(chunk_array)}バイト、予想行数={rows_in_chunk}、列数={num_cols}")
            
            # フィールドオフセットと長さの配列を確保（データ型はint32）
            total_fields = rows_in_chunk * num_cols
            d_field_offsets = cuda.device_array(total_fields, dtype=np.int32)
            d_field_lengths = cuda.device_array(total_fields, dtype=np.int32)
            
            # チャンク配列をGPUに転送
            d_chunk_array = cuda.to_device(chunk_array)
            
            # スレッド数とブロック数を決定
            # 1つのスレッドがいくつかの行を担当
            threads_per_block = 256
            rows_per_thread = max(1, (rows_in_chunk + 1023) // 1024)  # 最大1024スレッドで全行を処理
            blocks = min(1024, math.ceil(rows_in_chunk / rows_per_thread / threads_per_block))
            
            print(f"バイナリデータ解析: スレッド/ブロック={threads_per_block}、ブロック数={blocks}、スレッドあたり行数={rows_per_thread}")
            
            # 共有メモリの確保（ヘッダーサイズと行位置情報用）
            header_shared_size = 2 + 100  # ヘッダーサイズ + 総行数 + 最大100行の位置
            d_header_shared = cuda.device_array(header_shared_size, dtype=np.int32)
            
            # パースカーネルを起動
            parse_binary_format_kernel[blocks, threads_per_block](
                d_chunk_array, d_field_offsets, d_field_lengths, rows_per_thread, num_cols, d_header_shared
            )
            
            # 結果をホストにコピー
            field_offsets = d_field_offsets.copy_to_host()
            field_lengths = d_field_lengths.copy_to_host()
            
            # リソース解放
            del d_chunk_array
            del d_field_offsets
            del d_field_lengths
            cuda.synchronize()
            
            # フィールド数からユニークな行数を計算
            actual_rows = total_fields // num_cols
            
            # エラーチェック - 後半部分が全て 0 なら、実際の行数を調整
            # 実際にパースされた行数を検出
            valid_row = 0
            for r in range(actual_rows-1, -1, -1):
                row_start = r * num_cols
                if any(field_offsets[row_start:row_start+num_cols] != 0):
                    valid_row = r + 1
                    break
                    
            actual_rows = valid_row
            print(f"バイナリデータ解析完了: 解析された行数={actual_rows}")
            
            return field_offsets, field_lengths, actual_rows
            
        except Exception as e:
            print(f"GPUバイナリ解析中にエラー: {e}")
            # エラー時は空の配列を返す
            return np.array([], dtype=np.int32), np.array([], dtype=np.int32), 0
    
    def decode_chunk(self, buffers, chunk_array, field_offsets, field_lengths, rows_in_chunk, columns):
        """チャンクをデコードする
        
        Args:
            buffers: GPUバッファ辞書
            chunk_array: バイナリデータ配列
            field_offsets: フィールドオフセット配列
            field_lengths: フィールド長配列
            rows_in_chunk: チャンク内の行数
            columns: カラム情報リスト
            
        Returns:
            デコード結果
        """
        num_cols = len(columns)
        
        # 転送前にすべての変数を初期化（解放処理のため）
        d_chunk = None
        d_offsets = None
        d_lengths = None
        d_col_types = None
        d_col_lengths = None
        
        try:
            # メモリ転送前のGPUメモリ状態を確認
            try:
                mem_info = cuda.current_context().get_memory_info()
                print(f"メモリ使用量 (転送前): {mem_info[0]} / {mem_info[1]} バイト")
            except Exception as e:
                print(f"メモリ情報取得エラー: {e}")
            
            # デバイスに転送（通常はmemory_managerで行うが、ここではシンプルに直接処理）
            d_chunk = cuda.to_device(chunk_array)
            d_offsets = cuda.to_device(field_offsets)
            d_lengths = cuda.to_device(field_lengths)
            cuda.synchronize()  # メモリ転送の完了を待つ
            
            # メモリ転送後のGPUメモリ状態を確認
            try:
                mem_info = cuda.current_context().get_memory_info()
                print(f"メモリ使用量 (転送後): {mem_info[0]} / {mem_info[1]} バイト")
            except Exception as e:
                print(f"メモリ情報取得エラー: {e}")
            
            # バッファの取得
            int_buffer = buffers["int_buffer"]
            num_hi_output = buffers["num_hi_output"]
            num_lo_output = buffers["num_lo_output"]
            num_scale_output = buffers["num_scale_output"]
            str_buffer = buffers["str_buffer"]
            str_null_pos = buffers["str_null_pos"]
            d_str_offsets = buffers["d_str_offsets"]
            col_types = buffers["col_types"]
            col_lengths = buffers["col_lengths"]
            
            # デバイスに転送
            d_col_types = cuda.to_device(col_types)
            d_col_lengths = cuda.to_device(col_lengths)
            
            # スレッド数とブロック数の調整
            threads_per_block = 256  # 固定スレッド数
            blocks = min(
                1024,  # ブロック数の制限を緩和
                max(128, (rows_in_chunk + threads_per_block - 1) // threads_per_block)  # 最小128ブロック
            )
            print(f"Using {blocks} blocks with {threads_per_block} threads per block")
                
            # 統合カーネルの起動
            decode_all_columns_kernel[blocks, threads_per_block](
                d_chunk, d_offsets, d_lengths,
                int_buffer, num_hi_output, num_lo_output, num_scale_output,
                str_buffer, str_null_pos, d_str_offsets,
                d_col_types, d_col_lengths,
                rows_in_chunk, num_cols
            )
            
            # 結果を取得するための一時辞書
            results = {}
            
            # 結果の回収
            int_col_idx = 0
            str_col_idx = 0
            
            for i, col in enumerate(columns):
                col_type = col_types[i]
                if col_type <= 1:  # 数値型（integer or numeric）
                    if col_type == 0:  # integer
                        if int_buffer is not None:
                            host_array = np.empty(rows_in_chunk, dtype=np.int32)
                            int_buffer[int_col_idx * rows_in_chunk:(int_col_idx + 1) * rows_in_chunk].copy_to_host(host_array)
                            results[col.name] = host_array
                            int_col_idx += 1
                    else:  # numeric
                        if num_hi_output is not None and num_lo_output is not None:
                            host_hi = np.empty(rows_in_chunk, dtype=np.int64)
                            host_lo = np.empty(rows_in_chunk, dtype=np.int64)
                            host_scale = np.empty(1, dtype=np.int32)
                            
                            num_hi_output[int_col_idx * rows_in_chunk:(int_col_idx + 1) * rows_in_chunk].copy_to_host(host_hi)
                            num_lo_output[int_col_idx * rows_in_chunk:(int_col_idx + 1) * rows_in_chunk].copy_to_host(host_lo)
                            num_scale_output[int_col_idx:int_col_idx + 1].copy_to_host(host_scale)
                            
                            values = []
                            for j in range(rows_in_chunk):
                                hi = host_hi[j]
                                lo = host_lo[j]
                                scale = host_scale[0]
                                
                                if hi == 0 and lo >= 0:
                                    value = float(lo) / (10 ** scale) if scale > 0 else float(lo)
                                elif hi == -1 and lo < 0:
                                    value = float(lo) / (10 ** scale) if scale > 0 else float(lo)
                                else:
                                    value = f"[{hi},{lo}]@{scale}"
                                
                                values.append(value)
                            
                            results[col.name] = values
                            int_col_idx += 1
                else:  # 文字列型
                    if str_buffer is not None and str_null_pos is not None:
                        length = col_lengths[i]
                        
                        # ホスト側でオフセット値を取得
                        host_offsets = np.empty(len(d_str_offsets), dtype=np.int32)
                        d_str_offsets.copy_to_host(host_offsets)
                        
                        str_start = host_offsets[str_col_idx]
                        str_end = str_start + (rows_in_chunk * length)
                        
                        # 文字列バッファ部分のコピー
                        host_str_array = np.empty(rows_in_chunk * length, dtype=np.uint8)
                        str_buffer[str_start:str_
