# PostgreSQL â†’ GPU ç›´æ¥ã‚³ãƒ”ãƒ¼å®Ÿè£…ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

æœ¬å®Ÿè£…ã¯ã€PostgreSQL ã‹ã‚‰ã€Œãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµŒç”±ã›ãš GPU ãƒãƒƒãƒ•ã‚¡ã¸ç›´æ¥ã‚³ãƒ”ãƒ¼ã€ã™ã‚‹æ‰‹æ³•ã‚’æä¾›ã—ã¾ã™ã€‚

## âš ï¸ CPU100%å¼µã‚Šä»˜ãå•é¡Œã¨è§£æ±ºæ–¹æ³•

**å•é¡Œ**: å¾“æ¥ã® `b"".join(chunks)` ã‚„ `BytesIO` æ–¹å¼ã§ã¯ã€å¤§é‡ã®å°ã•ãªãƒãƒ£ãƒ³ã‚¯ï¼ˆ10ä¸‡å€‹ä»¥ä¸Šï¼‰å‡¦ç†æ™‚ã« **CPU100%å¼µã‚Šä»˜ãã€GPUã¯0%å¾…æ©Ÿ** ãŒç™ºç”Ÿ

**æ ¹æœ¬åŸå› **:
- Python ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
- åŒæœŸçš„ãªãƒ›ã‚¹ãƒˆâ†’GPUè»¢é€ã§CPUãƒ–ãƒ­ãƒƒã‚¯
- pageable ãƒ¡ãƒ¢ãƒªã«ã‚ˆã‚‹DMAåŠ¹ç‡ä½ä¸‹

**è§£æ±ºæ–¹æ³•ï¼ˆ2æ®µéšï¼‰**:
1. **Pinned + éåŒæœŸè»¢é€**: CPUä½¿ç”¨ç‡ã‚’1æ¡%ã¾ã§å‰Šæ¸›ã€10GB/sé”æˆ
2. **NVMe + GPUDirect Storage**: CPUä½¿ç”¨ç‡ã‚’æ•°%ä»¥ä¸‹ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¸¯åŸŸã‚’ãã®ã¾ã¾GPUã«

## âš ï¸ é‡è¦ï¼šRMM API å¤‰æ›´ã«ã¤ã„ã¦

**RMM 25.xç³»ã§ `DeviceBuffer.copy_from_host` ã®ã‚·ã‚°ãƒãƒãƒ£ãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸ**

- **RMM 21.xä»¥å‰**: `copy_from_host(buffer, dst_offset=0, stream=None)`
- **RMM 25.xä»¥é™**: `copy_from_host(host_bytes, stream=None)` â€» `dst_offset` å‰Šé™¤

### ä¸»ãªç‰¹å¾´

- **ã‚¼ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« I/O**: ãƒ‡ã‚£ã‚¹ã‚¯ã‚’çµŒç”±ã›ãšã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯â†’GPUãƒ¡ãƒ¢ãƒªã¸ç›´æ¥è»¢é€
- **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†**: `psycopg3.copy()` ã§ãƒãƒ£ãƒ³ã‚¯ã‚’é€æ¬¡å—ã‘å–ã‚Šã€`cuda.cudadrv.driver.memcpy_htod()` ã§ GPU å´ã«ç›´æ¥æ›¸ãè¾¼ã¿
- **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: ãƒ›ã‚¹ãƒˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æœ€å°åŒ–ï¼ˆãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®ã¿ï¼‰
- **é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸå¹…ã®ã¿ãŒå¾‹é€Ÿè¦å› 

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
PostgreSQL COPY BINARY
        â†“ (chunks)
   psycopg3.copy()
        â†“ (buffer)
rmm.DeviceBuffer.copy_from_host()
        â†“ (offset++)
      GPU Memory
        â†“ (optional)
   kvikio.CuFile.pwrite()
        â†“
    Direct Storage
```

## å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«

### 1. `benchmark/benchmark_single_copy.py` â­**æ¨å¥¨**
**ãƒãƒƒãƒ•ã‚¡1å›ã‚³ãƒ”ãƒ¼æ–¹å¼**: æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ã‹ã¤é«˜åŠ¹ç‡

- RMM 25.x æ­£ã—ã„APIä½¿ç”¨: `copy_from_host(host_bytes)` ä½ç½®å¼•æ•°1å€‹ã®ã¿
- CPUä½¿ç”¨ç‡æœ€å°åŒ–: è¤‡é›‘ãªã‚ªãƒ•ã‚»ãƒƒãƒˆå‡¦ç†ãªã—
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: ä¸€æ™‚çš„ã«å…¨ãƒ‡ãƒ¼ã‚¿åé›†å¾Œã€1å›ã§GPUè»¢é€
- ã‚¨ãƒ©ãƒ¼å›é¿: TypeErrorå®Œå…¨è§£æ±º

### 2. `benchmark/simple_direct_gpu_copy.py`
ã‚·ãƒ³ãƒ—ãƒ«ãªé€æ¬¡ã‚³ãƒ”ãƒ¼ç‰ˆï¼ˆä¿®æ­£æ¸ˆã¿ï¼‰

```python
import psycopg, rmm

# ãƒãƒƒãƒ•ã‚¡1å›ã‚³ãƒ”ãƒ¼æ–¹å¼ï¼ˆæ¨å¥¨ï¼‰
with psycopg.connect("dbname=bench") as conn:
    with conn.cursor() as cur:
        with cur.copy("COPY lineorder TO STDOUT (FORMAT BINARY)") as copy:
            # å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’åé›†
            chunks = []
            for chunk in copy:
                chunks.append(chunk)
            
            # ä¸€æ‹¬çµåˆ
            host_bytes = b"".join(chunks)

# GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ & 1å›ã‚³ãƒ”ãƒ¼
dbuf = rmm.DeviceBuffer(size=len(host_bytes))
dbuf.copy_from_host(host_bytes)  # â˜… ä½ç½®å¼•æ•°1å€‹ã®ã¿ï¼ˆRMM 25.xæ­£è§£ï¼‰
```

### 3. `benchmark/benchmark_direct_gpu_copy.py`
é«˜æ©Ÿèƒ½ç‰ˆï¼ˆä¿®æ­£æ¸ˆã¿ï¼‰: GPUå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆ

### 4. `benchmark/benchmark_rmm_compatible.py`
RMMäº’æ›ç‰ˆ: ãƒãƒ¼ã‚¸ãƒ§ãƒ³è‡ªå‹•åˆ¤å®šã§æ—§ãƒ»æ–°APIä¸¡å¯¾å¿œ

## ä½¿ç”¨æ–¹æ³•

### ç’°å¢ƒè¨­å®š

```bash
# PostgreSQLæ¥ç¶šè¨­å®š
export GPUPASER_PG_DSN='dbname=postgres user=postgres host=localhost port=5432'

# Pythonç’°å¢ƒç¢ºèª
export PYTHONPATH=$PYTHONPATH:/home/ubuntu/gpupgparser
```

### åŸºæœ¬å®Ÿè¡Œ

```bash
# ğŸ† æœ€é«˜æ€§èƒ½: GDS + NVMeæ–¹å¼ï¼ˆNVMeã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¿…é ˆï¼‰
python benchmark/benchmark_gds_nvme.py --rows 50000000

# â­ æ¨å¥¨: Pinned + éåŒæœŸæ–¹å¼ï¼ˆCPU100%å•é¡Œè§£æ±ºï¼‰
python benchmark/benchmark_pinned_async.py --rows 50000000

# åŠ¹ç‡åŒ–ç‰ˆ: BytesIOä½¿ç”¨
python benchmark/benchmark_efficient_copy.py --rows 50000000

# ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ: å°ã•ãªãƒ‡ãƒ¼ã‚¿ç”¨
python benchmark/benchmark_single_copy.py --rows 1000000
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

```bash
# GDS ã‚µãƒãƒ¼ãƒˆç¢ºèª
python benchmark/benchmark_gds_nvme.py --check-gds

# GDS ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
python benchmark/benchmark_gds_nvme.py --benchmark-gds

# Pinned ãƒ¡ãƒ¢ãƒªè¨­å®šèª¿æ•´
python benchmark/benchmark_pinned_async.py --chunk-size 8 --rows 50000000

# ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ç¢ºèª
python benchmark/benchmark_pinned_async.py --info
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

```bash
# å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
python benchmark/simple_direct_gpu_copy.py --rows 50000000

# æ—¢å­˜å®Ÿè£…ã¨ã®æ¯”è¼ƒ
python benchmark/benchmark_lineorder_5m.py --rows 50000000  # å¾“æ¥ç‰ˆ
python benchmark/benchmark_direct_gpu_copy.py --rows 50000000  # GPUç›´æ¥ç‰ˆ
```

## æŠ€è¡“è©³ç´°

### ãƒ¡ãƒ¢ãƒªç®¡ç†

```python
# RMM GPU ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–
rmm.reinitialize(pool_allocator=True, initial_pool_size=8*1024**3)  # 8GB

# ãƒãƒƒãƒ•ã‚¡1å›ã‚³ãƒ”ãƒ¼æ–¹å¼ï¼ˆæ¨å¥¨ï¼‰
with conn.cursor().copy(copy_sql) as copy_obj:
    chunks = [chunk for chunk in copy_obj if chunk]
    host_bytes = b"".join(chunks)

# GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ & 1å›ã‚³ãƒ”ãƒ¼
dbuf = rmm.DeviceBuffer(size=len(host_bytes))
dbuf.copy_from_host(host_bytes)  # ä½ç½®å¼•æ•°1å€‹ã®ã¿
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
# ãƒãƒƒãƒ•ã‚¡ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–
if offset + chunk_size > dbuf.size:
    print("è­¦å‘Š: ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºä¸è¶³")
    break

# GPU ãƒ¡ãƒ¢ãƒªä¸è¶³å¯¾ç­–
try:
    dbuf = rmm.DeviceBuffer(size=buffer_size)
except Exception as e:
    print(f"GPU ãƒãƒƒãƒ•ã‚¡ç¢ºä¿ã‚¨ãƒ©ãƒ¼: {e}")
```

### CuFile çµ±åˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

```python
from kvikio import CuFile

# GPU ãƒãƒƒãƒ•ã‚¡ã‚’ç›´æ¥ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜
with CuFile(output_path, 'w') as f:
    f.pwrite(dbuf)
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

### å¾“æ¥æ–¹å¼ vs GPUç›´æ¥ã‚³ãƒ”ãƒ¼

| é …ç›® | å¾“æ¥æ–¹å¼ | GPUç›´æ¥ã‚³ãƒ”ãƒ¼ |
|------|----------|---------------|
| ãƒ›ã‚¹ãƒˆãƒ¡ãƒ¢ãƒª | å…¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®ã¿ |
| ãƒ‡ã‚£ã‚¹ã‚¯ I/O | ã‚ã‚Š | **ã‚¼ãƒ­** |
| GPUè»¢é€ | ä¸€æ‹¬è»¢é€ | **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°** |
| å¾‹é€Ÿè¦å›  | ãƒ‡ã‚£ã‚¹ã‚¯é€Ÿåº¦ | **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€Ÿåº¦** |

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¾‹

```
=== GPUç›´æ¥ã‚³ãƒ”ãƒ¼ç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº† ===
ç·æ™‚é–“ = 73.3532 ç§’
--- æ™‚é–“å†…è¨³ ---
  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—       : 0.0010 ç§’
  COPYâ†’GPUç›´æ¥æ›¸ãè¾¼ã¿: 68.9416 ç§’  â† ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¾‹é€Ÿ
  GPUãƒ‘ãƒ¼ã‚¹           : 1.0435 ç§’
  GPUãƒ‡ã‚³ãƒ¼ãƒ‰         : 0.4809 ç§’
  Parquetæ›¸ãè¾¼ã¿     : 0.2858 ç§’
--- æœ€é©åŒ–åŠ¹æœ ---
  âœ… ãƒ•ã‚¡ã‚¤ãƒ« I/O: å®Œå…¨ã‚¼ãƒ­ (ç›´æ¥GPUæ›¸ãè¾¼ã¿)
  âœ… ãƒ›ã‚¹ãƒˆãƒ¡ãƒ¢ãƒª: æœ€å°åŒ– (ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®ã¿)
  âœ… GPUè»¢é€: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### RMM API ã‚¨ãƒ©ãƒ¼ã®è§£æ±º

#### 1. `TypeError: copy_from_host() takes at least 1 positional argument (0 given)`

**åŸå› **: RMM 25.x ã§ `dst_offset` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚

**è§£æ±ºæ–¹æ³•**:
```bash
# RMMäº’æ›ç‰ˆã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
python benchmark/benchmark_rmm_compatible.py --rows 1000000

# ã¾ãŸã¯æ‰‹å‹•ã§ä¿®æ­£ç‰ˆã‚’ä½¿ç”¨
python benchmark/benchmark_direct_gpu_copy.py --rows 1000000
```

#### 2. ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªæ–¹æ³•

```python
import rmm, inspect
print(f"RMM ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {rmm.__version__}")
sig = inspect.signature(rmm.DeviceBuffer.copy_from_host)
print(f"copy_from_host ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {list(sig.parameters.keys())}")
```

#### 3. API å¤‰æ›´å¯¾å¿œè¡¨

| RMM ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | copy_from_host | ã‚ªãƒ•ã‚»ãƒƒãƒˆæŒ‡å®š |
|---------------|----------------|---------------|
| 21.xä»¥å‰ | `copy_from_host(buffer, dst_offset=0)` | âœ… ã‚µãƒãƒ¼ãƒˆ |
| 25.xä»¥é™ | `copy_from_host(host_bytes)` | âŒ å‰Šé™¤ â†’ Numba Driverä½¿ç”¨ |

### ã‚ˆãã‚ã‚‹å•é¡Œ

1. **RMMåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼**
   ```bash
   # CUDAç’°å¢ƒç¢ºèª
   nvidia-smi
   python -c "from numba import cuda; print(cuda.current_context())"
   ```

2. **GPU ãƒ¡ãƒ¢ãƒªä¸è¶³**
   ```python
   # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’èª¿æ•´
   buffer_size = header_bytes + rows_est * row_bytes_conservative
   ```

3. **psycopg3 æ¥ç¶šã‚¨ãƒ©ãƒ¼**
   ```bash
   # æ¥ç¶šæ–‡å­—åˆ—ç¢ºèª
   echo $GPUPASER_PG_DSN
   psql "$GPUPASER_PG_DSN" -c "SELECT 1"
   ```

4. **Numba CUDA Driver ã‚¨ãƒ©ãƒ¼**
   ```python
   # CUDA ãƒ‰ãƒ©ã‚¤ãƒç¢ºèª
   from numba import cuda
   try:
       cuda.cudadrv.driver.memcpy_htod(0, b"test", 4)
   except Exception as e:
       print(f"CUDA Driver ã‚¨ãƒ©ãƒ¼: {e}")
   ```

### ãƒ‡ãƒãƒƒã‚°æ‰‹é †

1. **åŸºæœ¬æ¥ç¶šãƒ†ã‚¹ãƒˆ**
   ```python
   python benchmark/simple_direct_gpu_copy.py --rows 1000
   ```

2. **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª**
   ```bash
   nvidia-smi
   watch -n1 nvidia-smi  # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
   ```

3. **ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºèª¿æ•´**
   ```python
   # copy() ã®ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã¯ psycopg3 ãŒè‡ªå‹•èª¿æ•´
   # å¤§ããªãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯é€²æ—è¡¨ç¤ºã§ç¢ºèª
   ```

## å¿œç”¨ä¾‹

### 1. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```python
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ â†’ GPU â†’ æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«
dbuf = direct_gpu_copy(table_name)
gpu_array = cuda.as_cuda_array(dbuf)
results = gpu_ml_model(gpu_array)
```

### 2. é«˜é€Ÿãƒ‡ãƒ¼ã‚¿ç§»è¡Œ

```python
# å¤§è¦æ¨¡ãƒ†ãƒ¼ãƒ–ãƒ«ã® GPU å´ã¸ã®ç§»è¡Œ
for table in tables:
    dbuf = direct_gpu_copy(table)
    save_to_cufile(dbuf, f"gpu_storage/{table}.bin")
```

### 3. åˆ†æ•£å‡¦ç†

```python
# è¤‡æ•° GPU ã¸ã®åˆ†æ•£æ›¸ãè¾¼ã¿
with cuda.gpus[0]:
    dbuf0 = direct_gpu_copy(table, offset=0, limit=N//2)
with cuda.gpus[1]:
    dbuf1 = direct_gpu_copy(table, offset=N//2, limit=N//2)
```

## å‚è€ƒè³‡æ–™

- [psycopg3 COPY documentation](https://www.psycopg.org/psycopg3/docs/basic/copy.html)
- [RMM (RAPIDS Memory Manager)](https://github.com/rapidsai/rmm)
- [kvikio (CuFile Python wrapper)](https://github.com/rapidsai/kvikio)
- [PostgreSQL COPY BINARY format](https://www.postgresql.org/docs/current/sql-copy.html)