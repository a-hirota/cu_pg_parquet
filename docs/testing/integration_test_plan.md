# GPU PostgreSQL Parser 統合テスト計画

## 1. 概要

### 1.1 目的
本ドキュメントは、GPU PostgreSQL Parser (gpupgparser) システムの包括的な統合テスト計画を定義します。各処理段階を独立して検証し、エンドツーエンドのパイプライン全体を検証することを目的としています。

### 1.2 処理フローアーキテクチャ
```
[PostgreSQL] → [Queue(/dev/shm)] → [GPU Memory] → [Column Arrays] → [cuDF DataFrame] → [Parquet File]
           ↑                    ↑              ↑                  ↑                    ↑
      Process 1           Process 2       Process 3         Process 4           Process 5
   (バイナリ抽出)      (GPU転送)       (CUDA解析)      (DataFrame変換)    (ファイル出力)
```

### 1.3 テストカテゴリ
- **機能テスト**: 各プロセスを独立して検証
- **データ型テスト**: PostgreSQL型の包括的カバレッジ
- **境界値テスト**: エッジケースと制限値
- **性能テスト**: スループットとリソース使用
- **統合テスト**: プロセス間の相互作用とデータフロー
- **信頼性テスト**: エラーハンドリングとリカバリ

## 2. 機能別テストケース

### 2.1 Process 1: PostgreSQLバイナリ抽出テスト

#### 基本機能
```yaml
TC1-1: 小規模テーブル抽出
  入力: 100行のテーブル、基本データ型
  処理: COPY BINARYプロトコル抽出
  検証: バイナリ形式の正確性、行数確認

TC1-2: 大規模テーブルストリーミング
  入力: 10GBテーブル、チャンク読み込み
  処理: 64MBチャンクでのストリーミング
  検証: メモリ使用量の安定性、データ損失なし

TC1-3: 接続レジリエンス
  入力: ネットワーク中断のシミュレーション
  処理: リトライロジックと再接続
  検証: 正常な復旧、データ整合性
```

#### キュー管理
```yaml
TC1-4: キュー容量処理
  入力: /dev/shm容量を超えるデータ
  処理: プロデューサー・コンシューマー協調
  検証: 適切なブロッキング、オーバーフローなし

TC1-5: マルチテーブル並行抽出
  入力: 5テーブルの同時処理
  処理: 並列抽出スレッド
  検証: キューの分離、データ混在なし
```

### 2.2 Process 2: GPUメモリ転送テスト

#### kvikio転送テスト
```yaml
TC2-1: ファイルからGPUへの直接転送
  入力: /dev/shmの1GBバイナリファイル
  処理: kvikio.read()でGPUメモリへ転送
  検証: MD5チェックサム一致、ゼロコピー確認

TC2-2: マルチGPU並列転送
  入力: 4データチャンク、4GPU
  処理: 並行kvikio転送
  検証: GPU割り当て、メモリ競合なし

TC2-3: GPUメモリ圧迫時の処理
  入力: GPUメモリの80%を超えるデータ
  処理: メモリ監視付き転送
  検証: 適切な処理、必要時のホストへのスピル
```

#### メモリ管理
```yaml
TC2-4: メモリプール割り当て
  入力: 繰り返し割り当て/解放
  処理: RMMプール使用
  検証: フラグメンテーションなし、安定した性能

TC2-5: メモリ不足からの回復
  入力: GPUメモリを超える割り当て
  処理: エラーハンドリングとクリーンアップ
  検証: クリーンな回復、メモリリークなし
```

### 2.3 Process 3: CUDA解析テスト

#### 固定長データ型
```yaml
TC3-1: 整数型 (INT2/4/8)
  入力: MIN_VALUE, -1, 0, 1, MAX_VALUE, NULL
  処理: parse_int_column カーネル
  検証: 正確な値の一致、オーバーフロー検出

TC3-2: 浮動小数点 (FLOAT4/8)
  入力: -Inf, -1.0, 0.0, 1.0, +Inf, NaN, NULL
  処理: parse_float_column カーネル
  検証: IEEE 754準拠、特殊値

TC3-3: ブール型
  入力: true, false, NULLパターン
  処理: parse_bool_column カーネル
  検証: ビット効率、nullビットマップ

TC3-4: 時刻型 (DATE/TIME/TIMESTAMP)
  入力: エポック、現在、未来の日付、タイムゾーン
  処理: parse_temporal_column カーネル
  検証: マイクロ秒精度、範囲制限
```

#### 可変長データ型
```yaml
TC3-5: TEXT/VARCHAR
  入力: 空文字、ASCII、UTF-8、最大長文字列
  処理: parse_text_column カーネル
  検証: エンコーディング保持、長さの正確性

TC3-6: BYTEAバイナリデータ
  入力: 0バイトから1GBのバイナリデータ
  処理: parse_bytea_column カーネル
  検証: バイナリ整合性、サイズ処理

TC3-7: 配列型
  入力: 空配列、1次元、多次元配列
  処理: parse_array_column カーネル
  検証: 次元追跡、要素アクセス

TC3-8: JSON/JSONB
  入力: オブジェクト、配列、ネストした構造
  処理: parse_json_column カーネル
  検証: 構造保持、キー順序
```

### 2.4 Process 4: DataFrame変換テスト

```yaml
TC4-1: カラムアレイからcuDF Series
  入力: Process 3からの解析済みカラムアレイ
  処理: cudf.Series構築
  検証: データ型マッピング、nullマスク

TC4-2: マルチカラムDataFrame組み立て
  入力: 混合型の100カラム
  処理: DataFrame作成
  検証: カラム整列、メモリレイアウト

TC4-3: 大規模DataFrame処理
  入力: 1000万行 x 50カラム
  処理: チャンク化DataFrame作成
  検証: メモリ効率、フラグメンテーションなし
```

### 2.5 Process 5: Parquet出力テスト

```yaml
TC5-1: 圧縮アルゴリズム比較
  入力: 1GB DataFrame
  処理: SNAPPY, ZSTD, LZ4, GZIPで書き込み
  検証: サイズ削減、書き込み速度

TC5-2: パーティション出力
  入力: 日付/カテゴリカラムを持つDataFrame
  処理: カラムによるパーティション
  検証: ディレクトリ構造、ファイル分散

TC5-3: スキーマ進化
  入力: 型変更のあるDataFrame
  処理: 追記モード書き込み
  検証: スキーマ互換性、型プロモーション
```

## 3. データ型境界値テストマトリックス

```yaml
データ型     | 最小値         | 最大値         | NULL | 特殊ケース
------------|----------------|----------------|------|---------------
SMALLINT    | -32,768        | 32,767         | ✓    | -
INTEGER     | -2,147,483,648 | 2,147,483,647  | ✓    | -
BIGINT      | -2^63          | 2^63-1         | ✓    | -
DECIMAL     | 131,072桁      | Scale 16,383   | ✓    | NaN, Infinity
REAL        | -3.4E+38       | 3.4E+38        | ✓    | NaN, ±Inf
DOUBLE      | -1.7E+308      | 1.7E+308       | ✓    | NaN, ±Inf
VARCHAR(n)  | ''             | n文字          | ✓    | Unicode, 絵文字
TEXT        | ''             | 1GB            | ✓    | 全UTF-8
BYTEA       | 0バイト        | 1GB            | ✓    | バイナリデータ
DATE        | 紀元前4713年   | 西暦5874897年  | ✓    | -
TIME        | 00:00:00       | 24:00:00       | ✓    | マイクロ秒
TIMESTAMP   | 紀元前4713年   | 西暦294276年   | ✓    | ±Infinity
BOOLEAN     | false          | true           | ✓    | -
ARRAY       | {}             | n次元          | ✓    | ネスト配列
JSON/JSONB  | null           | 1GBネスト      | ✓    | 深いネスト
```

## 4. 性能テストシナリオ

### 4.1 スループットベンチマーク

```yaml
ベンチマーク: エンドツーエンド処理速度
  小規模データ:  100MB,  100万行,   10カラム
  中規模データ:  10GB,   1億行,     50カラム  
  大規模データ:  100GB,  10億行,    100カラム
  
  測定項目:
    - PostgreSQL読み取り速度 (MB/秒)
    - GPU転送速度 (GB/秒)
    - 解析スループット (行/秒)
    - Parquet書き込み速度 (MB/秒)
    - 合計時間とボトルネック
```

### 4.2 リソース使用率

```yaml
リソース監視:
  CPUメトリクス:
    - プロセスごとのコア使用率
    - コンテキストスイッチ
    - I/O待機時間
    
  GPUメトリクス:
    - SM占有率
    - メモリ帯域使用率
    - カーネル実行時間
    
  メモリメトリクス:
    - ホストメモリ使用量
    - GPUメモリ割り当て
    - メモリプール効率
    - ページフォルト
```

### 4.3 スケーラビリティ分析

```yaml
マルチGPUスケーリング:
  構成: 1, 2, 4, 8 GPU
  データセット: 100GBテーブル
  
  測定項目:
    - 線形スケーリング係数
    - GPU間通信オーバーヘッド
    - ロードバランシング効果
    - GPU当たりの最適チャンクサイズ
```

## 5. 統合テストシナリオ

### 5.1 エンドツーエンド検証

```yaml
E2E-1: 標準本番ワークロード
  セットアップ:
    - 顧客テーブル: 1000万行, 25カラム
    - 注文テーブル: 5000万行, 15カラム
    - 商品テーブル: 100万行, 40カラム
  
  実行:
    - 全テーブルの並行処理
    - 標準変換の適用
    - パーティション化Parquetファイル生成
  
  検証:
    - 行数精度: 100%
    - データ整合性: チェックサム一致
    - スキーマ準拠: 全型保持
    - 性能: 合計30分以内
```

### 5.2 障害回復テスト

```yaml
E2E-2: プロセス中断からの回復
  シナリオ:
    - 抽出中のProcess 1強制終了
    - 解析中のGPUメモリ不足
    - Parquet書き込み中のディスクフル
    - PostgreSQLからのネットワーク切断
  
  検証:
    - グレースフルシャットダウン
    - 状態保持
    - 正常な再起動
    - データ損失や破損なし
```

### 5.3 継続運用

```yaml
E2E-3: 24時間ストレステスト
  構成:
    - 継続的なテーブル処理
    - メモリリーク検出
    - 性能劣化監視
    - リソースクリーンアップ検証
  
  成功基準:
    - メモリリークなし (1%未満の増加)
    - 安定したスループット (5%未満の変動)
    - クラッシュやハングなし
    - 全データ整合性チェック合格
```

## 6. テスト実装計画

### 6.1 フェーズ1: 基盤構築 (第1-2週)
```yaml
第1週:
  - テストインフラのセットアップ
  - テストデータジェネレータ作成
  - Process 1テスト実装 (TC1-1からTC1-5)
  - 基本的なCI/CDパイプライン

第2週:
  - Process 2テスト実装 (TC2-1からTC2-5)
  - GPU環境セットアップ
  - メモリ監視ツール
  - 初期性能ベースライン
```

### 6.2 フェーズ2: コア機能 (第3-4週)
```yaml
第3週:
  - Process 3テスト: 固定長型 (TC3-1からTC3-4)
  - 境界値テストフレームワーク
  - 自動テスト実行

第4週:
  - Process 3テスト: 可変長型 (TC3-5からTC3-8)
  - Process 4と5のテスト (TC4-1からTC5-3)
  - 統合テストフレームワーク
```

### 6.3 フェーズ3: 高度なテスト (第5-6週)
```yaml
第5週:
  - 性能ベンチマーク
  - マルチGPUテスト
  - ストレステストシナリオ
  - 障害注入フレームワーク

第6週:
  - エンドツーエンドシナリオ
  - 24時間安定性テスト
  - テストレポート生成
  - ドキュメント完成
```

## 7. テストインフラストラクチャ

### 7.1 テストデータ生成
```python
# テストデータジェネレータフレームワーク
class TestDataGenerator:
    def generate_boundary_values(self, data_type):
        """最小値、最大値、null、エッジケースを生成"""
        
    def generate_random_data(self, data_type, row_count):
        """ランダムな有効データを生成"""
        
    def generate_malformed_data(self, data_type):
        """意図的に破損したデータを生成"""
```

### 7.2 テスト実行フレームワーク
```yaml
テストランナー設定:
  フレームワーク: pytest + pytest-benchmark
  
  フィクスチャ:
    - postgresql_connection
    - gpu_memory_pool
    - test_data_generator
    - performance_monitor
    
  プラグイン:
    - pytest-xdist (並列実行)
    - pytest-timeout (テストタイムアウト)
    - pytest-memray (メモリプロファイリング)
    - pytest-monitor (リソース追跡)
```

### 7.3 継続的インテグレーション
```yaml
GitHub Actionsワークフロー:
  on: [push, pull_request]
  
  jobs:
    unit-tests:
      - プロセス固有のテスト
      - GPU不要
      
    integration-tests:
      - フルパイプラインテスト
      - GPUランナー必須
      - PostgreSQLサービスコンテナ
      
    performance-regression:
      - ベンチマーク比較
      - 閾値アラート
      - トレンド分析
```

## 8. 成功指標

### 8.1 品質ゲート
```yaml
必須合格基準:
  機能:
    - データ型カバレッジ100%
    - データ損失や破損ゼロ
    - 全境界ケース処理
    
  性能:
    - スループット > 1GB/秒 (大規模テーブル)
    - GPU使用率 > 80%
    - メモリオーバーヘッド < データサイズの2倍
    
  信頼性:
    - 24時間安定性テスト合格
    - グレースフルなエラー回復
    - メモリリークなし
```

### 8.2 テストカバレッジ要件
```yaml
コードカバレッジ:
  - 行カバレッジ: > 90%
  - ブランチカバレッジ: > 85%
  - CUDAカーネルカバレッジ: 100%
  
テストカバレッジ:
  - 全PostgreSQL型: 100%
  - エラーパス: > 95%
  - 性能シナリオ: 100%
```

## 9. リスク分析と軽減策

### 9.1 技術的リスク
```yaml
高優先度:
  リスク: GPUメモリ不足
  軽減策: 動的チャンクサイジング、ホストへのスピル
  
  リスク: PostgreSQL接続喪失
  軽減策: コネクションプーリング、自動リトライ
  
  リスク: データ型不一致
  軽減策: 包括的な型テスト、安全なデフォルト

中優先度:
  リスク: 性能回帰
  軽減策: 自動ベンチマーク、トレンド分析
  
  リスク: マルチGPU同期
  軽減策: 明示的バリア、データ検証
```

### 9.2 運用リスク
```yaml
デプロイメントリスク:
  - CUDAバージョン互換性
  - PostgreSQLバージョン差異
  - システムリソース可用性
  
軽減策:
  - バージョンマトリックステスト
  - デプロイメント検証スイート
  - リソース要件ドキュメント
```

## 10. 成果物とタイムライン

### 10.1 テスト成果物
```yaml
成果物:
  第2週: テストインフラとジェネレータ
  第4週: 機能テストスイート完成
  第6週: 性能テストフレームワーク
  第8週: 完全な統合テストスイート
  第10週: 最終テストレポートとドキュメント
```

### 10.2 保守計画
```yaml
継続的活動:
  - 週次回帰実行
  - 性能トレンド監視
  - 新PostgreSQLバージョンテスト
  - テストスイート最適化
  - ドキュメント更新
```